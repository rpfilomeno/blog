<!DOCTYPE html><html lang="en-us"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>Interacting Minds: A Research Paper on Multi-Modal/MOE AI Agent Collaboration - The AI Sloth Slayer</title><meta name="description" content="1. Introduction: The Rise of Collaborative Multi-Modal MOE AI Agents The field of artificial intelligence has witnessed a significant proliferation of AI agents,&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="stylesheet" href="https://roger.rogverse.fyi/media/plugins/syntaxHighlighter/prism-gray.css"><link rel="stylesheet" href="https://roger.rogverse.fyi/media/plugins/syntaxHighlighter/prism-inline-color.css"><link rel="canonical" href="https://roger.rogverse.fyi/interacting-minds-a-research-paper-on-multi-modalmoe-ai-agent-collaboration.html"><link rel="alternate" type="application/atom+xml" href="https://roger.rogverse.fyi/feed.xml" title="The AI Sloth Slayer - RSS"><link rel="alternate" type="application/json" href="https://roger.rogverse.fyi/feed.json" title="The AI Sloth Slayer - JSON"><meta property="og:title" content="Interacting Minds: A Research Paper on Multi-Modal/MOE AI Agent Collaboration"><meta property="og:image" content="https://roger.rogverse.fyi/media/posts/11/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3.jpg"><meta property="og:image:width" content="736"><meta property="og:image:height" content="636"><meta property="og:site_name" content="The AI Sloth Slayer"><meta property="og:description" content="1. Introduction: The Rise of Collaborative Multi-Modal MOE AI Agents The field of artificial intelligence has witnessed a significant proliferation of AI agents,&hellip;"><meta property="og:url" content="https://roger.rogverse.fyi/interacting-minds-a-research-paper-on-multi-modalmoe-ai-agent-collaboration.html"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@godie"><meta name="twitter:title" content="Interacting Minds: A Research Paper on Multi-Modal/MOE AI Agent Collaboration"><meta name="twitter:description" content="1. Introduction: The Rise of Collaborative Multi-Modal MOE AI Agents The field of artificial intelligence has witnessed a significant proliferation of AI agents,&hellip;"><meta name="twitter:image" content="https://roger.rogverse.fyi/media/posts/11/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3.jpg"><link rel="stylesheet" href="https://roger.rogverse.fyi/assets/css/fontawesome-all.min.css?v=85514f933f9e0b82460af63f1a403fa5"><link rel="stylesheet" href="https://roger.rogverse.fyi/assets/css/style.css?v=68ffd7db75b56239d8fcaa9c4cfef9a8"><noscript><link rel="stylesheet" href="https://roger.rogverse.fyi/assets/css/noscript.css?v=efa867a99f5064d6729e4dc2008ad50b"></noscript><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://roger.rogverse.fyi/interacting-minds-a-research-paper-on-multi-modalmoe-ai-agent-collaboration.html"},"headline":"Interacting Minds: A Research Paper on Multi-Modal/MOE AI Agent Collaboration","datePublished":"2025-04-14T09:13+08:00","dateModified":"2025-05-27T10:28+08:00","image":{"@type":"ImageObject","url":"https://roger.rogverse.fyi/media/posts/11/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3.jpg","height":636,"width":736},"description":"1. Introduction: The Rise of Collaborative Multi-Modal MOE AI Agents The field of artificial intelligence has witnessed a significant proliferation of AI agents,&hellip;","author":{"@type":"Person","name":"Roger Filomeno","url":"https://roger.rogverse.fyi/authors/roger-filomeno/"},"publisher":{"@type":"Organization","name":"Roger Filomeno"}}</script><style>#wrapper > .bg {
               background-image: url(https://roger.rogverse.fyi/assets/images/overlay.png), linear-gradient(0deg, rgba(0, 0, 0, 0.1), rgba(0, 0, 0, 0.1)), url(https://roger.rogverse.fyi/media/website/mrbg-2.png);
           }</style><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-VLXN0Y9Q0W"></script><script>window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VLXN0Y9Q0W');</script></head><body class="is-preload post-template"><div id="wrapper"><header id="header"><a class="logo" href="https://roger.rogverse.fyi/">The AI Sloth Slayer</a></header><nav id="nav"><ul class="links"><li><a href="https://roger.rogverse.fyi/" title="Home" target="_self">Home</a></li><li><a href="https://roger.rogverse.fyi/work.html" title="Work" target="_self">Work</a></li><li><a href="https://roger.rogverse.fyi/3d-projects-2.html" target="_self">3D Projects</a></li><li><a href="https://roger.rogverse.fyi/tags/" title="tags" target="_self">Tags</a></li><li><a href="https://roger.rogverse.fyi/tags/blog/" title="log" target="_self">Blog</a></li><li><a href="https://roger.rogverse.fyi/privacy-policy.html" target="_self">Privacy Policy</a></li></ul><ul class="icons"><li><a href="https://x.com/godie" class="icon brands fa-x-twitter"><span class="label">Twitter</span></a></li><li><a href="https://www.linkedin.com/in/rpfilomeno" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li></ul></nav><main id="main"><article class="post"><header class="major"><time datetime="2025-04-14T09:13" class="date">April 14, 2025</time><h1>Interacting Minds: A Research Paper on Multi-Modal/MOE AI Agent Collaboration</h1><p class="post__inner"></p></header><figure class="image main"><img src="https://roger.rogverse.fyi/media/posts/11/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3.jpg" srcset="https://roger.rogverse.fyi/media/posts/11/responsive/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3-xs.webp 300w, https://roger.rogverse.fyi/media/posts/11/responsive/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3-sm.webp 480w, https://roger.rogverse.fyi/media/posts/11/responsive/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3-md.webp 768w, https://roger.rogverse.fyi/media/posts/11/responsive/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3-lg.webp 1024w, https://roger.rogverse.fyi/media/posts/11/responsive/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3-xl.webp 1360w" sizes="(max-width: 1360px) 100vw, 1360px" loading="lazy" height="636" width="736" alt=""></figure><div class="post__inner post__entry"><h2 id="1-introduction-the-rise-of-collaborative-multi-modal-moe-ai-agents"><strong>1. Introduction: The Rise of Collaborative Multi-Modal MOE AI Agents</strong></h2><p>The field of artificial intelligence has witnessed a significant proliferation of AI agents, evolving from rudimentary models to sophisticated entities capable of autonomous action. These agents are designed to operate independently, making decisions based on their environment, inputs, and predefined objectives to achieve specific goals.<sup>1</sup> This capacity for independent action distinguishes AI agents from traditional AI models, which typically require direct human prompting for every step.<sup>1</sup></p><p>A particularly transformative advancement in this domain is the emergence of multi-modal AI agents. Unlike unimodal systems that process only a single type of data, multi-modal agents possess the capability to understand and analyze information across various modalities, including text, images, audio, and video.<sup>1</sup> This multi-faceted understanding enables them to generate more refined and accurate outputs, significantly enhancing their versatility and applicability in complex real-world scenarios where diverse data types are prevalent and crucial for improving accuracy.<sup>1</sup></p><p>Complementing this development is the increasing adoption of the Mixture of Experts (MOE) architecture in building large-scale AI models. The MOE technique addresses the computational challenges associated with training massive models by dividing them into smaller, specialized sub-networks known as “experts”.<sup>5</sup> A crucial component of the MOE architecture is the gating network, which intelligently selects the most appropriate expert or combination of experts to process each specific input.<sup>5</sup> This approach allows for a significant increase in model capacity and performance without a proportional increase in computational cost, making it a key enabler for developing advanced AI systems.<sup>8</sup></p><p>The convergence of multi-modal AI and MOE architectures is paving the way for the next generation of intelligent systems: sophisticated multi-agent systems where autonomous, multi-modal MOE agents can interact and collaborate to tackle complex problems that would be insurmountable for individual agents.<sup>1</sup> This paradigm shift in AI promises to unlock unprecedented levels of efficiency, innovation, and problem-solving capabilities across a wide range of applications.</p><p>This research paper aims to provide a comprehensive exploration of how these advanced multi-modal MOE AI agents will interact with each other. The scope of this investigation will encompass their communication methods, collaboration strategies, the inherent advantages and potential disadvantages of autonomous interaction, the mechanisms through which they might negotiate and reach agreements, the critical role of human oversight, advanced communication techniques such as dynamic function calls and code exchange, important considerations for collaboration between agents from different entities, and the potential real-world applications of such autonomous inter-agent systems. By delving into these key aspects, this paper seeks to provide a foundational understanding of the future landscape of collaborative AI.</p><h2 id="2-foundations-understanding-multi-modal-ai-and-mixture-of-experts"><strong>2. Foundations: Understanding Multi-Modal AI and Mixture of Experts</strong></h2><h3 id="21-multi-modal-ai-agents"><strong>2.1 Multi-Modal AI Agents</strong></h3><p>At its core, an AI agent is a computational entity engineered to operate independently.<sup>1</sup> Its primary function is to perform specific tasks autonomously, making decisions based on the information it gathers from its environment, the inputs it receives, and the overarching goals it is programmed to achieve.<sup>1</sup> The defining characteristic that distinguishes an AI agent from a standard AI model is its inherent ability to act upon its environment.<sup>1</sup></p><p>Multi-modal agents represent a significant evolution beyond traditional unimodal AI systems. These advanced agents are characterized by their capacity to process and interpret data from a diverse array of modalities, including but not limited to text, images, audio, and video.<sup>1</sup> This ability to understand and analyze information across multiple sensory channels allows multi-modal agents to generate outputs that can also span these different formats.<sup>1</sup> The integration of various data types leads to outputs that are often more refined and accurate compared to those produced by systems limited to a single modality.<sup>1</sup> For instance, a multi-modal agent might be tasked with creating an image based on both a textual description and an accompanying audio file, demonstrating its ability to synthesize information from different sources.<sup>1</sup></p><p>The potential applications of multi-modal agents extend the reach of AI into a broader understanding and interaction with the physical world, moving beyond the limitations of text or image-only processing.<sup>1</sup> Consider augmented reality (AR) applications where multi-modal agents can assist users in performing everyday tasks, leveraging egocentric audio and video observational capabilities to understand the user’s actions and provide proactive interventions.<sup>9</sup> These agents can see and listen to the actions taken by users, enabling them to detect and correct mistakes, offer encouragement, or simply engage in helpful conversation, akin to a human teacher or assistant.<sup>9</sup> The ability to process diverse biological information layers, such as genomics, proteomics, and metabolomics, to enable more precise and individualized medical diagnoses and treatments further illustrates the power of multi-modal AI.<sup>1</sup></p><p>The generalized architecture of a multi-modal AI agent typically begins with an input layer that captures data from various sources, encompassing text, audio, images, and video.<sup>1</sup> This diverse input allows the agent to gather a comprehensive understanding of the user’s request or the surrounding environment.<sup>1</sup> Following the input layer are modality encoders, which are responsible for pre-processing the data specific to each modality, extracting relevant features that can be further analyzed.<sup>10</sup> A crucial component is the modality interface, which serves to align the features extracted from different modalities into a common representational space, allowing the agent to understand the relationships and dependencies between them.<sup>10</sup> At the core of the agent’s reasoning and understanding lies a Large Language Model (LLM), which processes the aligned multi-modal information to interpret the user’s intent, generate plans, and formulate responses.<sup>1</sup> Finally, the output layer is responsible for generating the agent’s response, which can also span across multiple modalities, providing information or taking actions in the most appropriate format.<sup>1</sup></p><h3 id="22-mixture-of-experts-moe-models"><strong>2.2 Mixture of Experts (MOE) Models</strong></h3><p>The Mixture of Experts (MOE) model represents an innovative strategy in machine learning designed to effectively address complex problems by leveraging the collective intelligence of multiple specialized sub-models, often referred to as “experts”.<sup>5</sup> This technique is particularly valuable in the context of training large language models, which often demand significant computational resources.<sup>6</sup> The MOE approach tackles this challenge by breaking down these large models into smaller, more focused networks.<sup>6</sup></p><p>Imagine an AI model structured as a team of specialists, each possessing unique expertise in a particular area.<sup>6</sup> An MOE model operates on this principle by dividing a complex task among these smaller, specialized networks.<sup>6</sup> Each expert is trained to excel in a specific aspect of the problem, enabling the model to address the overall task with greater efficiency and accuracy.<sup>6</sup> This is analogous to having a diverse team of professionals, such as doctors, mechanics, and chefs, each handling the tasks within their domain of expertise.<sup>6</sup></p><p>The architecture of an MOE model comprises several key components. The input is the problem or data that needs to be processed by the AI.<sup>6</sup> The experts are the smaller AI models, each trained to be highly proficient in a specific part of the overall problem.<sup>6</sup> The gating network acts as a manager, deciding which expert is best suited to handle each part of the input.<sup>6</sup> It examines the input and determines the appropriate expert or combination of experts to process it.<sup>6</sup> Finally, the output is the final answer or solution produced by the MOE model after the selected experts have completed their work.<sup>6</sup></p><p>The training process for an MOE model differs from that of a traditional dense model, as it is conducted on the individual components rather than the entire model at once.<sup>6</sup> During expert training, each expert is trained on a specific subset of data or tasks, allowing it to focus and develop deep expertise in its assigned area.<sup>6</sup> For example, in a language processing task, one expert might specialize in syntax while another focuses on semantics.<sup>6</sup> The gating network is trained alongside the expert networks and is tasked with learning to select the most suitable expert for a given input.<sup>6</sup> It receives the same input as the experts and learns to predict a probability distribution over the experts, indicating which one is best equipped to handle the current input.<sup>6</sup> In the joint training phase, the entire MOE system, including both the expert models and the gating network, is trained together.<sup>6</sup> This ensures that both the gating network and the experts are optimized to work in harmony, with the loss function combining the losses from the individual components to encourage a collaborative optimization approach.<sup>6</sup></p><p>The MOE architecture offers several significant advantages. By utilizing specialized models, it improves the accuracy and efficiency of decision-making for complex problems.<sup>7</sup> The modular design allows for easy expansion and adaptation to evolving challenges and data complexity, as new experts can be added without requiring a complete redesign.<sup>7</sup> Dynamic gating enables real-time adaptability, continuously enhancing decision-making and task execution.<sup>7</sup> Furthermore, MOE models optimize resource utilization by activating only the relevant experts for a given input, reducing processing needs while maintaining high performance.<sup>7</sup> Unlike conventional dense models where the entire network is executed for every input, MOE models use conditional computation to enforce sparsity, allowing for increased model capacity without a corresponding increase in the computational burden.<sup>8</sup> This balance between efficiency and performance makes MOE a promising strategy for scaling AI systems.<sup>12</sup></p><p><strong>Table 1: Comparison of Dense and MoE Models</strong></p><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody><tr><td><strong>Feature</strong></td><td><strong>Dense Models</strong></td><td><strong>MoE Models</strong></td></tr><tr><td>Parameters (Total)</td><td>All parameters are active for every input</td><td>Large number of total parameters, but only a subset used during inference</td></tr><tr><td>Parameters (Active Inference)</td><td>Equal to total parameters</td><td>Significantly smaller than total parameters</td></tr><tr><td>Computation Cost (Training)</td><td>High, scales with the entire model size</td><td>Potentially lower due to expert parallelism and conditional computation</td></tr><tr><td>Computation Cost (Inference)</td><td>High, requires processing the entire network</td><td>Significantly lower as only selected experts are activated</td></tr><tr><td>Sparsity</td><td>No inherent sparsity</td><td>Introduces sparsity through the gating mechanism and expert selection</td></tr><tr><td>Specialization</td><td>Generalized learning across all data</td><td>Experts are specialized in different domains or aspects of the problem</td></tr><tr><td>Scalability</td><td>Computationally expensive to scale</td><td>Enables scaling to extremely large models with manageable resources</td></tr></tbody></table><h2 id="3-inter-agent-communication-protocols-and-methods"><strong>3. Inter-Agent Communication: Protocols and Methods</strong></h2><p>Effective interaction between multi-modal MOE AI agents hinges on their ability to communicate seamlessly and efficiently. Several protocols and methods are being explored to facilitate this crucial aspect of collaborative intelligence.</p><p>Natural language communication offers a highly intuitive approach, leveraging the advanced natural language understanding and generation capabilities inherent in Large Language Models.<sup>1</sup> This allows agents to exchange goals, instructions, and feedback in a manner closely resembling human conversation.<sup>1</sup> Supporting various modalities like text and voice further enhances the flexibility of these interactions, enabling agents to choose the most appropriate mode based on the specific application and context.<sup>1</sup></p><p>For tasks requiring precision and efficiency, structured data exchange provides a robust alternative. Utilizing standardized data formats such as JSON or XML enables agents to exchange task-specific information, parameters, and results in a clear and unambiguous manner.<sup>13</sup> This method also facilitates seamless integration with existing systems and platforms that rely on these well-defined data structures.<sup>13</sup></p><p>Agent Communication Languages (ACLs) offer a more formal framework for inter-agent interaction. Protocols like KQML and FIPA-ACL provide a structured approach to communication, including predefined message types known as performatives. These performatives allow agents to express various communicative acts, such as informing, requesting, and promising, leading to more semantically rich and less ambiguous exchanges through standardized message structures and interaction protocols.<sup>15</sup></p><p>Interestingly, in certain multi-agent systems, particularly those employing reinforcement learning, agents can spontaneously develop their own communication protocols and signaling mechanisms.<sup>18</sup> This phenomenon, known as emergent communication, can lead to highly efficient communication tailored to specific tasks, although the resulting “languages” may be difficult for humans to interpret.<sup>18</sup></p><p>To ensure broad interoperability across diverse AI ecosystems, several standardization efforts are underway. The Agent2Agent (A2A) protocol, developed with support from numerous technology partners, aims to standardize how AI agents communicate, securely exchange information, and coordinate actions across various platforms and frameworks, regardless of the underlying vendor or technology.<sup>13</sup> A2A is designed to enable agents to collaborate in their natural modalities, even without shared memory or context, building upon existing standards like HTTP and JSON.<sup>13</sup></p><p>Another key standardization effort is the Model Context Protocol (MCP), which focuses on enabling secure, two-way connections between AI agents and external data sources.<sup>20</sup> MCP acts as a universal standard for connecting AI systems with data sources, simplifying the process of giving AI agents access to the information they need to perform tasks effectively.<sup>21</sup> Major players like Stripe, Neo4j, and Cloudflare are already offering MCP servers, indicating its potential as a foundational protocol for AI agent interoperability.<sup>23</sup></p><p>Other notable standardization initiatives include the Agent Protocol by LangChain, an open-source project aiming to codify framework-agnostic APIs for serving LLM agents in production.<sup>22</sup> This protocol focuses on defining essential endpoints for agent interaction, such as creating tasks and triggering steps, with the goal of simplifying integration and fostering a more cohesive AI agent ecosystem.<sup>24</sup></p><p>The future of inter-agent communication will likely be characterized by a multifaceted approach. It will likely integrate the natural fluidity of natural language for high-level interactions, the structured precision of data exchange for task-specific needs, the semantic richness of ACLs for complex negotiations, and the task-optimized efficiency of emergent protocols, all while being increasingly underpinned by standardized protocols like A2A and MCP to ensure widespread interoperability across the burgeoning landscape of AI agents.</p><h2 id="4-strategies-for-collaborative-task-achievement"><strong>4. Strategies for Collaborative Task Achievement</strong></h2><p>The ability of multi-modal MOE AI agents to collaborate effectively is paramount for tackling complex objectives. Several key strategies are emerging to facilitate this collaboration.</p><p>A fundamental step in achieving complex goals is task decomposition. AI agents can be designed to break down high-level user-defined objectives into a prioritized list of smaller, more manageable sub-tasks.<sup>1</sup> This process often involves sophisticated planning and reasoning capabilities, allowing agents to efficiently segment tasks and determine the optimal sequence for execution.<sup>3</sup></p><p>Another crucial strategy is role specialization. Within a multi-agent system, different agents can be assigned specialized roles, each leveraging their unique expertise – potentially enhanced by an MOE architecture – to contribute to the overarching goal.<sup>27</sup> This mirrors the dynamics of human teams, where individuals with specific skills and knowledge collaborate to achieve a common objective.<sup>27</sup> For instance, in a supply chain optimization scenario, one agent might specialize in demand forecasting while another focuses on ensuring timely order fulfillment.<sup>27</sup></p><p>Effective collaboration also relies heavily on knowledge sharing. Agents must be able to exchange critical information, observations, and insights derived from their respective modalities or expert domains.<sup>29</sup> This sharing of knowledge contributes to a collective understanding of the problem at hand and informs the development of potential solutions. The use of shared knowledge bases or ontologies can further enhance this process by ensuring consistent interpretation of terms and concepts across different agents.<sup>33</sup></p><p>Coordination mechanisms play a vital role in managing the interactions between multiple agents. These mechanisms can range from centralized coordination, where a supervisor agent analyzes input, breaks down problems, and delegates tasks to sub-agents, to decentralized coordination, where agents interact directly with each other using defined communication protocols.<sup>28</sup> Agentic orchestration platforms are also being developed to provide a structured environment for managing complex workflows and ensuring seamless collaboration between agents.<sup>35</sup></p><p>In many scenarios, agents will engage in iterative refinement. This involves agents working both in parallel and sequentially, building upon each other’s outputs and iteratively improving the quality of the final result.<sup>36</sup> Cooperative agents, in particular, play a crucial role in this process by scrutinizing each other’s contributions and collaboratively enhancing the overall outcome.<sup>36</sup> The Mixture of Agents (MoA) paradigm exemplifies this approach, where layers of specialized LLM agents work together, with proposers generating diverse responses and aggregators synthesizing them into a high-quality final output.<sup>36</sup></p><p>Effective collaboration among multi-modal MOE agents will likely necessitate a dynamic and adaptive approach. This approach will leverage the unique strengths of each agent through role specialization, facilitate seamless knowledge exchange using standardized protocols and ontologies, employ appropriate coordination mechanisms to manage the inherent complexity of multi-agent systems, and encourage the iterative refinement of solutions to achieve optimal outcomes for intricate tasks. For example, Amazon Bedrock employs a supervisor-subagent model where a central agent coordinates specialized sub-agents to tackle complex, multi-step tasks, demonstrating a hierarchical approach to collaboration.<sup>28</sup> In contrast, multi-agent workflows in areas like supply chain optimization might involve more decentralized interactions, with agents directly communicating to manage inventory and fulfillment.<sup>27</sup> The emerging MoA framework further highlights the potential of cooperative agents to iteratively improve the quality of responses by building upon each other’s outputs, showcasing a more fluid and dynamic collaboration strategy.<sup>36</sup></p><h2 id="5-benefits-of-autonomous-multi-agent-interaction"><strong>5. Benefits of Autonomous Multi-Agent Interaction</strong></h2><p>The autonomous interaction of multi-modal MOE agents presents a compelling array of potential benefits that promise to revolutionize various aspects of technology and industry.</p><p>One of the most significant advantages is the potential for increased efficiency. Autonomous agents can automate complex, multi-step processes and workflows without the need for constant human intervention.<sup>28</sup> This leads to substantial reductions in task completion times and a more optimal utilization of resources.<sup>38</sup> Furthermore, these agents can handle multiple tasks concurrently and adapt to changing conditions in real-time, significantly enhancing operational efficiency across diverse domains.<sup>39</sup> Communication among networked AI agents, for instance, enables them to work together towards a common goal much more efficiently than a single agent operating in isolation.<sup>17</sup></p><p>Autonomous multi-agent interaction also offers improved scalability. These systems can readily handle increasing workloads and data volumes by dynamically adding or removing agents as needed, providing a flexible and cost-effective solution for managing fluctuating demands.<sup>17</sup> This scalability facilitates the deployment of AI solutions across large and distributed systems without requiring fundamental architectural overhauls.<sup>29</sup></p><p>The multi-modal nature of these agents contributes to enhanced accuracy. By performing cross-verification of data obtained from diverse sources, they can significantly reduce the likelihood of errors and improve the reliability of decision-making processes.<sup>35</sup> This capability helps minimize the human errors often associated with manual tasks and data processing, leading to more dependable outcomes.<sup>1</sup></p><p>Another key benefit is the 24/7 availability of autonomous agents. Unlike human workers, these agents can operate continuously around the clock without requiring breaks or rest, ensuring uninterrupted service and support across different time zones.<sup>40</sup> This continuous operation enables real-time responses and proactive problem-solving at any time, enhancing the responsiveness and resilience of various systems.<sup>29</sup></p><p>The automation of tasks and processes through autonomous multi-agent interaction can also lead to substantial cost reduction. By taking over tasks traditionally performed by human labor, organizations can achieve significant savings in operational expenses, freeing up human employees to concentrate on more strategic and creative endeavors.<sup>39</sup> Moreover, the intelligent automation facilitated by these agents can optimize resource allocation and minimize waste, further contributing to cost efficiencies.<sup>42</sup></p><p>In essence, the autonomous interaction of multi-modal MOE agents presents a powerful pathway to significant operational advantages. These include enhanced efficiency in task execution, improved scalability to meet varying demands, greater accuracy in data processing and decision-making, continuous availability for round-the-clock operation, and substantial reductions in operational costs. These benefits collectively drive innovation and transform business processes across a multitude of industries. For example, intelligent AI agents can blend seamlessly into existing business systems, autonomously managing complex, multi-step processes with minimal oversight, leading to “hands-off” automation solutions.<sup>38</sup> The ability of networked agents to share data and refine strategies based on real-time information further underscores the potential for significant efficiency gains.<sup>17</sup></p><h2 id="6-challenges-and-considerations-efficiency-privacy-and-security"><strong>6. Challenges and Considerations: Efficiency, Privacy, and Security</strong></h2><p>While the potential of autonomous multi-agent interaction is vast, realizing its benefits necessitates careful consideration and proactive management of several inherent challenges related to efficiency, privacy, and security.</p><p>Efficiency in communication and coordination can become a significant hurdle as the number of interacting agents increases.<sup>7</sup> The overhead associated with agents exchanging messages and synchronizing their actions can potentially lead to performance bottlenecks if not managed effectively through efficient protocols and message management strategies.<sup>7</sup> Coordinating and synchronizing the activities of a large number of autonomous agents, particularly in dynamic and unpredictable environments, presents a considerable challenge.<sup>28</sup> Furthermore, ensuring optimal resource allocation and load balancing across the specialized MOE experts within and across interacting agents requires sophisticated mechanisms.<sup>11</sup></p><p>Privacy is another critical concern. Autonomous agents often require access to, process, and exchange sensitive personal or organizational data across multiple modalities.<sup>2</sup> This raises significant risks of unintended data exposure or misuse if appropriate safeguards are not in place.<sup>2</sup> Obtaining informed consent and ensuring robust data governance become particularly challenging when agents operate autonomously on behalf of users or organizations.<sup>46</sup> Moreover, enabling secure collaboration between agents from different entities without compromising the privacy and security of their users’ sensitive information requires the adoption of privacy-preserving techniques.<sup>48</sup></p><p>Security risks are also paramount. The autonomous nature and extensive access privileges of AI agents make them potential targets for cyberattacks, data breaches, and adversarial manipulation.<sup>2</sup> Malicious actors could potentially compromise agents, leading to unauthorized actions, the exfiltration of sensitive data, or the disruption of critical systems.<sup>52</sup> Establishing robust authentication, authorization, and continuous monitoring mechanisms is essential to secure inter-agent communication and prevent unauthorized access or manipulation.<sup>52</sup></p><p>Beyond these technical challenges, ethical considerations are crucial. Autonomous agents trained on potentially biased data may exhibit those biases in their actions and decisions, leading to unfair or discriminatory outcomes.<sup>2</sup> The decision-making processes of complex AI agents can often lack transparency and explainability, making it difficult to understand and audit their actions.<sup>47</sup> Furthermore, establishing clear lines of accountability and responsibility for the actions and outcomes of autonomous AI agents presents a significant challenge.<sup>2</sup></p><p>In summary, while the autonomous interaction of multi-modal MOE agents offers tremendous potential, its successful and responsible implementation hinges on proactively addressing the challenges related to managing efficiency at scale, safeguarding the privacy of sensitive data, ensuring robust security against a range of threats, and navigating the complex ethical landscape to build trust and ensure positive societal impact. For example, limitations in data transmission and network latency can impact the efficiency of communication between a growing number of agents.<sup>43</sup> Privacy risks arise from the extensive data access required for autonomous operation, necessitating strict compliance with data protection regulations.<sup>44</sup> Security vulnerabilities can be exploited by malicious actors, highlighting the need for continuous monitoring and robust guardrails.<sup>44</sup> Finally, biases in training data can lead to unfair outcomes, underscoring the importance of transparency and accountability in AI agent behavior.<sup>59</sup></p><h2 id="7-autonomous-negotiation-and-agreement-in-ai-agent-systems"><strong>7. Autonomous Negotiation and Agreement in AI Agent Systems</strong></h2><p>A key aspect of effective collaboration among autonomous multi-modal MOE agents is their ability to negotiate and reach agreements without direct human intervention. This involves several intricate mechanisms.</p><p>Intent recognition plays a crucial role, enabling AI agents to infer the goals, intentions, and preferences of other agents by observing their actions, communication patterns, and interactions with the environment.<sup>63</sup> This goes beyond simply recognizing a sequence of actions to understanding the underlying intent or overall goal of another agent.<sup>63</sup> Machine learning techniques and contextual understanding can further enhance the accuracy of intent recognition in complex multi-agent scenarios.<sup>66</sup> For instance, an agent might observe another agent repeatedly attempting to access a specific resource and infer its intent to utilize that resource for a particular task.<sup>65</sup></p><p>Negotiation protocols provide the structured sets of rules and standards that govern the negotiation process between AI agents.<sup>15</sup> These protocols define how agents make proposals, issue counter-offers, and ultimately reach mutually acceptable agreements in both cooperative and competitive settings.<sup>15</sup> Various types of negotiation protocols exist, including auction-based mechanisms where agents bid competitively for resources or tasks, contract net protocols where agents announce tasks and bid to complete them, and argumentation-based approaches where agents exchange reasoned arguments to justify their positions.<sup>69</sup></p><p>Conflict resolution strategies are essential for situations where autonomous AI agents encounter disagreements, competing objectives, or conflicting actions.<sup>71</sup> These strategies can involve further negotiation, the use of mediation by a designated agent, or the application of predefined ethical principles or rules to resolve the conflict.<sup>71</sup> For example, if two agents simultaneously attempt to access a limited resource, a conflict resolution strategy might involve a negotiation process to determine which agent has a higher priority or can utilize the resource more efficiently.<sup>71</sup></p><p>Game theory offers a powerful mathematical framework for modeling strategic interactions between negotiating AI agents.<sup>70</sup> By applying game-theoretic principles, agents can analyze potential outcomes, predict the behavior of other agents, and choose optimal strategies to maximize their own utility or the utility of the user they represent.<sup>70</sup> Concepts like Nash Equilibrium, where no agent can improve its outcome by unilaterally changing its strategy, and Pareto Efficiency, where it’s impossible to make one agent better off without making another worse off, are particularly relevant in AI agent negotiation.<sup>76</sup></p><p>Multi-Agent Reinforcement Learning (MARL) provides another promising avenue for training AI agents to negotiate effectively.<sup>81</sup> Through repeated interactions, experience, and feedback (in the form of rewards or punishments) in simulated or real-world environments, agents can learn to refine their negotiation tactics and adapt their behavior based on the actions of other agents and the dynamics of the environment.<sup>87</sup> This allows agents to develop sophisticated negotiation policies without explicit programming.<sup>86</sup></p><p>Autonomous negotiation and agreement in AI agent systems will likely involve a combination of these mechanisms. Agents will need to accurately recognize the intentions of others, adhere to established negotiation protocols, employ appropriate conflict resolution strategies, and leverage game-theoretic reasoning or reinforcement learning to optimize negotiation outcomes in a variety of scenarios, from simple resource allocation to complex contract agreements. For instance, AI agents are being developed to autonomously negotiate contracts in procurement, aiming to secure the best possible terms by analyzing historical data and market trends.<sup>69</sup></p><h2 id="8-the-necessity-of-human-oversight-and-confirmation"><strong>8. The Necessity of Human Oversight and Confirmation</strong></h2><p>Despite the increasing sophistication of autonomous AI agents, human oversight and confirmation remain crucial for ensuring their responsible and beneficial operation.</p><p>Ethical considerations necessitate human involvement to ensure that the actions and decisions of autonomous AI agents align with human values, societal norms, and ethical principles.<sup>60</sup> This helps mitigate the risk of unintended harmful or biased outcomes that might arise from purely autonomous decision-making.<sup>60</sup> Establishing clear ethical guidelines and frameworks to govern the behavior of AI agents is essential for their responsible deployment.<sup>60</sup></p><p>Safety and risk mitigation are also key reasons for human oversight. Human intervention serves as a vital safety net, preventing autonomous agents from making critical errors or engaging in unintended behaviors that could lead to negative consequences, particularly in high-stakes domains such as healthcare or finance.<sup>44</sup> Approaches like “human-in-the-loop” and “human-on-the-loop” allow for necessary guidance and control over autonomous systems.<sup>60</sup></p><p>Legal and regulatory compliance demands human oversight to ensure that the actions of AI agents adhere to relevant laws, regulations, and industry standards, especially in highly regulated sectors.<sup>44</sup> As the legal landscape surrounding AI continues to evolve, human accountability for the actions of autonomous systems remains paramount.<sup>55</sup></p><p>For complex or high-stakes decisions, human confirmation or approval is often essential.<sup>3</sup> This is particularly true for decisions or agreements that carry significant financial, legal, or ethical implications.<sup>3</sup> Multi-signature schemes, for example, can require both human and AI agent approval for sensitive transactions, providing an added layer of security and control.<sup>111</sup></p><p>Maintaining user trust is another critical aspect. Human oversight and the ability for users to monitor and control the actions of AI agents are crucial for building and sustaining trust in these autonomous systems.<sup>105</sup> Transparency and explainability in AI decision-making processes further contribute to user confidence.<sup>60</sup></p><p>While the long-term vision might involve increasingly autonomous AI agents, the current stage of development necessitates robust human oversight and confirmation mechanisms. These mechanisms are vital for addressing ethical considerations, ensuring safety and compliance with regulations, handling complex and high-stakes decisions responsibly, and ultimately building the trust required for the widespread adoption of these powerful technologies. For instance, in financial transactions, a setup where an autonomous agent proposes transactions but requires approval from human signers provides enhanced security and control.<sup>111</sup> Similarly, in high-risk applications, human oversight ensures that AI decisions align with ethical guidelines and legal frameworks.<sup>105</sup></p><h2 id="9-enhancing-communication-dynamic-function-calls-and-code-exchange"><strong>9. Enhancing Communication: Dynamic Function Calls and Code Exchange</strong></h2><p>To further enhance the efficiency and capabilities of multi-modal MOE AI agents, advanced communication methods beyond natural language are being explored, including dynamic function calls and code exchange.</p><p>Dynamic function calls allow AI agents to interact with external tools, access specific data, or trigger particular actions in a more structured and efficient manner compared to relying solely on natural language instructions.<sup>114</sup> By defining the structure of functions and their parameters, agents can precisely specify the actions they need to perform, leading to reduced ambiguity and more direct execution of tasks through well-defined interfaces.<sup>115</sup> For example, an agent might use a function call to retrieve the current weather information for a specific location or to add an event to a user’s calendar.<sup>114</sup></p><p>The exchange of code between AI agents represents another powerful advanced communication method.<sup>118</sup> This allows agents to share specialized capabilities or algorithms that might not be readily available through standard APIs or natural language commands.<sup>19</sup> By exchanging and executing code snippets, agents can potentially achieve more efficient collaboration and problem-solving, leveraging the unique functionalities developed by others.<sup>19</sup> For instance, one agent specializing in a particular type of data analysis could share a code function with another agent that needs to perform that specific analysis.<sup>118</sup></p><p>Dynamic function calls and code exchange offer several advantages over natural language communication. They can lead to increased speed of interaction, reduced potential for misinterpretation or ambiguity, and enhanced precision in specifying actions and data formats.<sup>117</sup> These methods enable agents to interact with greater efficiency and directly invoke specific functionalities or share complex logic.</p><p>However, the exchange and execution of code between autonomous AI agents introduces significant security risks.<sup>19</sup> The potential for malicious code injection, unauthorized access to systems, or overall compromise necessitates the implementation of robust security measures.<sup>19</sup> Sandboxing environments, rigorous code verification processes, and the establishment of trust mechanisms between agents are crucial for mitigating these risks and ensuring safe and secure code exchange.<sup>56</sup></p><p>In conclusion, dynamic function calls and the exchange of code represent powerful advanced communication methods that can significantly enhance the efficiency and flexibility of interaction between multi-modal MOE AI agents. They enable agents to perform complex tasks and share specialized capabilities more effectively than natural language alone. Nevertheless, the potential security implications associated with executing code from other agents underscore the critical need for implementing stringent security protocols and establishing trust frameworks to ensure safe and reliable communication. For example, the AI-Exchange Protocol (AIXP) has been proposed as a standard to facilitate the exchange of information, potentially including code, between AI agents.<sup>118</sup> While function calling provides a structured way for agents to use external tools <sup>114</sup>, the direct exchange of executable code requires careful security considerations to prevent potential vulnerabilities.<sup>19</sup></p><h2 id="10-navigating-cross-entity-collaboration-and-prioritizing-user-interests"><strong>10. Navigating Cross-Entity Collaboration and Prioritizing User Interests</strong></h2><p>As multi-modal MOE AI agents become more prevalent, scenarios involving collaboration between agents from different entities will become increasingly common. This raises important questions about how these agents, such as personal AI and company AI, can collaborate effectively while prioritizing the interests of their respective users.</p><p>Collaboration between personal AI agents, acting on behalf of individuals, and company AI agents, representing organizations, presents a unique set of complexities.<sup>1</sup> These agents might have differing goals and priorities, reflecting the distinct objectives of the individuals and the organizations they serve.<sup>1</sup> Aligning these potentially disparate interests when their AI agents interact is a significant challenge.</p><p>To facilitate effective collaboration that respects user interests, mechanisms for preference signaling are essential. AI agents need to be able to communicate and understand the preferences, constraints, and priorities of their respective users during inter-agent interactions.<sup>95</sup> This could involve agents being guided by user-defined rules, accessing preference profiles, or even interpreting natural language instructions from their users to inform their collaborative behavior.<sup>120</sup></p><p>During negotiation processes with agents from other entities, AI agents must be equipped to prioritize and advocate for the best possible outcomes for their own users.<sup>96</sup> This might involve strategic decision-making and the ability to make trade-offs while ensuring that the final agreement aligns with their user’s key objectives or “bottom line”.<sup>120</sup> For instance, an AI agent negotiating a contract on behalf of a user would need to prioritize terms that are most beneficial to that user, potentially making concessions on less critical aspects.<sup>96</sup></p><p>In situations where cross-entity collaboration involves the exchange of sensitive data, privacy-preserving techniques become crucial. Technologies such as federated learning, secure multi-party computation, and zero-knowledge proofs can enable AI agents from different entities to collaborate on tasks or share valuable insights without compromising the privacy and security of their users’ confidential information.<sup>48</sup> This is particularly important in domains like healthcare or finance where data privacy is paramount.</p><p>In conclusion, effective cross-entity collaboration between multi-modal MOE AI agents will necessitate sophisticated mechanisms for preference signaling and negotiation. These mechanisms must enable agents to understand and prioritize the interests of their respective users while interacting with agents from other entities. Furthermore, the integration of privacy-preserving techniques will be essential to ensure secure and trustworthy interactions when exchanging information across organizational or personal boundaries. For example, personal AI agents might need to signal their user’s availability for a meeting to a company AI agent attempting to schedule a team call.<sup>41</sup> In such a scenario, both agents need to prioritize their respective users’ schedules and preferences to find a mutually agreeable time.<sup>41</sup></p><h2 id="11-real-world-applications-and-future-directions"><strong>11. Real-World Applications and Future Directions</strong></h2><p>The potential applications of autonomous AI agent interaction are vast and span across numerous real-world scenarios.</p><p>In scheduling and meeting coordination, autonomous multi-modal MOE AI agents can significantly streamline the often cumbersome process of arranging meetings.<sup>41</sup> These agents can intelligently scan participants’ calendars, considering individual preferences, time zones, and availability to propose optimal meeting times, thereby eliminating the need for extensive back-and-forth communication.<sup>41</sup></p><p>Customer service is another area ripe for transformation. AI agents with multi-modal capabilities, such as understanding both text and voice inputs, can collaborate to handle complex customer inquiries, provide personalized support, and resolve issues with greater efficiency.<sup>124</sup> These agents can access customer history, leverage knowledge bases, and even escalate complex issues to human agents when necessary, ensuring a seamless and satisfactory customer experience.<sup>125</sup></p><p>Supply chain management stands to benefit immensely from autonomous AI agent interaction. Interacting agents can optimize various aspects of the supply chain, including demand forecasting, inventory management, supplier negotiation, and logistics coordination.<sup>127</sup> This can lead to increased efficiency, reduced costs, and a more resilient and responsive supply chain.<sup>129</sup></p><p>Industrial automation is also being revolutionized by AI agents. In manufacturing and industrial settings, autonomous agents can perform tasks such as predictive maintenance by monitoring equipment health and predicting failures, quality control by analyzing production data in real-time, process optimization by identifying inefficiencies, and coordination of robotic systems on the factory floor.<sup>130</sup> These applications lead to increased productivity, reduced downtime, and improved product quality.<sup>133</sup></p><p>Contract negotiation is another promising application. AI agents are being developed to autonomously negotiate contracts in various industries, aiming to secure optimal terms and reduce the need for manual human intervention.<sup>93</sup> These agents can analyze vast amounts of data, understand complex legal language, and negotiate based on predefined goals and constraints.<sup>96</sup></p><p>Looking towards the future, several trends are expected to shape the evolution of AI agent communication and collaboration. We will likely see the development of more sophisticated multi-agent systems capable of tackling increasingly complex problems through coordinated effort.<sup>13</sup> The emergence of standardized communication protocols, such as A2A and MCP, will be crucial for enabling seamless interoperability between agents from different platforms and domains.<sup>13</sup> There will also be a growing focus on incorporating emotional intelligence into AI agents to facilitate more natural and empathetic interactions.<sup>144</sup> Furthermore, ethical AI development and responsible deployment will become increasingly important as these agents become more integrated into our lives.<sup>140</sup></p><p>The autonomous interaction of multi-modal MOE AI agents holds immense potential to transform a wide array of real-world applications across diverse sectors. Future advancements will likely concentrate on enhancing their collaborative capabilities, ensuring their ethical and secure operation, and expanding their integration into increasingly intricate and dynamic environments. For example, in manufacturing, AI agents are already being used for predictive maintenance and quality control.<sup>131</sup> In finance, they are assisting with fraud detection and risk assessment.<sup>146</sup> The continued development and refinement of these applications, along with the emergence of new ones, will undoubtedly shape the future of how we interact with technology and solve complex problems.</p><h2 id="12-conclusion-the-future-landscape-of-interacting-multi-modal-moe-ai-agents"><strong>12. Conclusion: The Future Landscape of Interacting Multi-Modal MOE AI Agents</strong></h2><p>This research paper has explored the intricate landscape of interaction among multi-modal MOE AI agents, highlighting their transformative potential across various domains. The synergy between multi-modal perception, MOE-enhanced processing, and autonomous operation signifies a major leap forward in artificial intelligence, promising systems capable of perceiving, processing, and acting in complex environments with unprecedented efficiency and versatility.</p><p>The ability of these agents to communicate through diverse methods, including natural language, structured data exchange, and emerging standardized protocols, lays the foundation for sophisticated collaboration. Strategies such as task decomposition, role specialization, knowledge sharing, and iterative refinement enable multi-agent systems to tackle complex objectives that would be beyond the reach of individual agents. The benefits of autonomous interaction are substantial, offering increased efficiency, improved scalability, enhanced accuracy, continuous availability, and significant cost reductions.</p><p>However, realizing the full potential of these technologies requires careful consideration of the inherent challenges. Managing efficiency at scale, safeguarding the privacy of sensitive data, ensuring robust security against various threats, and addressing complex ethical implications are all critical aspects that must be proactively managed to build trust and ensure responsible deployment.</p><p>Standardization efforts, such as the development of protocols like A2A and MCP, are crucial for facilitating seamless interoperability and collaboration among agents from different platforms and domains. These efforts will pave the way for a more connected and collaborative AI ecosystem.</p><p>Future research should focus on developing more robust and efficient communication protocols, exploring advanced strategies for collaborative task achievement, establishing effective mechanisms for human oversight and control, and innovating approaches to ensure privacy and security in cross-entity interactions. As AI agents continue to evolve, understanding and addressing these key areas will be paramount.</p><p>In conclusion, the future landscape of artificial intelligence will be significantly shaped by the autonomous interaction of multi-modal MOE AI agents. Their potential to drive innovation, solve complex problems, and transform industries is immense. By continuing to advance our understanding of their communication, collaboration, and decision-making processes, while remaining mindful of the associated challenges and ethical considerations, we can harness the full power of these interacting minds to create a more efficient, intelligent, and beneficial future.</p><h4 id="works-cited"><strong>Works cited</strong></h4><ol><li><p>AI Interactivity (Part I): AI Agents and Multimodal Agents - Tensility Venture Partners, <a href="https://www.tensilityvc.com/insights/ai-interactivity-part-i-ai-agents-and-multimodal-agents">https://www.tensilityvc.com/insights/ai-interactivity-part-i-ai-agents-and-multimodal-agents</a></p></li><li><p>Top 10 Research Papers on AI Agents (2025) - Analytics Vidhya, <a href="https://www.analyticsvidhya.com/blog/2024/12/ai-agents-research-papers/">https://www.analyticsvidhya.com/blog/2024/12/ai-agents-research-papers/</a></p></li><li><p>Multimodality, Tool Use, and Autonomous Agents: Large Language Models Explained, Part 3 | Center for Security and Emerging Technology, <a href="https://cset.georgetown.edu/article/multimodality-tool-use-and-autonomous-agents/">https://cset.georgetown.edu/article/multimodality-tool-use-and-autonomous-agents/</a></p></li><li><p>[2306.13549] A Survey on Multimodal Large Language Models - arXiv, <a href="https://arxiv.org/abs/2306.13549">https://arxiv.org/abs/2306.13549</a></p></li><li><p>www.datacamp.com, <a href="https://www.datacamp.com/blog/mixture-of-experts-moe#:~:text=Mixture%20of%20Experts%20(MoE)%20is,best%20expert%20for%20each%20input.">https://www.datacamp.com/blog/mixture-of-experts-moe#:~:text=Mixture%20of%20Experts%20(MoE)%20is,best%20expert%20for%20each%20input.</a></p></li><li><p>What Is Mixture of Experts (MoE)? How It Works, Use Cases &amp; More | DataCamp, <a href="https://www.datacamp.com/blog/mixture-of-experts-moe">https://www.datacamp.com/blog/mixture-of-experts-moe</a></p></li><li><p>Mixture of Experts: Advancing AI Agent Collaboration and Decisions - Akira AI, <a href="https://www.akira.ai/blog/mixture-of-experts-for-ai-agents">https://www.akira.ai/blog/mixture-of-experts-for-ai-agents</a></p></li><li><p>What is mixture of experts? | IBM, <a href="https://www.ibm.com/think/topics/mixture-of-experts">https://www.ibm.com/think/topics/mixture-of-experts</a></p></li><li><p>YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents in Augmented Reality Tasks - Google Research, <a href="https://research.google/pubs/yeti-yet-to-intervene-proactive-interventions-by-multimodal-ai-agents-in-augmented-reality-tasks/">https://research.google/pubs/yeti-yet-to-intervene-proactive-interventions-by-multimodal-ai-agents-in-augmented-reality-tasks/</a></p></li><li><p>survey on multimodal large language models | National Science Review - Oxford Academic, <a href="https://academic.oup.com/nsr/article/11/12/nwae403/7896414">https://academic.oup.com/nsr/article/11/12/nwae403/7896414</a></p></li><li><p>Mixture of Experts LLMs: Key Concepts Explained - neptune.ai, <a href="https://neptune.ai/blog/mixture-of-experts-llms">https://neptune.ai/blog/mixture-of-experts-llms</a></p></li><li><p>[R] New Paper on Mixture of Experts (MoE) : r/MachineLearning - Reddit, <a href="https://www.reddit.com/r/MachineLearning/comments/1erv2sn/r_new_paper_on_mixture_of_experts_moe/">https://www.reddit.com/r/MachineLearning/comments/1erv2sn/r_new_paper_on_mixture_of_experts_moe/</a></p></li><li><p>Announcing the Agent2Agent Protocol (A2A) - Google for Developers Blog, <a href="https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/">https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/</a></p></li><li><p>How do AI agents communicate with other agents? - Milvus, <a href="https://milvus.io/ai-quick-reference/how-do-ai-agents-communicate-with-other-agents">https://milvus.io/ai-quick-reference/how-do-ai-agents-communicate-with-other-agents</a></p></li><li><p>Agent Communication Protocols: An Overview - SmythOS, <a href="https://smythos.com/ai-agents/ai-agent-development/agent-communication-protocols/">https://smythos.com/ai-agents/ai-agent-development/agent-communication-protocols/</a></p></li><li><p>Comparing Agent Communication Languages and Protocols: Choosing the Right Framework for Multi-Agent Systems - SmythOS, <a href="https://smythos.com/ai-agents/ai-agent-development/agent-communication-languages-and-protocols-comparison/">https://smythos.com/ai-agents/ai-agent-development/agent-communication-languages-and-protocols-comparison/</a></p></li><li><p>What is AI Agent Communication? - IBM, <a href="https://www.ibm.com/think/topics/ai-agent-communication">https://www.ibm.com/think/topics/ai-agent-communication</a></p></li><li><p>Interpretation of Emergent Communication in Heterogeneous Collaborative Embodied Agents - CVF Open Access, <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Patel_Interpretation_of_Emergent_Communication_in_Heterogeneous_Collaborative_Embodied_Agents_ICCV_2021_paper.pdf">https://openaccess.thecvf.com/content/ICCV2021/papers/Patel_Interpretation_of_Emergent_Communication_in_Heterogeneous_Collaborative_Embodied_Agents_ICCV_2021_paper.pdf</a></p></li><li><p>AI Agent Communication: Breakthrough or Security Nightmare? - Deepak Gupta, <a href="https://guptadeepak.com/when-ai-agents-start-whispering-the-double-edged-sword-of-autonomous-agent-communication/">https://guptadeepak.com/when-ai-agents-start-whispering-the-double-edged-sword-of-autonomous-agent-communication/</a></p></li><li><p>A2A and MCP: Start of the AI Agent Protocol Wars? - Koyeb, <a href="https://www.koyeb.com/blog/a2a-and-mcp-start-of-the-ai-agent-protocol-wars">https://www.koyeb.com/blog/a2a-and-mcp-start-of-the-ai-agent-protocol-wars</a></p></li><li><p>Introducing the Model Context Protocol - Anthropic, <a href="https://www.anthropic.com/news/model-context-protocol">https://www.anthropic.com/news/model-context-protocol</a></p></li><li><p>The Rise of AI Agents and the Need for Standardized Protocols - Pynomial, <a href="https://pynomial.com/2025/02/the-rise-of-ai-agents-and-the-need-for-standardized-protocols/">https://pynomial.com/2025/02/the-rise-of-ai-agents-and-the-need-for-standardized-protocols/</a></p></li><li><p>The AI Agent Infrastructure Stack — Three Defining Layers: Tools, Data, and Orchestration, <a href="https://www.madrona.com/ai-agent-infrastructure-three-layers-tools-data-orchestration/">https://www.madrona.com/ai-agent-infrastructure-three-layers-tools-data-orchestration/</a></p></li><li><p>Agent Protocol, <a href="https://agentprotocol.ai/">https://agentprotocol.ai/</a></p></li><li><p>Common interface for interacting with AI agents. The protocol is tech stack agnostic - you can use it with any framework for building agents. - GitHub, <a href="https://github.com/AI-Engineer-Foundation/agent-protocol">https://github.com/AI-Engineer-Foundation/agent-protocol</a></p></li><li><p>Top 7 Frameworks for Building AI Agents in 2025 - Analytics Vidhya, <a href="https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/">https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/</a></p></li><li><p>What Are AI Agentic Workflows &amp; How to Implement Them - Multimodal.dev, <a href="https://www.multimodal.dev/post/ai-agentic-workflows">https://www.multimodal.dev/post/ai-agentic-workflows</a></p></li><li><p>Introducing multi-agent collaboration capability for Amazon Bedrock (preview) - AWS, <a href="https://aws.amazon.com/blogs/aws/introducing-multi-agent-collaboration-capability-for-amazon-bedrock/">https://aws.amazon.com/blogs/aws/introducing-multi-agent-collaboration-capability-for-amazon-bedrock/</a></p></li><li><p>Multi-Agent Collaboration Mechanisms: A Survey of LLMs - arXiv, <a href="https://arxiv.org/html/2501.06322v1">https://arxiv.org/html/2501.06322v1</a></p></li><li><p>Knowledge Sharing AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/knowledge-sharing">https://clickup.com/p/ai-agents/knowledge-sharing</a></p></li><li><p>Unleashing the Future of Knowledge Management with Agentic AI - Akira AI, <a href="https://www.akira.ai/blog/ai-agent-for-knowledge-base">https://www.akira.ai/blog/ai-agent-for-knowledge-base</a></p></li><li><p>Leveraging Multi-AI Agents for Cross-Domain Knowledge Discovery - arXiv, <a href="https://arxiv.org/html/2404.08511v1">https://arxiv.org/html/2404.08511v1</a></p></li><li><p>How do multi-agent systems handle heterogeneous agents? - Milvus, <a href="https://milvus.io/ai-quick-reference/how-do-multiagent-systems-handle-heterogeneous-agents">https://milvus.io/ai-quick-reference/how-do-multiagent-systems-handle-heterogeneous-agents</a></p></li><li><p>Agent Communication and Ontologies - SmythOS, <a href="https://smythos.com/ai-agents/agent-architectures/agent-communication-and-ontologies/">https://smythos.com/ai-agents/agent-architectures/agent-communication-and-ontologies/</a></p></li><li><p>Multimodal AI Agents: Reimaging Human-Computer Interaction - Akira AI, <a href="https://www.akira.ai/blog/ai-agents-with-multimodal-models">https://www.akira.ai/blog/ai-agents-with-multimodal-models</a></p></li><li><p>Exploring MoE and MoA for Smarter AI Solutions - PuppyAgent, <a href="https://www.puppyagent.com/blog/Exploring-MoE-and-MoA-for-Smarter-AI-Solutions">https://www.puppyagent.com/blog/Exploring-MoE-and-MoA-for-Smarter-AI-Solutions</a></p></li><li><p>Mixture of Agents: An Emerging Approach in AI Methodologies - Dria, <a href="https://dria.co/blog/mixture-of-agents:-an-emerging-approach-in-ai-methodologies">https://dria.co/blog/mixture-of-agents:-an-emerging-approach-in-ai-methodologies</a></p></li><li><p>What Are Intelligent AI Agents (And Can They Really Work Alone)? | Moveworks, <a href="https://www.moveworks.com/us/en/resources/blog/what-is-intelligent-ai-agent-how-they-work-autonomously">https://www.moveworks.com/us/en/resources/blog/what-is-intelligent-ai-agent-how-they-work-autonomously</a></p></li><li><p>Autonomous AI Agents: Exploring Their Role - Neontri, <a href="https://neontri.com/blog/autonomous-ai-agents/">https://neontri.com/blog/autonomous-ai-agents/</a></p></li><li><p>Autonomous Agent Frameworks - SmythOS, <a href="https://smythos.com/ai-agents/agent-architectures/autonomous-agent-frameworks/">https://smythos.com/ai-agents/agent-architectures/autonomous-agent-frameworks/</a></p></li><li><p>Meeting Scheduler AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/meeting-scheduler">https://clickup.com/p/ai-agents/meeting-scheduler</a></p></li><li><p>Multimodal AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/multimodal">https://clickup.com/p/ai-agents/multimodal</a></p></li><li><p>Multi-agent Systems and Communication: Enabling Effective Interaction Between Agents, <a href="https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-and-communication/">https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-and-communication/</a></p></li><li><p>Preparing for the AI Agent Revolution: Navigating the Legal and Compliance Challenges of Autonomous Decision-Makers - StoneTurn, <a href="https://stoneturn.com/insight/preparing-for-the-ai-agent-revolution/">https://stoneturn.com/insight/preparing-for-the-ai-agent-revolution/</a></p></li><li><p>Privacy Concerns AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/privacy-concerns">https://clickup.com/p/ai-agents/privacy-concerns</a></p></li><li><p>Minding Mindful Machines: AI Agents and Data Protection Considerations, <a href="https://fpf.org/blog/minding-mindful-machines-ai-agents-and-data-protection-considerations/">https://fpf.org/blog/minding-mindful-machines-ai-agents-and-data-protection-considerations/</a></p></li><li><p>Five privacy concerns around agentic AI | SC Media, <a href="https://www.scworld.com/perspective/five-privacy-concerns-around-agentic-ai">https://www.scworld.com/perspective/five-privacy-concerns-around-agentic-ai</a></p></li><li><p>Unlocking the Potential of Agentic AI with Privacy-Enhancing Technologies - Duality Tech, <a href="https://dualitytech.com/blog/unlocking-the-potential-of-agentic-ai-with-privacy-enhancing-technologies/">https://dualitytech.com/blog/unlocking-the-potential-of-agentic-ai-with-privacy-enhancing-technologies/</a></p></li><li><p>Empowering Agentic AI Within Financial Systems Requires Zero-Knowledge Proofs and Privacy-Preserving Technologies | Chainlink Blog, <a href="https://blog.chain.link/agentic-ai-in-finance/">https://blog.chain.link/agentic-ai-in-finance/</a></p></li><li><p>Secret Network and Project Zero Partner, <a href="https://scrt.network/blog/secret-network-and-project-zero-partner">https://scrt.network/blog/secret-network-and-project-zero-partner</a></p></li><li><p>AI Agents Need A Privacy Layer - Oasis Network, <a href="https://oasisprotocol.org/blog/ai-agents-privacy-blockchain">https://oasisprotocol.org/blog/ai-agents-privacy-blockchain</a></p></li><li><p>The Rise of AI Agents and the Security Challenges Ahead | Auth0, <a href="https://auth0.com/blog/the-rise-of-ai-agents-and-the-security-challenges-ahead/">https://auth0.com/blog/the-rise-of-ai-agents-and-the-security-challenges-ahead/</a></p></li><li><p>The Identities Behind AI Agents: A Deep Dive Into AI &amp; NHI - The Hacker News, <a href="https://thehackernews.com/2025/04/the-identities-behind-ai-agents-deep.html">https://thehackernews.com/2025/04/the-identities-behind-ai-agents-deep.html</a></p></li><li><p>Mitigating the Top 10 Vulnerabilities in AI Agents - XenonStack, <a href="https://www.xenonstack.com/blog/vulnerabilities-in-ai-agents">https://www.xenonstack.com/blog/vulnerabilities-in-ai-agents</a></p></li><li><p>Challenges in Governing AI Agents - Lawfare, <a href="https://www.lawfaremedia.org/article/challenges-in-governing-ai-agents">https://www.lawfaremedia.org/article/challenges-in-governing-ai-agents</a></p></li><li><p>Awesome-LLM-based-AI-Agents-Knowledge/8-4-communication.md at main - GitHub, <a href="https://github.com/mind-network/Awesome-LLM-based-AI-Agents-Knowledge/blob/main/8-4-communication.md">https://github.com/mind-network/Awesome-LLM-based-AI-Agents-Knowledge/blob/main/8-4-communication.md</a></p></li><li><p>5 Security Considerations for Managing AI Agents and Their Identities - Aembit, <a href="https://aembit.io/blog/5-security-considerations-for-managing-ai-agents-and-their-identities/">https://aembit.io/blog/5-security-considerations-for-managing-ai-agents-and-their-identities/</a></p></li><li><p>Understanding AI Agent Security - Promptfoo, <a href="https://www.promptfoo.dev/blog/agent-security/">https://www.promptfoo.dev/blog/agent-security/</a></p></li><li><p>The Future of Autonomous Agents: Trends, Challenges, and Opportunities Ahead, <a href="https://smythos.com/ai-agents/agent-architectures/future-of-autonomous-agents/">https://smythos.com/ai-agents/agent-architectures/future-of-autonomous-agents/</a></p></li><li><p>AI Agent Best Practices and Ethical Considerations | Writesonic, <a href="https://writesonic.com/blog/ai-agents-best-practices">https://writesonic.com/blog/ai-agents-best-practices</a></p></li><li><p>The Ethical Challenges of AI Agents | Tepperspectives, <a href="https://tepperspectives.cmu.edu/all-articles/the-ethical-challenges-of-ai-agents/">https://tepperspectives.cmu.edu/all-articles/the-ethical-challenges-of-ai-agents/</a></p></li><li><p>Ethical considerations in deploying autonomous AI agents - Tech Edition, <a href="https://www.techedt.com/ethical-considerations-in-deploying-autonomous-ai-agents">https://www.techedt.com/ethical-considerations-in-deploying-autonomous-ai-agents</a></p></li><li><p>Intent recognition in multi-agent systems: Cow herding - ResearchGate, <a href="https://www.researchgate.net/publication/274205903_Intent_recognition_in_multi-agent_systems_Cow_herding">https://www.researchgate.net/publication/274205903_Intent_recognition_in_multi-agent_systems_Cow_herding</a></p></li><li><p>Intent Recognition in Multi-Agent Systems: Collective Box Pushing and Cow Herding - CORE, <a href="https://core.ac.uk/download/pdf/213404087.pdf">https://core.ac.uk/download/pdf/213404087.pdf</a></p></li><li><p>Plan and Intent Recognition in a Multi-agent System for Collective Box Pushing, <a href="https://www.researchgate.net/publication/274469749_Plan_and_Intent_Recognition_in_a_Multi-agent_System_for_Collective_Box_Pushing">https://www.researchgate.net/publication/274469749_Plan_and_Intent_Recognition_in_a_Multi-agent_System_for_Collective_Box_Pushing</a></p></li><li><p>Prediction of Intent in Robotics and Multi-agent Systems | SciSpace, <a href="https://scispace.com/pdf/prediction-of-intent-in-robotics-and-multi-agent-systems-2uazbh7zl0.pdf">https://scispace.com/pdf/prediction-of-intent-in-robotics-and-multi-agent-systems-2uazbh7zl0.pdf</a></p></li><li><p>Negotiation Protocols for AI Agents - Matoffo, <a href="https://matoffo.com/negotiation-protocols-for-ai-agents/">https://matoffo.com/negotiation-protocols-for-ai-agents/</a></p></li><li><p>accessed January 1, 1970, <a href="https://www.researchgate.net/publication/343780350_Autonomous_Negotiation_in_Multi-Agent_Systems_Principles_and_Challenges">https://www.researchgate.net/publication/343780350_Autonomous_Negotiation_in_Multi-Agent_Systems_Principles_and_Challenges</a></p></li><li><p>Agent Communication and Negotiation: Enhancing Decision-Making and Collaboration in Multi-Agent Systems - SmythOS, <a href="https://smythos.com/ai-agents/agent-architectures/agent-communication-and-negotiation/">https://smythos.com/ai-agents/agent-architectures/agent-communication-and-negotiation/</a></p></li><li><p>Multi-Agent Systems and Negotiation: Strategies for Effective Agent Collaboration, <a href="https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-and-negotiation/">https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-and-negotiation/</a></p></li><li><p>Conflict Resolution AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/conflict-resolution">https://clickup.com/p/ai-agents/conflict-resolution</a></p></li><li><p>Normative conflict resolution through human–autonomous agent interaction - University of York, <a href="https://pure.york.ac.uk/portal/files/116793996/1-s2.0-S2666659625000101-main.pdf">https://pure.york.ac.uk/portal/files/116793996/1-s2.0-S2666659625000101-main.pdf</a></p></li><li><p>Dealing With Ethical Conflicts In Autonomous Agents And Multi-Agent Systems, <a href="https://www.researchgate.net/publication/279258407_Dealing_With_Ethical_Conflicts_In_Autonomous_Agents_And_Multi-Agent_Systems">https://www.researchgate.net/publication/279258407_Dealing_With_Ethical_Conflicts_In_Autonomous_Agents_And_Multi-Agent_Systems</a></p></li><li><p>Resolving Conflict in Decision-Making for Autonomous Driving - Robotics, <a href="https://www.roboticsproceedings.org/rss17/p049.pdf">https://www.roboticsproceedings.org/rss17/p049.pdf</a></p></li><li><p>How can multi-agent systems communicate? Is game theory the answer? - Capgemini USA, <a href="https://www.capgemini.com/us-en/insights/expert-perspectives/how-can-multi-agent-systems-communicate-is-game-theory-the-answer/">https://www.capgemini.com/us-en/insights/expert-perspectives/how-can-multi-agent-systems-communicate-is-game-theory-the-answer/</a></p></li><li><p>Agent-Based Modeling and Game Theory: Simulating Strategic Interactions in Complex Systems - SmythOS, <a href="https://smythos.com/ai-industry-solutions/law/agent-based-modeling-and-game-theory/">https://smythos.com/ai-industry-solutions/law/agent-based-modeling-and-game-theory/</a></p></li><li><p>Game-theoretic LLM: Agent Workflow for Negotiation Games - arXiv, <a href="https://arxiv.org/html/2411.05990v1">https://arxiv.org/html/2411.05990v1</a></p></li><li><p>Scientific approaches and techniques for negotiation : a game theoretic and artificial intelligence perspective - CWI, <a href="https://ir.cwi.nl/pub/4448">https://ir.cwi.nl/pub/4448</a></p></li><li><p>Game Theory (Stanford Encyclopedia of Philosophy), <a href="https://plato.stanford.edu/entries/game-theory/#AI">https://plato.stanford.edu/entries/game-theory/#AI</a></p></li><li><p>Game Theory in AI: The Nash Equilibrium EXPLAINED - YouTube, <a href="https://www.youtube.com/watch?v=fbHl9AbcSic">https://www.youtube.com/watch?v=fbHl9AbcSic</a></p></li><li><p>MARLIN: Multi-Agent Reinforcement Learning Guided by Language-Based Inter-Robot Negotiation - arXiv, <a href="https://arxiv.org/html/2410.14383v3">https://arxiv.org/html/2410.14383v3</a></p></li><li><p>[2410.14383] MARLIN: Multi-Agent Reinforcement Learning Guided by Language-Based Inter-Robot Negotiation - arXiv, <a href="https://arxiv.org/abs/2410.14383">https://arxiv.org/abs/2410.14383</a></p></li><li><p>Applying Multi-Agent Reinforcement Learning to Candidate/Employer Job Matching and Salary Negotiations | Computer Science and Economics, <a href="https://csec.yale.edu/senior-essays/fall-2022/applying-multi-agent-reinforcement-learning-candidateemployer-job-matching">https://csec.yale.edu/senior-essays/fall-2022/applying-multi-agent-reinforcement-learning-candidateemployer-job-matching</a></p></li><li><p>Deep Reinforcement Learning Agent for Negotiation in Multi-Agent Cooperative Distributed Predictive Control - MDPI, <a href="https://www.mdpi.com/2076-3417/13/4/2432">https://www.mdpi.com/2076-3417/13/4/2432</a></p></li><li><p>MULTI-AGENT REINFORCEMENT LEARNING FOR COALITIONAL BARGAINING GAMES, <a href="https://openreview.net/forum?id=OaZktJBVpUy">https://openreview.net/forum?id=OaZktJBVpUy</a></p></li><li><p>A Deep Reinforcement Learning Approach to Concurrent Bilateral Negotiation - IJCAI, <a href="https://www.ijcai.org/proceedings/2020/0042.pdf">https://www.ijcai.org/proceedings/2020/0042.pdf</a></p></li><li><p>Towards Learning Multi-Agent Negotiations via Self-Play - CVF Open Access, <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/ADW/Tang_Towards_Learning_Multi-Agent_Negotiations_via_Self-Play_ICCVW_2019_paper.pdf">https://openaccess.thecvf.com/content_ICCVW_2019/papers/ADW/Tang_Towards_Learning_Multi-Agent_Negotiations_via_Self-Play_ICCVW_2019_paper.pdf</a></p></li><li><p>Towards Learning Multi-Agent Negotiations via Self-Play, <a href="https://machinelearning.apple.com/research/towards-learning-multi-agent-negotiations-via-self-play">https://machinelearning.apple.com/research/towards-learning-multi-agent-negotiations-via-self-play</a></p></li><li><p>Single-Agent vs. Multi-Agent Techniques for Concurrent Reinforcement Learning of Negotiation Dialogue Policies - ACL Anthology, <a href="https://aclanthology.org/P14-1047/">https://aclanthology.org/P14-1047/</a></p></li><li><p>accessed January 1, 1970, <a href="https://arxiv.org/abs/2006.03753">https://arxiv.org/abs/2006.03753</a></p></li><li><p>Unlock Savings with Autonomous Negotiation Agents (ANA) - Zycus, <a href="https://www.zycus.com/solution/autonomous-negotiation-agents">https://www.zycus.com/solution/autonomous-negotiation-agents</a></p></li><li><p>Negotiation Strategy AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/negotiation-strategy">https://clickup.com/p/ai-agents/negotiation-strategy</a></p></li><li><p>AI Negotiation Agent | statworx®, <a href="https://www.statworx.com/en/generative-ai-solutions/ai-negotiation-agent/">https://www.statworx.com/en/generative-ai-solutions/ai-negotiation-agent/</a></p></li><li><p>AI-Powered Deals: How Autonomous Negotiation is Redefining Supply Chain Strategy, <a href="https://supplychain360.io/autonomous-negotiation-revolutionizing-supply-chain-efficiency-2025-trends/">https://supplychain360.io/autonomous-negotiation-revolutionizing-supply-chain-efficiency-2025-trends/</a></p></li><li><p>Multi-AI Agents and How Business Can Prepare, <a href="https://www.mri.co.jp/en/knowledge/article/202412_2.html">https://www.mri.co.jp/en/knowledge/article/202412_2.html</a></p></li><li><p>The Role of Procurement: AI Agents for Contract Negotiation in Finance - Akira AI, <a href="https://www.akira.ai/blog/ai-agents-for-contract-negotiation">https://www.akira.ai/blog/ai-agents-for-contract-negotiation</a></p></li><li><p>AI Lease Negotiation 2025 Ultimate Guide | Real Estate Deals - Rapid Innovation, <a href="https://www.rapidinnovation.io/post/ai-agent-lease-negotiation-assistant">https://www.rapidinnovation.io/post/ai-agent-lease-negotiation-assistant</a></p></li><li><p>AI Agents Are Transforming Healthcare Payer Interactions With Smart Negotiation, <a href="https://www.thoughtful.ai/blog/ai-agents-are-transforming-healthcare-payer-interactions-with-smart-negotiation">https://www.thoughtful.ai/blog/ai-agents-are-transforming-healthcare-payer-interactions-with-smart-negotiation</a></p></li><li><p>Understanding Agentic AI in Procurement: How Autonomous AI Has Been Transforming Supplier Deals - Pactum, <a href="https://pactum.com/understanding-agentic-ai-in-procurement-how-autonomous-ai-has-been-transforming-supplier-deals/">https://pactum.com/understanding-agentic-ai-in-procurement-how-autonomous-ai-has-been-transforming-supplier-deals/</a></p></li><li><p>When Will Your AI Negotiate With My AI? - Nibble, <a href="https://blog.nibbletechnology.com/will-ai-negotiate-with-ai">https://blog.nibbletechnology.com/will-ai-negotiate-with-ai</a></p></li><li><p>Contract Negotiation AI Agents for the Finance Industry - Glide, <a href="https://www.glideapps.com/agents/finance/contract-negotiation-ai-agents">https://www.glideapps.com/agents/finance/contract-negotiation-ai-agents</a></p></li><li><p>How To Use AI Negotiation To Get More Of What You Want | Lindy, <a href="https://www.lindy.ai/blog/ai-negotiation">https://www.lindy.ai/blog/ai-negotiation</a></p></li><li><p>AI in Contract Negotiations (procurement) : r/legaltech - Reddit, <a href="https://www.reddit.com/r/legaltech/comments/1i3eqtg/ai_in_contract_negotiations_procurement/">https://www.reddit.com/r/legaltech/comments/1i3eqtg/ai_in_contract_negotiations_procurement/</a></p></li><li><p>The leader in agentic AI for procurement for over half a decade, <a href="https://pactum.com/">https://pactum.com/</a></p></li><li><p>The crucial role of humans in AI oversight - Cornerstone OnDemand, <a href="https://www.cornerstoneondemand.com/resources/article/the-crucial-role-of-humans-in-ai-oversight/">https://www.cornerstoneondemand.com/resources/article/the-crucial-role-of-humans-in-ai-oversight/</a></p></li><li><p>How humans &amp; AI agents can work together ethically &amp; effectively - Macro 4, <a href="https://www.macro4.com/blog/the-rise-of-ai-agents-how-humans-and-machines-can-work-together-ethically-and-effectively/">https://www.macro4.com/blog/the-rise-of-ai-agents-how-humans-and-machines-can-work-together-ethically-and-effectively/</a></p></li><li><p>New Ethics Risks Courtesy of AI Agents? Researchers Are on the Case - IBM, <a href="https://www.ibm.com/think/insights/ai-agent-ethics">https://www.ibm.com/think/insights/ai-agent-ethics</a></p></li><li><p>What Ethical Issues Does Agentforce AI Bring to the Table for CIOs? - Inclusion Cloud, <a href="https://inclusioncloud.com/insights/blog/ethical-issues-agentforce-cios/">https://inclusioncloud.com/insights/blog/ethical-issues-agentforce-cios/</a></p></li><li><p>AI agents evolve rapidly, challenging human oversight - IBM, <a href="https://www.ibm.com/think/insights/ai-agents-evolve-rapidly">https://www.ibm.com/think/insights/ai-agents-evolve-rapidly</a></p></li><li><p>Unlocking value with AI agents: A responsible approach - PwC, <a href="https://www.pwc.com/us/en/tech-effect/ai-analytics/responsible-ai-agents.html">https://www.pwc.com/us/en/tech-effect/ai-analytics/responsible-ai-agents.html</a></p></li><li><p>Human approval for AI agent actions - Safe Docs, <a href="https://docs.safe.global/home/ai-agent-quickstarts/human-approval">https://docs.safe.global/home/ai-agent-quickstarts/human-approval</a></p></li><li><p>From Fine Print to Machine Code: How AI Agents are Rewriting the Rules of Engagement: Part 3 of 3, <a href="https://law.stanford.edu/2025/03/26/from-fine-print-to-machine-code-how-ai-agents-are-rewriting-the-rules-of-engagement-part-3-of-3/">https://law.stanford.edu/2025/03/26/from-fine-print-to-machine-code-how-ai-agents-are-rewriting-the-rules-of-engagement-part-3-of-3/</a></p></li><li><p>5 Ways To Build a Trustworthy AI Agent - Salesforce, <a href="https://www.salesforce.com/blog/trustworthy-ai-agent/">https://www.salesforce.com/blog/trustworthy-ai-agent/</a></p></li><li><p>How to use Azure AI Agent Service with function calling - Learn Microsoft, <a href="https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/function-calling">https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/function-calling</a></p></li><li><p>Function-Calling vs Agents - Community.aws, <a href="https://community.aws/content/2sryksE4Ga2hAsUksJZfnT8pJnr/function-calling-vs-agents">https://community.aws/content/2sryksE4Ga2hAsUksJZfnT8pJnr/function-calling-vs-agents</a></p></li><li><p>ReAct agents vs function calling agents - LeewayHertz, <a href="https://www.leewayhertz.com/react-agents-vs-function-calling-agents/">https://www.leewayhertz.com/react-agents-vs-function-calling-agents/</a></p></li><li><p>Agent Communication and Message Passing: Streamlining Interaction and Data Exchange in Multi-Agent Systems - SmythOS, <a href="https://smythos.com/ai-agents/agent-architectures/agent-communication-and-message-passing/">https://smythos.com/ai-agents/agent-architectures/agent-communication-and-message-passing/</a></p></li><li><p>AI-Exchange Protocol (AIXP): A Communication Standard for Artificial Intelligence Agents - GitHub, <a href="https://github.com/davila7/AIXP">https://github.com/davila7/AIXP</a></p></li><li><p>Communicating with other agents – Fetch.ai Documentation, <a href="https://fetch.ai/docs/guides/agents/intermediate/communicating-with-other-agents">https://fetch.ai/docs/guides/agents/intermediate/communicating-with-other-agents</a></p></li><li><p>Designing AI Agents That Work for You, Part 1: Communication Patterns - Innovation at Consumer Reports, <a href="https://innovation.consumerreports.org/designing-ai-agents-that-work-for-you-part-1/">https://innovation.consumerreports.org/designing-ai-agents-that-work-for-you-part-1/</a></p></li><li><p>How to Automate Meeting Scheduling with AI - Datagrid, <a href="https://www.datagrid.com/blog/automate-email-scheduling-ai">https://www.datagrid.com/blog/automate-email-scheduling-ai</a></p></li><li><p>Calendly AI Agents - Relevance AI, <a href="https://relevanceai.com/agent-templates-software/calendly">https://relevanceai.com/agent-templates-software/calendly</a></p></li><li><p>Emergency Meeting Coordination AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/emergency-meeting-coordination">https://clickup.com/p/ai-agents/emergency-meeting-coordination</a></p></li><li><p>www.salesforce.com, <a href="https://www.salesforce.com/service/ai/customer-service-agents/#:~:text=AI%20customer%20service%20agents%20are,a%20personalized%20and%20conversational%20way.">https://www.salesforce.com/service/ai/customer-service-agents/#:~:text=AI%20customer%20service%20agents%20are,a%20personalized%20and%20conversational%20way.</a></p></li><li><p>AI Customer Service Agents - Salesforce, <a href="https://www.salesforce.com/service/ai/customer-service-agents/">https://www.salesforce.com/service/ai/customer-service-agents/</a></p></li><li><p>AI Agent-Led Customer Service: Revolutionizing Support with Freddy AI - Freshworks, <a href="https://www.freshworks.com/freshdesk/ai-agents/customer-service/">https://www.freshworks.com/freshdesk/ai-agents/customer-service/</a></p></li><li><p>sema4.ai, <a href="https://sema4.ai/blog/ai-agents-supply-chain/#:~:text=AI%20agents%20monitor%20supplier%20performance,costs%20while%20ensuring%20adequate%20supply.">https://sema4.ai/blog/ai-agents-supply-chain/#:~:text=AI%20agents%20monitor%20supplier%20performance,costs%20while%20ensuring%20adequate%20supply.</a></p></li><li><p>AI Agents for Manufacturing Success | Salesforce US, <a href="https://www.salesforce.com/manufacturing/artificial-intelligence/ai-agents-for-manufacturing/">https://www.salesforce.com/manufacturing/artificial-intelligence/ai-agents-for-manufacturing/</a></p></li><li><p>Revolutionizing Supply Chain Management: How AI Agents are Reshaping Industry Logistics - Sema4.ai, <a href="https://sema4.ai/blog/ai-agents-supply-chain/">https://sema4.ai/blog/ai-agents-supply-chain/</a></p></li><li><p>Industrial AI in action: How AI agents and digital threads will transform the manufacturing industries - Microsoft, <a href="https://www.microsoft.com/en-us/industry/blog/manufacturing-and-mobility/manufacturing/2025/03/25/industrial-ai-in-action-how-ai-agents-and-digital-threads-will-transform-the-manufacturing-industries/">https://www.microsoft.com/en-us/industry/blog/manufacturing-and-mobility/manufacturing/2025/03/25/industrial-ai-in-action-how-ai-agents-and-digital-threads-will-transform-the-manufacturing-industries/</a></p></li><li><p>From Data to Decisions: AI Agents for Industrial Process Optimization - Akira AI, <a href="https://www.akira.ai/blog/ai-agents-for-industrial-process-optimization">https://www.akira.ai/blog/ai-agents-for-industrial-process-optimization</a></p></li><li><p>Why should manufacturers embrace AI agents now? - The World Economic Forum, <a href="https://www.weforum.org/stories/2025/01/why-manufacturers-should-embrace-next-frontier-ai-agents/">https://www.weforum.org/stories/2025/01/why-manufacturers-should-embrace-next-frontier-ai-agents/</a></p></li><li><p>AI Agents in Manufacturing 2025 Ultimate Guide - Rapid Innovation, <a href="https://www.rapidinnovation.io/post/ai-agent-manufacturing-applications-use-cases-benefits">https://www.rapidinnovation.io/post/ai-agent-manufacturing-applications-use-cases-benefits</a></p></li><li><p>AI Agents for Manufacturing Will Give You Superpowers | Plataine, <a href="https://www.plataine.com/blog/ai-agents-for-manufacturing-will-give-you-superpowers/">https://www.plataine.com/blog/ai-agents-for-manufacturing-will-give-you-superpowers/</a></p></li><li><p>What are AI Agents in Manufacturing? - Augmentir, <a href="https://www.augmentir.com/glossary/ai-agents-in-manufacturing">https://www.augmentir.com/glossary/ai-agents-in-manufacturing</a></p></li><li><p>AI agent for manufacturing: Applications and use cases, components, capabilities, implementation and benefits - LeewayHertz, <a href="https://www.leewayhertz.com/ai-agent-for-manufacturing/">https://www.leewayhertz.com/ai-agent-for-manufacturing/</a></p></li><li><p>Reinventing Manufacturing with Agentic AI - Akira AI, <a href="https://www.akira.ai/blog/ai-agents-for-manufacturing">https://www.akira.ai/blog/ai-agents-for-manufacturing</a></p></li><li><p>AI Agents In Production – A High Level Overview - Hiflylabs, <a href="https://hiflylabs.com/blog/2024/8/1/ai-agents-multi-agent-overview">https://hiflylabs.com/blog/2024/8/1/ai-agents-multi-agent-overview</a></p></li><li><p>How AI Agents Are Driving ROI: 3 Real-World Case Studies (2025) - Creole Studios, <a href="https://www.creolestudios.com/real-world-ai-agent-case-studies/">https://www.creolestudios.com/real-world-ai-agent-case-studies/</a></p></li><li><p>The Future of AI: The Power of Agent-to-Agent - Workday Blog, <a href="https://blog.workday.com/en-us/agent-to-agent-overview.html">https://blog.workday.com/en-us/agent-to-agent-overview.html</a></p></li><li><p>Future of AI Agents: Trends &amp; Predictions for Businesses (2025) - REVE Chat, <a href="https://www.revechat.com/blog/future-of-ai-agents/">https://www.revechat.com/blog/future-of-ai-agents/</a></p></li><li><p>AI Agents: The Defining Workforce Trend of 2025 - Data Society, <a href="https://datasociety.com/ai-agents-the-defining-workforce-trend-of-2025/">https://datasociety.com/ai-agents-the-defining-workforce-trend-of-2025/</a></p></li><li><p>Generative AI meets the virtual world: A model for human-AI collaboration - Deloitte, <a href="https://www2.deloitte.com/us/en/insights/industry/technology/ai-and-vr-model-for-human-ai-collaboration.html">https://www2.deloitte.com/us/en/insights/industry/technology/ai-and-vr-model-for-human-ai-collaboration.html</a></p></li><li><p>Top 10 AI Agent Trends and Predictions for 2025 - Analytics Vidhya, <a href="https://www.analyticsvidhya.com/blog/2024/12/ai-agent-trends/">https://www.analyticsvidhya.com/blog/2024/12/ai-agent-trends/</a></p></li><li><p>Why agents are the next frontier of generative AI - McKinsey, <a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/why-agents-are-the-next-frontier-of-generative-ai">https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/why-agents-are-the-next-frontier-of-generative-ai</a></p></li><li><p>16 Real-World AI Agents Examples in 2025 - Aisera, <a href="https://aisera.com/blog/ai-agents-examples/">https://aisera.com/blog/ai-agents-examples/</a></p></li></ol></div><footer class="post__inner post__footer"><p class="post__last-updated">This article was updated on May 27, 2025</p><div class="post__share-tag-container"><div class="post__tag"><h3>Tagged in:</h3><ul><li><a href="https://roger.rogverse.fyi/tags/ai/">AI</a></li><li><a href="https://roger.rogverse.fyi/tags/blog/">Blog</a></li><li><a href="https://roger.rogverse.fyi/tags/research/">research</a></li></ul></div><div class="post__share"><button class="post__share-button js-post__share-button icon" aria-label="Share button"><i class="fas fa-share-alt"></i></button><div class="post__share-popup js-post__share-popup"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Froger.rogverse.fyi%2Finteracting-minds-a-research-paper-on-multi-modalmoe-ai-agent-collaboration.html" class="js-share icon brands fa-facebook-f" rel="nofollow noopener noreferrer"><span class="label">Facebook</span> </a><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Froger.rogverse.fyi%2Finteracting-minds-a-research-paper-on-multi-modalmoe-ai-agent-collaboration.html&amp;via=godie&amp;text=Interacting%20Minds%3A%20A%20Research%20Paper%20on%20Multi-Modal%2FMOE%20AI%20Agent%20Collaboration" class="js-share icon brands fa-x-twitter" rel="nofollow noopener noreferrer"><span class="label">Twitter</span> </a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Froger.rogverse.fyi%2Finteracting-minds-a-research-paper-on-multi-modalmoe-ai-agent-collaboration.html" class="js-share icon brands fa-linkedin" rel="nofollow noopener noreferrer"><span class="label">LinkedIn</span></a></div></div></div><div class="post__bio"><img src="https://roger.rogverse.fyi/media/website/circle-avatar-open.png" loading="lazy" height="1080" width="1080" alt="Roger Filomeno"><div><h3><a href="https://roger.rogverse.fyi/authors/roger-filomeno/" class="invert" rel="author">Roger Filomeno</a></h3><p>Roger the CEO of <a href="https://rogverse.fyi/" title="Automation that Amplifies Human Potential" target="_blank" rel="noopener">ROGVERSE</a> ltd -- a comprehensive AI automation platform built on principle: <em>Automation that Amplifies Human Potential</em></p></div></div></footer></article></main><footer id="copyright"><p>THE AI SLOTH SLAYER 2025 All rights reserve</p></footer></div><script src="https://roger.rogverse.fyi/assets/js/jquery.min.js?v=c9771cc3e90e18f5336eedbd0fffb2cf"></script><script src="https://roger.rogverse.fyi/assets/js/jquery.scrollex.min.js?v=f89065e3d988006af9791b44561d7c90"></script><script src="https://roger.rogverse.fyi/assets/js/jquery.scrolly.min.js?v=1ed5a78bde1476875a40f6b9ff44fc14"></script><script src="https://roger.rogverse.fyi/assets/js/browser.min.js?v=c07298dd19048a8a69ad97e754dfe8d0"></script><script src="https://roger.rogverse.fyi/assets/js/breakpoints.min.js?v=81a479eb099e3b187613943b085923b8"></script><script src="https://roger.rogverse.fyi/assets/js/util.min.js?v=4201a626f8c9b614a663b3a1d7d82615"></script><script src="https://roger.rogverse.fyi/assets/js/main.min.js?v=56233c354bd814758be8bff42f7e13a5"></script><script>/*<![CDATA[*/var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};/*]]>*/</script><script src="https://cdn.botpress.cloud/webchat/v2.2/inject.js"></script><script src="https://files.bpcontent.cloud/2025/01/25/00/20250125005609-7G1UEWJF.js"></script><script>!function(){var e,r="undefined"==typeof window?{}:window,n=r.usertour;if(console.log("enter npm backage, usertour:",n),!n){var o="https://js.usertour.io/";console.log("enter npm backage: ",o);var t=null;n=r.usertour={_stubbed:!0,load:function(){return t||(t=new Promise((function(e,n){var u=document.createElement("script");u.async=!0;var a=r.USERTOURJS_ENV_VARS||{};"es2020"===(a.USERTOURJS_BROWSER_TARGET||function(e){for(var r=[[/Edg\//,/Edg\/(\d+)/,80],[/OPR\//,/OPR\/(\d+)/,67],[/Chrome\//,/Chrome\/(\d+)/,80],[/CriOS\//,/CriOS\/(\d+)/,100],[/Safari\//,/Version\/(\d+)/,14],[/Firefox\//,/Firefox\/(\d+)/,74]],n=0;n<r.length;n++){var o=r[n],t=o[0],u=o[1],a=o[2];if(e.match(t)){var i=e.match(new RegExp(u));if(i&&parseInt(i[1],10)>=a)return"es2020";break}}return"legacy"}(navigator.userAgent))?(u.type="module",u.src=a.USERTOURJS_ES2020_URL||o+"es2020/usertour.js"):u.src=a.USERTOURJS_LEGACY_URL||o+"legacy/usertour.iife.js",u.onload=function(){e()},u.onerror=function(){document.head.removeChild(u),t=null;var e=new Error("Could not load Usertour.js");console.warn(e.message),n(e)},document.head.appendChild(u)}))),t}};var u=r.USERTOURJS_QUEUE=r.USERTOURJS_QUEUE||[],a=function(e){n[e]=function(){var r=Array.prototype.slice.call(arguments);n.load(),u.push([e,null,r])}},i=function(e){n[e]=function(){var r,o=Array.prototype.slice.call(arguments);n.load();var t=new Promise((function(e,n){r={resolve:e,reject:n}}));return u.push([e,r,o]),t}};a("init"),a("off"),a("on"),a("reset"),i("endAll"),i("group"),i("identify"),i("identifyAnonymous"),i("start"),i("track"),i("updateGroup"),i("updateUser"),e=!1,n["isIdentified"]=function(){return e}}}();

  usertour.init('cm98jgf140am8y2bn8ddqwtbl');
  usertour.identifyAnonymous();</script><script src="https://roger.rogverse.fyi/media/plugins/pagePrefetching/quicklink.umd.js"></script><script>window.addEventListener('load', () => {
					quicklink.listen({
						prerender: true,
						el: document.querySelector('body'),
						delay: 0,
						limit: Infinity,
						throttle: Infinity,
						timeout: 2000
					});
				});</script><script defer="defer" src="https://roger.rogverse.fyi/media/plugins/syntaxHighlighter/prism.js"></script><script defer="defer" src="https://roger.rogverse.fyi/media/plugins/syntaxHighlighter/prism-line-numbers.min.js"></script><script defer="defer" src="https://roger.rogverse.fyi/media/plugins/syntaxHighlighter/clipboard.min.js"></script><script defer="defer" src="https://roger.rogverse.fyi/media/plugins/syntaxHighlighter/prism-copy-to-clipboard.min.js"></script><script defer="defer" src="https://roger.rogverse.fyi/media/plugins/syntaxHighlighter/prism-inline-color.min.js"></script><script defer="defer" src="https://roger.rogverse.fyi/media/plugins/syntaxHighlighter/prism-autolinker.min.js"></script><div class="pcb" data-behaviour="badge" data-behaviour-link="#cookie-settings" data-revision="1" data-config-ttl="90" data-debug-mode="false"><div role="dialog" aria-modal="true" aria-hidden="true" aria-labelledby="pcb-title" aria-describedby="pcb-txt" class="pcb__banner pcb__banner--bar"><div class="pcb__inner"><div id="pcb-title" role="heading" aria-level="2" class="pcb__title">This website uses cookies</div><div id="pcb-txt" class="pcb__txt">Select which cookies to opt-in to via the checkboxes below; our website uses cookies to examine site traffic and user activity while on our site, for marketing, and to provide social media functionality. <a href="https://rogverse.fyi/privacy/">More details...</a></div><div class="pcb__buttons"><button type="button" class="pcb__btn pcb__btn--link pcb__btn--configure" aria-haspopup="dialog">Manage preferences</button> <button type="button" class="pcb__btn pcb__btn--solid pcb__btn--accept">Accept all</button></div></div></div><div class="pcb__popup" role="dialog" aria-modal="true" aria-hidden="true" aria-labelledby="pcb-popup-title"><div class="pcb__popup__wrapper"><div class="pcb__inner pcb__popup__inner"><div class="pcb__popup__heading"><div id="pcb-popup-title" role="heading" aria-level="2" class="pcb__title">Cookie settings</div><button class="pcb__popup__close" aria-label="Close"></button></div><div class="pcb__popup__content"><div class="pcb__txt pcb__popup__txt">We use cookies to enhance your browsing experience, serve personalized ads or content, and analyze our traffic. By clicking "Accept All", you consent to our use of cookies. <a href="https://rogverse.fyi/privacy/">More details...</a></div><ul class="pcb__groups"><li class="pcb__group"><details><summary class="pcb__group__title no-desc">Required</summary></details><div class="pcb__popup__switch is-checked"><input type="checkbox" data-group-name="" id="pcb-group-0" checked="checked"> <label for="pcb-group-0">Required</label></div></li></ul></div><div class="pcb__buttons pcb__popup__buttons"><button type="button" class="pcb__btn pcb__btn--solid pcb__btn--accept">Accept all</button> <button type="button" class="pcb__btn pcb__btn--reject">Reject all</button> <button type="button" class="pcb__btn pcb__btn--save">Save settings</button></div></div></div></div><div class="pcb__overlay" aria-hidden="true"></div><button class="pcb__badge" aria-label="Cookie Policy" aria-hidden="true"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" width="40" height="40" viewBox="0 0 23 23" fill="currentColor"><path d="M21.41 12.71c-.08-.01-.15 0-.22 0h-.03c-.03 0-.05 0-.08.01-.07 0-.13.01-.19.04-.52.21-1.44.19-2.02-.22-.44-.31-.65-.83-.62-1.53a.758.758 0 0 0-.27-.61.73.73 0 0 0-.65-.14c-1.98.51-3.49.23-4.26-.78-.82-1.08-.73-2.89.24-4.49.14-.23.14-.52 0-.75a.756.756 0 0 0-.67-.36c-.64.03-1.11-.1-1.31-.35-.19-.26-.13-.71-.01-1.29.04-.18.06-.38.03-.59-.05-.4-.4-.7-.81-.66C5.1 1.54 1 6.04 1 11.48 1 17.28 5.75 22 11.6 22c5.02 0 9.39-3.54 10.39-8.42.08-.4-.18-.78-.58-.87Zm-9.81 7.82c-5.03 0-9.12-4.06-9.12-9.06 0-4.34 3.05-8 7.25-8.86-.08.7.05 1.33.42 1.81.24.32.66.67 1.38.84-.76 1.86-.65 3.78.36 5.11.61.81 2.03 2 4.95 1.51.18.96.71 1.54 1.18 1.87.62.43 1.38.62 2.1.62.05 0 .09 0 .13-.01-1.23 3.64-4.7 6.18-8.64 6.18ZM13 17c0 .55-.45 1-1 1s-1-.45-1-1 .45-1 1-1 1 .45 1 1Zm5.29-12.3a.99.99 0 0 1-.29-.71c0-.55.45-.99 1-.99a1 1 0 0 1 .71.3c.19.19.29.44.29.71 0 .55-.45.99-1 .99a1 1 0 0 1-.71-.3ZM9 13.5c0 .83-.67 1.5-1.5 1.5S6 14.33 6 13.5 6.67 12 7.5 12s1.5.67 1.5 1.5Zm3.25.81a.744.744 0 0 1-.06-1.05c.28-.32.75-.34 1.05-.06.31.28.33.75.05 1.06-.15.16-.35.25-.56.25-.18 0-.36-.06-.5-.19ZM8.68 7.26c.41.37.44 1 .07 1.41-.2.22-.47.33-.75.33a.96.96 0 0 1-.67-.26c-.41-.37-.44-1-.07-1.41.37-.42 1-.45 1.41-.08Zm11.48 1.88c.18-.19.52-.19.7 0 .05.04.09.1.11.16.03.06.04.12.04.19 0 .13-.05.26-.15.35-.09.1-.22.15-.35.15s-.26-.05-.35-.15a.355.355 0 0 1-.11-.16.433.433 0 0 1-.04-.19c0-.13.05-.26.15-.35Zm-4.93-1.86a.75.75 0 1 1 1.059-1.06.75.75 0 0 1-1.059 1.06Z"/></svg></button></div><script>(function(win) {
    if (!document.querySelector('.pcb')) {
        return;
    }

    var cbConfig = {
        behaviour: document.querySelector('.pcb').getAttribute('data-behaviour'),
        behaviourLink: document.querySelector('.pcb').getAttribute('data-behaviour-link'),
        revision: document.querySelector('.pcb').getAttribute('data-revision'),
        configTTL: parseInt(document.querySelector('.pcb').getAttribute('data-config-ttl'), 10),
        debugMode: document.querySelector('.pcb').getAttribute('data-debug-mode') === 'true',
        initialState: null,
        initialLsState: null,
        previouslyAccepted: []
    };

    var cbUI = {
        wrapper: document.querySelector('.pcb'),
        banner: {
            element: null,
            btnAccept: null,
            btnReject: null,
            btnConfigure: null
        },
        popup: {
            element: null,
            btnClose: null,
            btnSave: null,
            btnAccept: null,
            btnReject: null,
            checkboxes: null,
        },
        overlay: null,
        badge: null,
        blockedScripts: document.querySelectorAll('script[type^="gdpr-blocker/"]'),
        triggerLinks: cbConfig.behaviourLink ? document.querySelectorAll('a[href*="' + cbConfig.behaviourLink + '"]') : null
    };

    function initUI () {
        // setup banner elements
        cbUI.banner.element = cbUI.wrapper.querySelector('.pcb__banner');
        cbUI.banner.btnAccept = cbUI.banner.element.querySelector('.pcb__btn--accept');
        cbUI.banner.btnReject = cbUI.banner.element.querySelector('.pcb__btn--reject');
        cbUI.banner.btnConfigure = cbUI.banner.element.querySelector('.pcb__btn--configure');

        // setup popup elements
        if (cbUI.wrapper.querySelector('.pcb__popup')) {
            cbUI.popup.element = cbUI.wrapper.querySelector('.pcb__popup');
            cbUI.popup.btnClose = cbUI.wrapper.querySelector('.pcb__popup__close');
            cbUI.popup.btnSave = cbUI.popup.element.querySelector('.pcb__btn--save');
            cbUI.popup.btnAccept = cbUI.popup.element.querySelector('.pcb__btn--accept');
            cbUI.popup.btnReject = cbUI.popup.element.querySelector('.pcb__btn--reject');
            cbUI.popup.checkboxes = cbUI.popup.element.querySelector('input[type="checkbox"]');
            // setup overlay
            cbUI.overlay = cbUI.wrapper.querySelector('.pcb__overlay');
        }

        cbUI.badge = cbUI.wrapper.querySelector('.pcb__badge');

        if (cbConfig.behaviour.indexOf('link') > -1) {
            for (var i = 0; i < cbUI.triggerLinks.length; i++) {
                cbUI.triggerLinks[i].addEventListener('click', function(e) {
                    e.preventDefault();
                    showBannerOrPopup();
                });
            }
        }
    }

    function initState () {
        var lsKeyName = getConfigName();
        var currentConfig = localStorage.getItem(lsKeyName);
        var configIsFresh = checkIfConfigIsFresh();

        if (!configIsFresh || currentConfig === null) {
            if (cbConfig.debugMode) {
                console.log('🍪 Config not found, or configuration expired');
            }

            if (window.publiiCBGCM) {
                gtag('consent', 'default', {
                    'ad_storage': window.publiiCBGCM.defaultState.ad_storage ? 'granted' : 'denied',
                    'ad_personalization': window.publiiCBGCM.defaultState.ad_personalization ? 'granted' : 'denied',
                    'ad_user_data': window.publiiCBGCM.defaultState.ad_user_data ? 'granted' : 'denied',
                    'analytics_storage': window.publiiCBGCM.defaultState.analytics_storage ? 'granted' : 'denied',
                    'personalization_storage': window.publiiCBGCM.defaultState.personalization_storage ? 'granted' : 'denied',
                    'functionality_storage': window.publiiCBGCM.defaultState.functionality_storage ? 'granted' : 'denied',
                    'security_storage': window.publiiCBGCM.defaultState.security_storage ? 'granted' : 'denied'
                });  
                
                if (cbConfig.debugMode) {
                    console.log('🍪 GCMv2 DEFAULT STATE: ' + JSON.stringify({
                        'ad_storage': window.publiiCBGCM.defaultState.ad_storage ? 'granted' : 'denied',
                        'ad_personalization': window.publiiCBGCM.defaultState.ad_personalization ? 'granted' : 'denied',
                        'ad_user_data': window.publiiCBGCM.defaultState.ad_user_data ? 'granted' : 'denied',
                        'analytics_storage': window.publiiCBGCM.defaultState.analytics_storage ? 'granted' : 'denied',
                        'personalization_storage': window.publiiCBGCM.defaultState.personalization_storage ? 'granted' : 'denied',
                        'functionality_storage': window.publiiCBGCM.defaultState.functionality_storage ? 'granted' : 'denied',
                        'security_storage': window.publiiCBGCM.defaultState.security_storage ? 'granted' : 'denied'
                    }));
                }
            }

            showBanner();
        } else if (typeof currentConfig === 'string') {
            if (cbConfig.debugMode) {
                console.log('🍪 Config founded');
            }

            cbConfig.initialLsState = currentConfig.split(',');

            if (window.publiiCBGCM) {
                gtag('consent', 'default', {
                    'ad_storage': getDefaultConsentState(currentConfig, 'ad_storage'),
                    'ad_personalization': getDefaultConsentState(currentConfig, 'ad_personalization'),
                    'ad_user_data': getDefaultConsentState(currentConfig, 'ad_user_data'),
                    'analytics_storage': getDefaultConsentState(currentConfig, 'analytics_storage'),
                    'personalization_storage': getDefaultConsentState(currentConfig, 'personalization_storage'),
                    'functionality_storage': getDefaultConsentState(currentConfig, 'functionality_storage'),
                    'security_storage': getDefaultConsentState(currentConfig, 'security_storage')
                });
                
                if (cbConfig.debugMode) {
                    console.log('🍪 GCMv2 DEFAULT STATE: ' + JSON.stringify({
                        'ad_storage': getDefaultConsentState(currentConfig, 'ad_storage'),
                        'ad_personalization': getDefaultConsentState(currentConfig, 'ad_personalization'),
                        'ad_user_data': getDefaultConsentState(currentConfig, 'ad_user_data'),
                        'analytics_storage': getDefaultConsentState(currentConfig, 'analytics_storage'),
                        'personalization_storage': getDefaultConsentState(currentConfig, 'personalization_storage'),
                        'functionality_storage': getDefaultConsentState(currentConfig, 'functionality_storage'),
                        'security_storage': getDefaultConsentState(currentConfig, 'security_storage')
                    }));
                }
            }

            showBadge();

            if (cbUI.popup.element) {
                var allowedGroups = currentConfig.split(',');
                var checkedCheckboxes = cbUI.popup.element.querySelectorAll('input[type="checkbox"]:checked');

                for (var j = 0; j < checkedCheckboxes.length; j++) {
                    var name = checkedCheckboxes[j].getAttribute('data-group-name');

                    if (name && name !== '-' && allowedGroups.indexOf(name) === -1) {
                        checkedCheckboxes[j].checked = false;
                    }
                }

                for (var i = 0; i < allowedGroups.length; i++) {
                    var checkbox = cbUI.popup.element.querySelector('input[type="checkbox"][data-group-name="' + allowedGroups[i] + '"]');

                    if (checkbox) {
                        checkbox.checked = true;
                    }

                    allowCookieGroup(allowedGroups[i]);
                }
            }
        }

        setTimeout(function () {
            cbConfig.initialState = getInitialStateOfConsents();
        }, 0);
    }

    function checkIfConfigIsFresh () {
        var lastConfigSave = localStorage.getItem('publii-gdpr-cookies-config-save-date');

        if (lastConfigSave === null) {
            return false;
        }

        lastConfigSave = parseInt(lastConfigSave, 10);

        if (lastConfigSave === 0) {
            return true;
        }

        if (+new Date() - lastConfigSave < cbConfig.configTTL * 24 * 60 * 60 * 1000) {
            return true;
        }

        return false;
    }

    function getDefaultConsentState (currentConfig, consentGroup) {
        let configGroups = currentConfig.split(',');

        for (let i = 0; i < configGroups.length; i++) {
            let groupName = configGroups[i];
            let group = window.publiiCBGCM.groups.find(group => group.cookieGroup === groupName);

            if (group && group[consentGroup]) {
                return 'granted';
            }
        }  
        
        if (window.publiiCBGCM.defaultState[consentGroup]) {
            return 'granted'; 
        }
        
        return 'denied';
    }

    function initBannerEvents () {
        cbUI.banner.btnAccept.addEventListener('click', function (e) {
            e.preventDefault();
            acceptAllCookies('banner');
            showBadge();
        }, false);

        if (cbUI.banner.btnReject) {
            cbUI.banner.btnReject.addEventListener('click', function (e) {
                e.preventDefault();
                rejectAllCookies();
                showBadge();
            }, false);
        }

        if (cbUI.banner.btnConfigure) {
            cbUI.banner.btnConfigure.addEventListener('click', function (e) {
                e.preventDefault();
                hideBanner();
                showAdvancedPopup();
                showBadge();
            }, false);
        }
    }

    function initPopupEvents () {
        if (!cbUI.popup.element) {
            return;
        }

        cbUI.overlay.addEventListener('click', function (e) {
            hideAdvancedPopup();
        }, false);

        cbUI.popup.element.addEventListener('click', function (e) {
            e.stopPropagation();
        }, false);

        cbUI.popup.btnAccept.addEventListener('click', function (e) {
            e.preventDefault();
            acceptAllCookies('popup');
        }, false);

        cbUI.popup.btnReject.addEventListener('click', function (e) {
            e.preventDefault();
            rejectAllCookies();
        }, false);

        cbUI.popup.btnSave.addEventListener('click', function (e) {
            e.preventDefault();
            saveConfiguration();
        }, false);

        cbUI.popup.btnClose.addEventListener('click', function (e) {
            e.preventDefault();
            hideAdvancedPopup();
        }, false);
    }

    function initBadgeEvents () {
        if (!cbUI.badge) {
            return;
        }

        cbUI.badge.addEventListener('click', function (e) {
            showBannerOrPopup();
        }, false);
    }

    initUI();
    initState();
    initBannerEvents();
    initPopupEvents();
    initBadgeEvents();

    /**
     * API
     */
    function addScript (src, inline) {
        var newScript = document.createElement('script');

        if (src) {
            newScript.setAttribute('src', src);
        }

        if (inline) {
            newScript.text = inline;
        }

        document.body.appendChild(newScript);
    }

    function allowCookieGroup (allowedGroup) {
        var scripts = document.querySelectorAll('script[type="gdpr-blocker/' + allowedGroup + '"]');
        cbConfig.previouslyAccepted.push(allowedGroup);
    
        for (var j = 0; j < scripts.length; j++) {
            addScript(scripts[j].src, scripts[j].text);
        }

        var groupEvent = new Event('publii-cookie-banner-unblock-' + allowedGroup);
        document.body.dispatchEvent(groupEvent);
        unlockEmbeds(allowedGroup);

        if (cbConfig.debugMode) {
            console.log('🍪 Allowed group: ' + allowedGroup);
        }

        if (window.publiiCBGCM && (!cbConfig.initialLsState || cbConfig.initialLsState.indexOf(allowedGroup) === -1)) {
            let consentResult = {};
            let group = window.publiiCBGCM.groups.find(group => group.cookieGroup === allowedGroup);

            if (group) {
                let foundSomeConsents = false;

                Object.keys(group).forEach(key => {
                    if (key !== 'cookieGroup' && group[key] === true) {
                        consentResult[key] = 'granted';
                        foundSomeConsents = true;
                    }
                });

                if (foundSomeConsents) {
                    gtag('consent', 'update', consentResult);   

                    if (cbConfig.debugMode) {
                        console.log('🍪 GCMv2 UPDATE: ' + JSON.stringify(consentResult));
                    }
                }
            }
        }
    }

    function showBannerOrPopup () {
        if (cbUI.popup.element) {
            showAdvancedPopup();
        } else {
            showBanner();
        }
    }

    function showAdvancedPopup () {
        cbUI.popup.element.classList.add('is-visible');
        cbUI.overlay.classList.add('is-visible');
        cbUI.popup.element.setAttribute('aria-hidden', 'false');
        cbUI.overlay.setAttribute('aria-hidden', 'false');
    }

    function hideAdvancedPopup () {
        cbUI.popup.element.classList.remove('is-visible');
        cbUI.overlay.classList.remove('is-visible');
        cbUI.popup.element.setAttribute('aria-hidden', 'true');
        cbUI.overlay.setAttribute('aria-hidden', 'true');
    }

    function showBanner () {
        cbUI.banner.element.classList.add('is-visible');
        cbUI.banner.element.setAttribute('aria-hidden', 'false');
    }

    function hideBanner () {
        cbUI.banner.element.classList.remove('is-visible');
        cbUI.banner.element.setAttribute('aria-hidden', 'true');
    }

    function showBadge () {
        if (!cbUI.badge) {
            return;
        }

        cbUI.badge.classList.add('is-visible');
        cbUI.badge.setAttribute('aria-hidden', 'false');
    }

    function getConfigName () {
        var lsKeyName = 'publii-gdpr-allowed-cookies';

        if (cbConfig.revision) {
            lsKeyName = lsKeyName + '-v' + parseInt(cbConfig.revision, 10);
        }

        return lsKeyName;
    }

    function storeConfiguration (allowedGroups) {
        var lsKeyName = getConfigName();
        var dataToStore = allowedGroups.join(',');
        localStorage.setItem(lsKeyName, dataToStore);

        if (cbConfig.configTTL === 0) {
            localStorage.setItem('publii-gdpr-cookies-config-save-date', 0);

            if (cbConfig.debugMode) {
                console.log('🍪 Store never expiring configuration');
            }
        } else {
            localStorage.setItem('publii-gdpr-cookies-config-save-date', +new Date());
        }
    }

    function getInitialStateOfConsents () {
        if (!cbUI.popup.element) {
            return [];
        }

        var checkedGroups = cbUI.popup.element.querySelectorAll('input[type="checkbox"]:checked');
        var groups = [];

        for (var i = 0; i < checkedGroups.length; i++) {
            var allowedGroup = checkedGroups[i].getAttribute('data-group-name');

            if (allowedGroup !== '') {
                groups.push(allowedGroup);
            }
        }

        if (cbConfig.debugMode) {
            console.log('🍪 Initial state: ' + groups.join(', '));
        }

        return groups;
    }

    function getCurrentStateOfConsents () {
        if (!cbUI.popup.element) {
            return [];
        }

        var checkedGroups = cbUI.popup.element.querySelectorAll('input[type="checkbox"]:checked');
        var groups = [];

        for (var i = 0; i < checkedGroups.length; i++) {
            var allowedGroup = checkedGroups[i].getAttribute('data-group-name');

            if (allowedGroup !== '') {
                groups.push(allowedGroup);
            }
        }

        if (cbConfig.debugMode) {
            console.log('🍪 State to save: ' + groups.join(', '));
        }

        return groups;
    }

    function getAllGroups () {
        if (!cbUI.popup.element) {
            return [];
        }

        var checkedGroups = cbUI.popup.element.querySelectorAll('input[type="checkbox"]');
        var groups = [];

        for (var i = 0; i < checkedGroups.length; i++) {
            var allowedGroup = checkedGroups[i].getAttribute('data-group-name');

            if (allowedGroup !== '') {
                groups.push(allowedGroup);
            }
        }

        return groups;
    }

    function acceptAllCookies (source) {
        var groupsToAccept = getAllGroups();
        storeConfiguration(groupsToAccept);

        for (var i = 0; i < groupsToAccept.length; i++) {
            var group = groupsToAccept[i];

            if (cbConfig.initialState.indexOf(group) > -1 || cbConfig.previouslyAccepted.indexOf(group) > -1) {
                if (cbConfig.debugMode) {
                    console.log('🍪 Skip previously activated group: ' + group);
                }

                continue;
            }

            allowCookieGroup(group);
        }

        if (cbUI.popup.element) {
            var checkboxesToCheck = cbUI.popup.element.querySelectorAll('input[type="checkbox"]');

            for (var j = 0; j < checkboxesToCheck.length; j++) {
                checkboxesToCheck[j].checked = true;
            }
        }

        if (cbConfig.debugMode) {
            console.log('🍪 Accept all cookies: ', groupsToAccept.join(', '));
        }

        if (source === 'popup') {
            hideAdvancedPopup();
        } else if (source === 'banner') {
            hideBanner();
        }
    }

    function rejectAllCookies () {
        if (cbConfig.debugMode) {
            console.log('🍪 Reject all cookies');
        }

        storeConfiguration([]);
        setTimeout(function () {
            window.location.reload();
        }, 100);
    }

    function saveConfiguration () {
        var groupsToAccept = getCurrentStateOfConsents();
        storeConfiguration(groupsToAccept);

        if (cbConfig.debugMode) {
            console.log('🍪 Save new config: ', groupsToAccept.join(', '));
        }

        if (reloadIsNeeded(groupsToAccept)) {
            setTimeout(function () {
                window.location.reload();
            }, 100);
            return;
        }

        for (var i = 0; i < groupsToAccept.length; i++) {
            var group = groupsToAccept[i];

            if (cbConfig.initialState.indexOf(group) > -1 || cbConfig.previouslyAccepted.indexOf(group) > -1) {
                if (cbConfig.debugMode) {
                    console.log('🍪 Skip previously activated group: ' + group);
                }

                continue;
            }

            allowCookieGroup(group);
        }

        hideAdvancedPopup();
    }

    function reloadIsNeeded (groupsToAccept) {
        // check if user rejected consent for initial groups
        var initialGroups = cbConfig.initialState;
        var previouslyAcceptedGroups = cbConfig.previouslyAccepted;
        var groupsToCheck = initialGroups.concat(previouslyAcceptedGroups);

        for (var i = 0; i < groupsToCheck.length; i++) {
            var groupToCheck = groupsToCheck[i];

            if (groupToCheck !== '' && groupsToAccept.indexOf(groupToCheck) === -1) {
                if (cbConfig.debugMode) {
                    console.log('🍪 Reload is needed due lack of: ', groupToCheck);
                }

                return true;
            }
        }

        return false;
    }

    function unlockEmbeds (cookieGroup) {
        var iframesToUnlock = document.querySelectorAll('.pec-wrapper[data-consent-group-id="' + cookieGroup + '"]');

        for (var i = 0; i < iframesToUnlock.length; i++) {
            var iframeWrapper = iframesToUnlock[i];
            iframeWrapper.querySelector('.pec-overlay').classList.remove('is-active');
            iframeWrapper.querySelector('.pec-overlay').setAttribute('aria-hidden', 'true');
            var iframe = iframeWrapper.querySelector('iframe');
            iframe.setAttribute('src', iframe.getAttribute('data-consent-src'));
        }
    }

    win.publiiEmbedConsentGiven = function (cookieGroup) {
        // it will unlock embeds
        allowCookieGroup(cookieGroup);

        var checkbox = cbUI.popup.element.querySelector('input[type="checkbox"][data-group-name="' + cookieGroup + '"]');

        if (checkbox) {
            checkbox.checked = true;
        }

        var groupsToAccept = getCurrentStateOfConsents();
        storeConfiguration(groupsToAccept);

        if (cbConfig.debugMode) {
            console.log('🍪 Save new config: ', groupsToAccept.join(', '));
        }
    }
})(window);</script></body></html>