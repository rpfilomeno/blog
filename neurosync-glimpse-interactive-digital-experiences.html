<!DOCTYPE html><html lang="en-us"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>NeuroSync: Glimpse Interactive Digital Experiences - Ai.2.mations</title><meta name="description" content="NeuroSync: The Future of Interactive Digital Experiences is Here Get ready for a revolution in digital interaction! This blog post dives into the exciting world of NeuroSync, an open-source project poised to redefine how we experience interactive games, digital avatars, and even streaming content. Prepare&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://roger.rogverse.fyi/neurosync-glimpse-interactive-digital-experiences.html"><link rel="alternate" type="application/atom+xml" href="https://roger.rogverse.fyi/feed.xml" title="Ai.2.mations - RSS"><link rel="alternate" type="application/json" href="https://roger.rogverse.fyi/feed.json" title="Ai.2.mations - JSON"><meta property="og:title" content="NeuroSync: Glimpse Interactive Digital Experiences"><meta property="og:image" content="https://roger.rogverse.fyi/media/posts/9/neurosync-2.jpg"><meta property="og:image:width" content="2529"><meta property="og:image:height" content="1379"><meta property="og:site_name" content="Ai.2.mations"><meta property="og:description" content="NeuroSync: The Future of Interactive Digital Experiences is Here Get ready for a revolution in digital interaction! This blog post dives into the exciting world of NeuroSync, an open-source project poised to redefine how we experience interactive games, digital avatars, and even streaming content. Prepare&hellip;"><meta property="og:url" content="https://roger.rogverse.fyi/neurosync-glimpse-interactive-digital-experiences.html"><meta property="og:type" content="article"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@godie"><meta name="twitter:title" content="NeuroSync: Glimpse Interactive Digital Experiences"><meta name="twitter:description" content="NeuroSync: The Future of Interactive Digital Experiences is Here Get ready for a revolution in digital interaction! This blog post dives into the exciting world of NeuroSync, an open-source project poised to redefine how we experience interactive games, digital avatars, and even streaming content. Prepare&hellip;"><meta name="twitter:image" content="https://roger.rogverse.fyi/media/posts/9/neurosync-2.jpg"><link rel="stylesheet" href="https://roger.rogverse.fyi/assets/css/style.css?v=2d788153c912d3afda77a06fe119f1e4"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://roger.rogverse.fyi/neurosync-glimpse-interactive-digital-experiences.html"},"headline":"NeuroSync: Glimpse Interactive Digital Experiences","datePublished":"2025-04-07T11:20+08:00","dateModified":"2025-04-07T15:05+08:00","image":{"@type":"ImageObject","url":"https://roger.rogverse.fyi/media/posts/9/neurosync-2.jpg","height":1379,"width":2529},"description":"NeuroSync: The Future of Interactive Digital Experiences is Here Get ready for a revolution in digital interaction! This blog post dives into the exciting world of NeuroSync, an open-source project poised to redefine how we experience interactive games, digital avatars, and even streaming content. Prepare&hellip;","author":{"@type":"Person","name":"Roger Filomeno","url":"https://roger.rogverse.fyi/authors/roger-filomeno/"},"publisher":{"@type":"Organization","name":"Roger Filomeno"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-VLXN0Y9Q0W"></script><script>window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-VLXN0Y9Q0W');</script></head><body class="post-template"><div class="container js-container"><nav class="menu"><ul class="navbar__menu"><li><a href="https://roger.rogverse.fyi/" title="Home" target="_self">Home</a></li><li><a href="https://roger.rogverse.fyi/work.html" title="Work" target="_self">Work</a></li><li><a href="https://roger.rogverse.fyi/3d-projects-2.html" target="_self">3D Projects</a></li><li><a href="https://roger.rogverse.fyi/tags/" title="tags" target="_self">Tags</a></li><li><a href="https://roger.rogverse.fyi/tags/blog/" title="log" target="_self">Blog</a></li></ul></nav><div class="container__content"><header class="top"><div class="top__item"><a class="logo" href="https://roger.rogverse.fyi/">Ai.2.mations</a></div><div class="top__item top__item--right"><button class="menu-toggle js-menu-toggle" aria-label="Menu" aria-expanded="false"><span class="menu-toggle-box"><span class="menu-toggle-inner">Menu</span></span></button></div></header><main class="main post"><article class="content"><div class="main__left"><figure class="hero"><img src="https://roger.rogverse.fyi/media/posts/9/neurosync-2.jpg" srcset="https://roger.rogverse.fyi/media/posts/9/responsive/neurosync-2-xs.webp 300w, https://roger.rogverse.fyi/media/posts/9/responsive/neurosync-2-sm.webp 480w, https://roger.rogverse.fyi/media/posts/9/responsive/neurosync-2-md.webp 768w, https://roger.rogverse.fyi/media/posts/9/responsive/neurosync-2-lg.webp 1024w, https://roger.rogverse.fyi/media/posts/9/responsive/neurosync-2-xl.webp 1280w, https://roger.rogverse.fyi/media/posts/9/responsive/neurosync-2-2xl.webp 1600w" sizes="(min-width: 1800px) 50vw, (min-width: 900px) 40vw, 100vw" loading="eager" height="1379" width="2529" alt=""></figure><header><h1>NeuroSync: Glimpse Interactive Digital Experiences</h1><p><time datetime="2025-04-07T11:20">April 7, 2025 </time>by <a href="https://roger.rogverse.fyi/authors/roger-filomeno/" rel="author" title="Roger Filomeno">Roger Filomeno</a></p></header></div><div class="main__right"><div class="content__entry"><h1 id="neurosync-the-future-of-interactive-digital-experiences-is-here">NeuroSync: The Future of Interactive Digital Experiences is Here</h1><p>Get ready for a revolution in digital interaction! This blog post dives into the exciting world of <a href="https://neurosync.info/">NeuroSync</a>, an open-source project poised to redefine how we experience interactive games, digital avatars, and even streaming content. Prepare to have your perception of reality in the digital realm challenged!</p><h2 id="the-quest-for-believable-digital-avatars">The Quest for Believable Digital Avatars</h2><p>We’re constantly seeking more immersive and dynamic digital experiences. Whether it’s diving into a new game, exploring the metaverse, or connecting on social media, the believability of digital avatars is key. Realistic facial animation, with all its subtle nuances, is crucial for conveying emotions and creating genuine engagement. Historically, this has been a complex and labor-intensive process. But now, <a href="https://huggingface.co/AnimaVR/NEUROSYNC_Audio_To_Face_Blendshape">NeuroSync</a> is stepping onto the scene to change the game.</p><p></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/inzoi.jpg" alt="Digital Avatar" data-is-external-image="true"></figure><em>INZOI a glimpse into the world of digital avatars.</em><p></p><h2 id="neurosync-unlocking-real-time-facial-animation-in-unreal-engine-5">NeuroSync: Unlocking Real-Time Facial Animation in Unreal Engine 5</h2><p>NeuroSync is an open-source marvel that allows for the real-time streaming of facial blendshapes into the powerful <a href="https://www.unrealengine.com/en-US/">Unreal Engine 5</a> using audio input. Let’s break down how this works:</p><h3 id="detailed-technical-overview">Detailed Technical Overview</h3><p>At its core, NeuroSync utilizes a sophisticated transformer seq2seq model. This model cleverly translates audio features into facial blendshape coefficients in real-time, making digital characters’ faces move in sync with their speech and even express emotions.</p><h3 id="the-power-of-the-local-api">The Power of the Local API</h3><p>For developers who crave control and minimal lag, NeuroSync offers a <a href="https://github.com/AnimaVR/NeuroSync_Local_API">Local API</a>. This allows you to host the pre-trained audio-to-face model on your own hardware, giving you complete command over the animation process and potentially reducing latency.</p><h3 id="seamless-integration-with-unreal-engine-5">Seamless Integration with Unreal Engine 5</h3><p>Integrating NeuroSync into Unreal Engine 5 is a breeze thanks to the <a href="https://docs.unrealengine.com/5.3/en-US/livelink-in-unreal-engine/">LiveLink API</a>. The <a href="https://github.com/AnimaVR/NeuroSync_Player">NeuroSync Player</a> acts as the bridge, streaming the animation data directly into the engine. It leverages Apple’s ARKit blendshapes for a wide range of realistic facial movements.</p><h3 id="continuous-improvement">Continuous Improvement</h3><p><a href="https://youtu.be/iqzbrE7KV_M?si=pw4LWBluneJRI57i">NeuroSync</a> is constantly evolving. Recent updates, like the one on February 4, 2025, have brought significant improvements in timing accuracy and the naturalness of expressions, especially in areas like brows, cheeks, and mouth shapes. Another update on March 29, 2025, further enhanced accuracy and smoothness through refined training data and model architecture.</p><p></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/thorium_m0BM7Eu1AP.png" alt="NeuroSync in Unreal Engine 5" data-is-external-image="true"></figure><em>NeuroSync seamlessly integrates with Unreal Engine 5</em><p></p><h2 id="the-power-couple-neurosync-and-multimodal-llms-in-interactive-games">The Power Couple: NeuroSync and Multimodal LLMs in Interactive Games</h2><p>Imagine combining NeuroSync’s realistic facial animation with the intelligence of multimodal Large Language Models (LLMs). This synergy could lead to truly revolutionary interactive gaming experiences.</p><h3 id="beyond-text-multimodal-llms-understand-the-game">Beyond Text: Multimodal LLMs Understand the Game</h3><p>Multimodal LLMs can process various forms of data, including text, images, and audio. This allows them to understand the game’s context and the player’s input in a much richer way than traditional text-based LLMs. They can interpret visual cues, spoken dialogue, and even the overall game environment to create more intelligent and responsive NPCs.</p><h3 id="bringing-characters-to-life-with-expressive-animation">Bringing Characters to Life with Expressive Animation</h3><p>NeuroSync provides the visual expressiveness that complements the intelligence of MLLMs. While an MLLM can generate smart dialogue, NeuroSync animates the character’s face in real-time, synchronized with the speech. This creates incredibly believable and relatable virtual characters.</p><h3 id="the-future-is-now-existing-integrations">The Future is Now: Existing Integrations</h3><p>The integration of LLMs with game engines is already being explored. Projects like <a href="https://arxiv.org/html/2309.12276v2">LLMR (Large Language Model for Mixed Reality)</a> and <a href="https://www.immersivecomputinglab.org/wp-content/uploads/2024/08/2024-ISMAR-AgentBehaviorGeneration.pdf">VIVRA (Voice Interactive Virtual Reality Annotation)</a> showcase the potential of LLMs in creating dynamic and interactive virtual worlds. The <a href="https://github.com/AkshitIreddy/Interactive-LLM-Powered-NPCs">Interactive LLM Powered NPCs</a> project even aims to revolutionize NPC interactions in existing games using AI for dialogue and facial animation.</p><p></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/graphic-features-supported-convai-1.png" alt="LLM Powered NPC" data-is-external-image="true"></figure><em>Intelligent NPCs powered by LLMs.</em><p></p><h2 id="neurosync-and-metas-vision-digital-twins-and-ai-influencers">NeuroSync and Meta’s Vision: Digital Twins and AI Influencers</h2><p>Tech giant Meta is heavily invested in the metaverse and the creation of realistic digital twins and engaging AI influencers. NeuroSync could play a vital role in bringing these digital entities to life.</p><h3 id="metas-ambitious-plans">Meta’s Ambitious Plans</h3><p>Meta envisions a future where digital twins accurately represent real-world individuals in the metaverse. Engaging AI influencers would also require highly realistic and expressive avatars.</p><h3 id="enhancing-visual-fidelity-and-emotional-expression">Enhancing Visual Fidelity and Emotional Expression</h3><p>NeuroSync’s real-time audio-to-facial animation can significantly contribute to the visual fidelity and emotional expressiveness of these Meta-driven avatars. The ability to generate nuanced facial expressions directly from audio will make digital twins and AI influencers feel more alive and believable.</p><h3 id="potential-for-collaboration">Potential for Collaboration</h3><p>The synergy between NeuroSync and Meta’s goals opens up exciting possibilities for collaboration. Meta could integrate NeuroSync’s technology to enhance its avatar creation process, and the open-source nature of NeuroSync could benefit from the scale and resources of Meta’s platforms.</p><p></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/Zucc_pgzaxw.jpg" alt="Metaverse Avatars" data-is-external-image="true"></figure><em>Realistic avatars in the metaverse.</em><p></p><h2 id="blurring-reality-neurosync-unreal-engine-5-and-streaming-content">Blurring Reality: NeuroSync, Unreal Engine 5, and Streaming Content</h2><p>The combination of NeuroSync and Unreal Engine 5’s incredible rendering capabilities could lead to a future where it’s hard to distinguish between computer-generated graphics and reality in streaming content.</p><h3 id="unreal-engine-5-a-master-of-photorealism">Unreal Engine 5: A Master of Photorealism</h3><p>Unreal Engine 5 is renowned for its ability to create stunningly photorealistic visuals in real-time. Games like Unrecord and Bodycam (while not explicitly detailed in the provided snippets, their visual fidelity is well-known) showcase the engine’s power to produce graphics that can often be mistaken for real life.</p><h3 id="elevating-ai-avatars-in-live-streaming">Elevating AI Avatars in Live Streaming</h3><p>When you pair UE5’s visual prowess with NeuroSync’s lifelike facial animation, AI avatars in live streaming scenarios can reach unprecedented levels of realism. Imagine AI streamers that not only look incredibly real but also speak and emote with natural facial expressions. This could truly blur the lines between virtual and human content creators.</p><p></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/Unreal+Engine_spotlights_meet-vincent-a-real-time-digital-human-created-in-house-by-a-team-of-just-five_Spotlight_Giantstep_blog_body_img2-1640x1000-fcfc6112efbd1cceabc7687e7fb4d456276791f8.jpg" alt="Unreal Engine 5 Realism" data-is-external-image="true"></figure><em>Meet Vincent: a real-time digital human. The photorealistic power of Unreal Engine 5.</em><p></p><h2 id="the-rise-of-ai-digital-personalities-surpassing-humans">The Rise of AI Digital Personalities: Surpassing Humans?</h2><p>The emergence of AI digital personalities, such as the popular AI Vtubers Neurosama and Codemiko, raises the question: could AI eventually surpass human creators in online interactions?</p><h3 id="neurosama-and-codemiko-the-ai-vtubing-phenomenon">Neurosama and Codemiko: The AI Vtubing Phenomenon</h3><p><a href="https://en.wikipedia.org/wiki/Neuro-sama">Neurosama</a> is an AI VTuber and chatbot on Twitch, created by developer Vedal. She uses a large language model to generate human-like responses and has gained a massive following, even breaking <a href="https://streamscharts.com/news/vedals-ai-vtuber-neuro-twitch-hype-train-record">Twitch’s Hype Train record</a>. <a href="https://en.wikipedia.org/wiki/CodeMiko">Codemiko</a>, on the other hand, is a VTuber known for her unique glitchy aesthetic and highly interactive streams. Behind the avatar is a real person, Youna Kang (The Technician), who uses motion capture and Unreal Engine to bring Codemiko to life.</p><h3 id="why-are-they-so-popular">Why Are They So Popular?</h3><p>Neurosama’s success is partly due to the novelty of interacting with an AI, while Codemiko’s appeal lies in her unique character and high level of interactivity. Both demonstrate that engaging digital personalities, whether fully AI-driven or human-controlled with advanced avatars, can captivate online audiences.</p><h3 id="ai-vs-humans-the-great-debate">AI vs. Humans: The Great Debate</h3><p>Could AI digital personalities truly surpass human creators? While AI offers advantages like 24/7 availability and scalability, it currently lacks the genuine emotions and lived experiences that drive deep human connection. It’s more likely that AI will become a powerful tool that complements human creativity rather than replacing it entirely.</p><p></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/Neuro-sama-20231106-1.webp" alt="AI VTuber" data-is-external-image="true"></figure><em>AI VTubers like Neurosama are gaining popularity.</em><p></p><p></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/thorium_9XrxXIYuJO-ezgif.com-cut.gif" alt="Codemiko" data-is-external-image="true"></figure><em>Codemiko, known for her interactive streams.</em><p></p><h2 id="conclusion-embracing-the-future-of-interactive-media">Conclusion: Embracing the Future of Interactive Media</h2><p>NeuroSync, in conjunction with the power of multimodal LLMs and the stunning visuals of Unreal Engine 5, is paving the way for a truly transformative era in interactive media. From more engaging games and realistic digital avatars to the potential blurring of lines in streaming content, the possibilities are immense. While AI digital personalities are making waves, the unique essence of human creativity will likely ensure a future where both AI and human creators thrive, offering diverse and enriching digital experiences.</p><footer><div class="content__tag-share"><ul class="content__tag"><li><a href="https://roger.rogverse.fyi/tags/ai/">AI</a></li><li><a href="https://roger.rogverse.fyi/tags/blog/">Blog</a></li></ul><div class="content__share"><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Froger.rogverse.fyi%2Fneurosync-glimpse-interactive-digital-experiences.html" class="js-share facebook" aria-label="Share with Facebook" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://roger.rogverse.fyi/assets/svg/svg-map.svg#facebook"/></svg> </a><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Froger.rogverse.fyi%2Fneurosync-glimpse-interactive-digital-experiences.html&amp;via=godieph&amp;text=NeuroSync%3A%20Glimpse%20Interactive%20Digital%20Experiences" class="js-share twitter" aria-label="Share with Twitter" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://roger.rogverse.fyi/assets/svg/svg-map.svg#twitter"/></svg> </a><a href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Froger.rogverse.fyi%2Fneurosync-glimpse-interactive-digital-experiences.html&amp;media=https%3A%2F%2Froger.rogverse.fyi%2Fmedia%2Fposts%2F9%2Fneurosync-2.jpg&amp;description=NeuroSync%3A%20Glimpse%20Interactive%20Digital%20Experiences" class="js-share pinterest" aria-label="Share with Pinterest" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://roger.rogverse.fyi/assets/svg/svg-map.svg#pinterest"/></svg> </a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Froger.rogverse.fyi%2Fneurosync-glimpse-interactive-digital-experiences.html" class="js-share linkedin" aria-label="Share with LinkedIn" rel="nofollow noopener noreferrer"><svg class="icon"><use xlink:href="https://roger.rogverse.fyi/assets/svg/svg-map.svg#linkedin"/></svg></a></div></div><div class="content__bio"><img src="https://roger.rogverse.fyi/media/website/circle-avatar-open.png" loading="lazy" height="1080" width="1080" alt="Roger Filomeno"><h3><a href="https://roger.rogverse.fyi/authors/roger-filomeno/" title="Roger Filomeno">Roger Filomeno</a></h3><div class="content__bio-desc"><p>Roger the CEO of <a href="https://rogverse.fyi/" title="Automation that Amplifies Human Potential" target="_blank" rel="noopener">ROGVERSE</a> ltd -- a comprehensive AI automation platform built on principle: <em>Automation that Amplifies Human Potential</em></p></div></div></footer></div></div></article><div class="main__right main__right--bottom"></div></main><footer class="footer"><div class="footer__social"><a href="https://web.facebook.com/ilovejelatin" class="facebook" aria-label="Facebook"><svg class="icon"><use xlink:href="https://roger.rogverse.fyi/assets/svg/svg-map.svg#facebook"/></svg> </a><a href="https://x.com/godie" class="twitter" aria-label="Twitter"><svg class="icon"><use xlink:href="https://roger.rogverse.fyi/assets/svg/svg-map.svg#twitter"/></svg> </a><a href="https://www.linkedin.com/in/rpfilomeno/" class="linkedin" aria-label="LinkedIn"><svg class="icon"><use xlink:href="https://roger.rogverse.fyi/assets/svg/svg-map.svg#linkedin"/></svg> </a><a href="https://www.youtube.com/@godiegaming" class="youtube" aria-label="Youtube"><svg class="icon"><use xlink:href="https://roger.rogverse.fyi/assets/svg/svg-map.svg#youtube"/></svg></a></div><div class="footer__copyright">A.I.2.mations 2025 All rights reserved</div></footer></div></div><script defer="defer" src="https://roger.rogverse.fyi/assets/js/scripts.min.js?v=1ea8317abae2e05fa2a65ed7bbff7ba7"></script><script>var images = document.querySelectorAll('img[loading]');
   
           for (var i = 0; i < images.length; i++) {
               if (images[i].complete) {
                   images[i].classList.add('is-loaded');
               } else {
                   images[i].addEventListener('load', function () {
                       this.classList.add('is-loaded');
                   }, false);
               }
           }</script><script src="https://cdn.botpress.cloud/webchat/v2.2/inject.js"></script><script src="https://files.bpcontent.cloud/2025/01/25/00/20250125005609-7G1UEWJF.js"></script><script>!function(){var e,r="undefined"==typeof window?{}:window,n=r.usertour;if(console.log("enter npm backage, usertour:",n),!n){var o="https://js.usertour.io/";console.log("enter npm backage: ",o);var t=null;n=r.usertour={_stubbed:!0,load:function(){return t||(t=new Promise((function(e,n){var u=document.createElement("script");u.async=!0;var a=r.USERTOURJS_ENV_VARS||{};"es2020"===(a.USERTOURJS_BROWSER_TARGET||function(e){for(var r=[[/Edg\//,/Edg\/(\d+)/,80],[/OPR\//,/OPR\/(\d+)/,67],[/Chrome\//,/Chrome\/(\d+)/,80],[/CriOS\//,/CriOS\/(\d+)/,100],[/Safari\//,/Version\/(\d+)/,14],[/Firefox\//,/Firefox\/(\d+)/,74]],n=0;n<r.length;n++){var o=r[n],t=o[0],u=o[1],a=o[2];if(e.match(t)){var i=e.match(new RegExp(u));if(i&&parseInt(i[1],10)>=a)return"es2020";break}}return"legacy"}(navigator.userAgent))?(u.type="module",u.src=a.USERTOURJS_ES2020_URL||o+"es2020/usertour.js"):u.src=a.USERTOURJS_LEGACY_URL||o+"legacy/usertour.iife.js",u.onload=function(){e()},u.onerror=function(){document.head.removeChild(u),t=null;var e=new Error("Could not load Usertour.js");console.warn(e.message),n(e)},document.head.appendChild(u)}))),t}};var u=r.USERTOURJS_QUEUE=r.USERTOURJS_QUEUE||[],a=function(e){n[e]=function(){var r=Array.prototype.slice.call(arguments);n.load(),u.push([e,null,r])}},i=function(e){n[e]=function(){var r,o=Array.prototype.slice.call(arguments);n.load();var t=new Promise((function(e,n){r={resolve:e,reject:n}}));return u.push([e,r,o]),t}};a("init"),a("off"),a("on"),a("reset"),i("endAll"),i("group"),i("identify"),i("identifyAnonymous"),i("start"),i("track"),i("updateGroup"),i("updateUser"),e=!1,n["isIdentified"]=function(){return e}}}();
   
     usertour.init('cm98jgf140am8y2bn8ddqwtbl');
     usertour.identifyAnonymous();</script><script src="https://roger.rogverse.fyi/media/plugins/pagePrefetching/quicklink.umd.js"></script><script>window.addEventListener('load', () => {
   					quicklink.listen({
   						prerender: true,
   						el: document.querySelector('body'),
   						delay: 0,
   						limit: Infinity,
   						throttle: Infinity,
   						timeout: 2000
   					});
   				});</script></body></html>