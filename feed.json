{
    "version": "https://jsonfeed.org/version/1",
    "title": "Ai.2.mations",
    "description": "",
    "home_page_url": "https://roger.rogverse.fyi",
    "feed_url": "https://roger.rogverse.fyi/feed.json",
    "user_comment": "",
    "author": {
        "name": "Roger Filomeno"
    },
    "items": [
        {
            "id": "https://roger.rogverse.fyi/neurosync-glimpse-interactive-digital-experiences.html",
            "url": "https://roger.rogverse.fyi/neurosync-glimpse-interactive-digital-experiences.html",
            "title": "NeuroSync: Glimpse Interactive Digital Experiences",
            "summary": "NeuroSync: The Future of Interactive Digital Experiences is Here Get ready for a revolution in digital interaction! This blog post dives into the exciting world of NeuroSync, an open-source project poised to redefine how we experience interactive games, digital avatars, and even streaming content. Prepare&hellip;",
            "content_html": "<h1 id=\"neurosync-the-future-of-interactive-digital-experiences-is-here\">NeuroSync: The Future of Interactive Digital Experiences is Here</h1>\n<p>Get ready for a revolution in digital interaction! This blog post dives into the exciting world of <a href=\"https://neurosync.info/\">NeuroSync</a>, an open-source project poised to redefine how we experience interactive games, digital avatars, and even streaming content. Prepare to have your perception of reality in the digital realm challenged!</p><h2 id=\"the-quest-for-believable-digital-avatars\">The Quest for Believable Digital Avatars</h2>\n<p>We’re constantly seeking more immersive and dynamic digital experiences. Whether it’s diving into a new game, exploring the metaverse, or connecting on social media, the believability of digital avatars is key. Realistic facial animation, with all its subtle nuances, is crucial for conveying emotions and creating genuine engagement. Historically, this has been a complex and labor-intensive process. But now, <a href=\"https://huggingface.co/AnimaVR/NEUROSYNC_Audio_To_Face_Blendshape\">NeuroSync</a> is stepping onto the scene to change the game.</p><p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://cdn.rogverse.fyi/inzoi.jpg\" alt=\"Digital Avatar\"  data-is-external-image=\"true\"></figure>\n<em>INZOI a glimpse into the world of digital avatars.</em></p><h2 id=\"neurosync-unlocking-real-time-facial-animation-in-unreal-engine-5\">NeuroSync: Unlocking Real-Time Facial Animation in Unreal Engine 5</h2>\n<p>NeuroSync is an open-source marvel that allows for the real-time streaming of facial blendshapes into the powerful <a href=\"https://www.unrealengine.com/en-US/\">Unreal Engine 5</a> using audio input. Let’s break down how this works:</p><h3 id=\"detailed-technical-overview\">Detailed Technical Overview</h3>\n<p>At its core, NeuroSync utilizes a sophisticated transformer seq2seq model. This model cleverly translates audio features into facial blendshape coefficients in real-time, making digital characters’ faces move in sync with their speech and even express emotions.</p><h3 id=\"the-power-of-the-local-api\">The Power of the Local API</h3>\n<p>For developers who crave control and minimal lag, NeuroSync offers a <a href=\"https://github.com/AnimaVR/NeuroSync_Local_API\">Local API</a>. This allows you to host the pre-trained audio-to-face model on your own hardware, giving you complete command over the animation process and potentially reducing latency.</p><h3 id=\"seamless-integration-with-unreal-engine-5\">Seamless Integration with Unreal Engine 5</h3>\n<p>Integrating NeuroSync into Unreal Engine 5 is a breeze thanks to the <a href=\"https://docs.unrealengine.com/5.3/en-US/livelink-in-unreal-engine/\">LiveLink API</a>. The <a href=\"https://github.com/AnimaVR/NeuroSync_Player\">NeuroSync Player</a> acts as the bridge, streaming the animation data directly into the engine. It leverages Apple’s ARKit blendshapes for a wide range of realistic facial movements.</p><h3 id=\"continuous-improvement\">Continuous Improvement</h3>\n<p><a href=\"https://youtu.be/iqzbrE7KV_M?si=pw4LWBluneJRI57i\">NeuroSync</a> is constantly evolving. Recent updates, like the one on February 4, 2025, have brought significant improvements in timing accuracy and the naturalness of expressions, especially in areas like brows, cheeks, and mouth shapes. Another update on March 29, 2025, further enhanced accuracy and smoothness through refined training data and model architecture.</p><p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://cdn.rogverse.fyi/thorium_m0BM7Eu1AP.png\" alt=\"NeuroSync in Unreal Engine 5\"  data-is-external-image=\"true\"></figure>\n<em>NeuroSync seamlessly integrates with Unreal Engine 5</em></p><h2 id=\"the-power-couple-neurosync-and-multimodal-llms-in-interactive-games\">The Power Couple: NeuroSync and Multimodal LLMs in Interactive Games</h2>\n<p>Imagine combining NeuroSync’s realistic facial animation with the intelligence of multimodal Large Language Models (LLMs). This synergy could lead to truly revolutionary interactive gaming experiences.</p><h3 id=\"beyond-text-multimodal-llms-understand-the-game\">Beyond Text: Multimodal LLMs Understand the Game</h3>\n<p>Multimodal LLMs can process various forms of data, including text, images, and audio. This allows them to understand the game’s context and the player’s input in a much richer way than traditional text-based LLMs. They can interpret visual cues, spoken dialogue, and even the overall game environment to create more intelligent and responsive NPCs.</p><h3 id=\"bringing-characters-to-life-with-expressive-animation\">Bringing Characters to Life with Expressive Animation</h3>\n<p>NeuroSync provides the visual expressiveness that complements the intelligence of MLLMs. While an MLLM can generate smart dialogue, NeuroSync animates the character’s face in real-time, synchronized with the speech. This creates incredibly believable and relatable virtual characters.</p><h3 id=\"the-future-is-now-existing-integrations\">The Future is Now: Existing Integrations</h3>\n<p>The integration of LLMs with game engines is already being explored. Projects like <a href=\"https://arxiv.org/html/2309.12276v2\">LLMR (Large Language Model for Mixed Reality)</a> and <a href=\"https://www.immersivecomputinglab.org/wp-content/uploads/2024/08/2024-ISMAR-AgentBehaviorGeneration.pdf\">VIVRA (Voice Interactive Virtual Reality Annotation)</a> showcase the potential of LLMs in creating dynamic and interactive virtual worlds. The <a href=\"https://github.com/AkshitIreddy/Interactive-LLM-Powered-NPCs\">Interactive LLM Powered NPCs</a> project even aims to revolutionize NPC interactions in existing games using AI for dialogue and facial animation.</p><p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://cdn.rogverse.fyi/graphic-features-supported-convai-1.png\" alt=\"LLM Powered NPC\"  data-is-external-image=\"true\"></figure>\n<em>Intelligent NPCs powered by LLMs.</em></p><h2 id=\"neurosync-and-metas-vision-digital-twins-and-ai-influencers\">NeuroSync and Meta’s Vision: Digital Twins and AI Influencers</h2>\n<p>Tech giant Meta is heavily invested in the metaverse and the creation of realistic digital twins and engaging AI influencers. NeuroSync could play a vital role in bringing these digital entities to life.</p><h3 id=\"metas-ambitious-plans\">Meta’s Ambitious Plans</h3>\n<p>Meta envisions a future where digital twins accurately represent real-world individuals in the metaverse. Engaging AI influencers would also require highly realistic and expressive avatars.</p><h3 id=\"enhancing-visual-fidelity-and-emotional-expression\">Enhancing Visual Fidelity and Emotional Expression</h3>\n<p>NeuroSync’s real-time audio-to-facial animation can significantly contribute to the visual fidelity and emotional expressiveness of these Meta-driven avatars. The ability to generate nuanced facial expressions directly from audio will make digital twins and AI influencers feel more alive and believable.</p><h3 id=\"potential-for-collaboration\">Potential for Collaboration</h3>\n<p>The synergy between NeuroSync and Meta’s goals opens up exciting possibilities for collaboration. Meta could integrate NeuroSync’s technology to enhance its avatar creation process, and the open-source nature of NeuroSync could benefit from the scale and resources of Meta’s platforms.</p><p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://cdn.rogverse.fyi/Zucc_pgzaxw.jpg\" alt=\"Metaverse Avatars\"  data-is-external-image=\"true\"></figure>\n<em>Realistic avatars in the metaverse.</em></p><h2 id=\"blurring-reality-neurosync-unreal-engine-5-and-streaming-content\">Blurring Reality: NeuroSync, Unreal Engine 5, and Streaming Content</h2>\n<p>The combination of NeuroSync and Unreal Engine 5’s incredible rendering capabilities could lead to a future where it’s hard to distinguish between computer-generated graphics and reality in streaming content.</p><h3 id=\"unreal-engine-5-a-master-of-photorealism\">Unreal Engine 5: A Master of Photorealism</h3>\n<p>Unreal Engine 5 is renowned for its ability to create stunningly photorealistic visuals in real-time. Games like Unrecord and Bodycam (while not explicitly detailed in the provided snippets, their visual fidelity is well-known) showcase the engine’s power to produce graphics that can often be mistaken for real life.</p><h3 id=\"elevating-ai-avatars-in-live-streaming\">Elevating AI Avatars in Live Streaming</h3>\n<p>When you pair UE5’s visual prowess with NeuroSync’s lifelike facial animation, AI avatars in live streaming scenarios can reach unprecedented levels of realism. Imagine AI streamers that not only look incredibly real but also speak and emote with natural facial expressions. This could truly blur the lines between virtual and human content creators.</p><p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://cdn.rogverse.fyi/Unreal+Engine_spotlights_meet-vincent-a-real-time-digital-human-created-in-house-by-a-team-of-just-five_Spotlight_Giantstep_blog_body_img2-1640x1000-fcfc6112efbd1cceabc7687e7fb4d456276791f8.jpg\" alt=\"Unreal Engine 5 Realism\"  data-is-external-image=\"true\"></figure>\n<em>Meet Vincent: a real-time digital human. The photorealistic power of Unreal Engine 5.</em></p><h2 id=\"the-rise-of-ai-digital-personalities-surpassing-humans\">The Rise of AI Digital Personalities: Surpassing Humans?</h2>\n<p>The emergence of AI digital personalities, such as the popular AI Vtubers Neurosama and Codemiko, raises the question: could AI eventually surpass human creators in online interactions?</p><h3 id=\"neurosama-and-codemiko-the-ai-vtubing-phenomenon\">Neurosama and Codemiko: The AI Vtubing Phenomenon</h3>\n<p><a href=\"https://en.wikipedia.org/wiki/Neuro-sama\">Neurosama</a> is an AI VTuber and chatbot on Twitch, created by developer Vedal. She uses a large language model to generate human-like responses and has gained a massive following, even breaking <a href=\"https://streamscharts.com/news/vedals-ai-vtuber-neuro-twitch-hype-train-record\">Twitch’s Hype Train record</a>. <a href=\"https://en.wikipedia.org/wiki/CodeMiko\">Codemiko</a>, on the other hand, is a VTuber known for her unique glitchy aesthetic and highly interactive streams. Behind the avatar is a real person, Youna Kang (The Technician), who uses motion capture and Unreal Engine to bring Codemiko to life.</p><h3 id=\"why-are-they-so-popular\">Why Are They So Popular?</h3>\n<p>Neurosama’s success is partly due to the novelty of interacting with an AI, while Codemiko’s appeal lies in her unique character and high level of interactivity. Both demonstrate that engaging digital personalities, whether fully AI-driven or human-controlled with advanced avatars, can captivate online audiences.</p><h3 id=\"ai-vs-humans-the-great-debate\">AI vs. Humans: The Great Debate</h3>\n<p>Could AI digital personalities truly surpass human creators? While AI offers advantages like 24/7 availability and scalability, it currently lacks the genuine emotions and lived experiences that drive deep human connection. It’s more likely that AI will become a powerful tool that complements human creativity rather than replacing it entirely.</p><p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://cdn.rogverse.fyi/Neuro-sama-20231106-1.webp\" alt=\"AI VTuber\"  data-is-external-image=\"true\"></figure>\n<em>AI VTubers like Neurosama are gaining popularity.</em></p><p><figure class=\"post__image\"><img loading=\"lazy\" src=\"https://cdn.rogverse.fyi/thorium_9XrxXIYuJO-ezgif.com-cut.gif\" alt=\"Codemiko\"  data-is-external-image=\"true\"></figure>\n<em>Codemiko, known for her interactive streams.</em></p><h2 id=\"conclusion-embracing-the-future-of-interactive-media\">Conclusion: Embracing the Future of Interactive Media</h2>\n<p>NeuroSync, in conjunction with the power of multimodal LLMs and the stunning visuals of Unreal Engine 5, is paving the way for a truly transformative era in interactive media. From more engaging games and realistic digital avatars to the potential blurring of lines in streaming content, the possibilities are immense. While AI digital personalities are making waves, the unique essence of human creativity will likely ensure a future where both AI and human creators thrive, offering diverse and enriching digital experiences.</p>",
            "image": "https://roger.rogverse.fyi/media/posts/9/neurosync-2.jpg",
            "author": {
                "name": "Roger Filomeno"
            },
            "tags": [
                   "Blog",
                   "AI"
            ],
            "date_published": "2025-04-07T11:20:23+08:00",
            "date_modified": "2025-04-07T15:05:23+08:00"
        },
        {
            "id": "https://roger.rogverse.fyi/beyond-the-terminal-is-vtm-the-revolutionary-text-based-desktop-in-the-making.html",
            "url": "https://roger.rogverse.fyi/beyond-the-terminal-is-vtm-the-revolutionary-text-based-desktop-in-the-making.html",
            "title": "Beyond the Terminal: Is VTM the Revolutionary Text-Based Desktop In The Making? ",
            "summary": "The world of command-line interfaces is experiencing a renaissance. For years, the terminal remained a relatively static tool, a direct descendant of the teletype machines of the past. But recently, we've seen exciting innovations aimed at enhancing the user experience, with tools like the Warp&hellip;",
            "content_html": "\n  <p>\n    The world of command-line interfaces is experiencing a renaissance. For years, the terminal remained a relatively static tool, a direct descendant of the teletype machines of the past. But recently, we've seen exciting innovations aimed at enhancing the user experience, with tools like the Warp terminal leading the charge . These modern terminals offer a plethora of features designed to boost productivity and make the command line more accessible. However, a new contender has emerged, one that proposes a far more radical shift: VTM, the text-based desktop environment . Could this be more than just another terminal emulator? Could it be a truly revolutionary way to interact with our computers?\n  </p>\n\n    <h2 id=\"warp-modernizing-the-terminal-experience\">\n      Warp: Modernizing the Terminal Experience\n    </h2>\n\n  <p>\n    Warp has garnered significant attention for its approach to modernizing the terminal. It takes the familiar concept of a terminal emulator and infuses it with features inspired by contemporary development environments . One of its standout capabilities is the integration of AI, offering intelligent command suggestions and explanations for errors, effectively lowering the barrier to entry for those less familiar with the command line . Warp also introduces the concept of \"blocks,\" grouping command inputs and outputs together for easier navigation, sharing, and filtering, addressing a common frustration of sifting through lengthy terminal sessions . For those accustomed to IDEs, Warp provides IDE-like editing on the command line, allowing users to place their mouse cursor and edit commands intuitively without the need for excessive backspacing . Furthermore, it boasts smart completions for a vast array of CLI tools, streamlining the process of entering commands . Collaboration is another key aspect, with features like session sharing enabling teams to work together on the command line in real-time . Users can also personalize their experience with extensive customization options for themes, keybindings, and prompts . Under the hood, Warp leverages technologies like Rust and GPU rendering to deliver performance enhancements, resulting in a faster and more responsive terminal . In essence, Warp refines the traditional terminal paradigm, making it more user-friendly, intelligent, and collaborative, focusing on improving the experience of interacting with the command line within a graphical environment .\n  </p>\n\n    <h2 id=\"vtm-a-different-breed-the-text-based-desktop-environment\">\n      VTM: A Different Breed - The Text-Based Desktop Environment\n    </h2>\n\n    <figure class=\"post__image post__image--center\">\n      <a href=\"https://github.com/directvt/vtm\" target=\"_blank\">\n        <img loading=\"lazy\" src=\"https://roger.rogverse.fyi/media/posts/7/vtm_jSrkwppU3f.png\" height=\"814\" width=\"1298\" alt=\"VTM on Windows 11 running Yazi\"  sizes=\"(min-width: 1500px) calc(7.87vw + 610px), (min-width: 900px) calc(44.48vw + 68px), (min-width: 780px) calc(8vw + 604px), calc(84.35vw + 23px)\" srcset=\"https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-xs.webp 300w ,https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-sm.webp 480w ,https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-md.webp 768w\">\n      </a>\n      <figcaption>https://github.com/directvt/vtm</figcaption>\n    </figure>\n\n  <p>\n    Stepping into a different realm entirely is VTM. Unlike Warp, which enhances the terminal, VTM aims to create a complete desktop environment constructed entirely from text cells arranged in a TUI (Text-based User Interface) matrix . This fundamental difference in approach leads to a unique set of features . The entire user interface in VTM is rendered using text characters, forming a mosaic of cells that constitute the display. This includes everything from application windows to any potential menus or interface elements. A key aspect of VTM is its ability to manage windows. It can wrap any console application within these text-based \"windows,\" which users can then arrange, resize, move, and even layer, offering a desktop-like organizational structure . The documentation for VTM's user interface details a comprehensive set of mouse and keyboard shortcuts for these window management operations, including actions for moving, resizing, maximizing, minimizing, and closing windows . Remarkably, VTM can be nested indefinitely, allowing for the creation of intricate and potentially isolated text-based desktop layouts . Users can launch existing command-line applications within this environment , with documentation mentioning command-line launching and the possibility of a default application setting . Video demonstrations show users launching terminal emulators and other text-based tools within the VTM environment . VTM offers flexibility in rendering its TUI matrix, capable of displaying it within its own GUI window (currently only on Windows) or within a compatible text console . Furthermore, VTM boasts cross-platform support, running on Windows and various \\*nix systems . This vision of a complete desktop built from text fundamentally diverges from the approach of traditional terminals and Warp, which primarily focus on enhancing the experience within the confines of a single terminal window. VTM, on the other hand, seeks to be a text-based alternative to the traditional graphical desktop.\n  </p>\n\n    <h2 id=\"revolutionary-potential-why-vtm-might-just-be-the-next-big-thing-or-a-niche-gem\">\n      Revolutionary Potential: Why VTM Might Just Be the Next Big Thing (or a Niche Gem)\n    </h2>\n\n  <p>\n    The implications of VTM being a text-based desktop environment are significant. One potential advantage lies in resource usage. Theoretically, an environment built entirely from text could consume considerably fewer system resources like CPU, RAM, and GPU compared to a conventional graphical desktop . While specific data on VTM's resource footprint isn't readily available, the inherent nature of a TUI suggests a lighter overhead compared to rendering complex graphical elements. This potential for lower resource consumption could make VTM particularly appealing in resource-constrained scenarios, on older hardware, or for users who prioritize efficiency.\n<br>\n<br>Furthermore, the text-based foundation of VTM could unlock unparalleled levels of customization. Since every aspect of the interface is rendered with text, users could theoretically have fine-grained control over its appearance and potentially even its functionality through text-based configuration files . The user interface documentation hints at extensive configuration options . This level of control could resonate with users who desire deep personalization of their computing environment.\n<br>\n<br>VTM's unique approach also opens up possibilities for use cases that extend beyond typical terminal workflows. It could serve as a minimalist computing environment for those seeking a distraction-free, text-centric experience. Its potential for lightweight operation could make it an efficient solution for remote access, especially in situations with limited bandwidth . VTM might also find applications in embedded systems where graphical capabilities are constrained. Additionally, it could offer unique accessibility advantages for users with certain visual impairments. The aesthetic of classic text-based interfaces combined with modern features like window management and application support could appeal to users who appreciate retro computing styles but require contemporary functionality . Moreover, VTM could provide a structured, windowed environment for running multiple terminal-based applications, offering a different organizational paradigm compared to tools like<code> tmux&nbsp;</code>or <code>screen</code> .\n<br>\n<br>In contrast, the enhancements offered by Warp primarily focus on improving the efficiency and usability of the traditional terminal experience within a graphical environment. While Warp undoubtedly addresses many pain points of command-line users, VTM challenges the fundamental paradigm of how we interact with our computers at a lower level. This difference in scope suggests that while Warp aims to make the existing terminal experience better, VTM explores a more radical alternative, potentially leading to more significant shifts in user interaction.\n  </p>\n\n    <h2 id=\"vtms-unique-features-standing-out-from-the-crowd\">\n      VTM's Unique Features: Standing Out from the Crowd\n    </h2>\n\n  <p>\n    Several specific features of VTM distinguish it from both traditional terminal emulators and modern ones like Warp. One key difference is VTM's text-based window management . Unlike the tabbed or split-pane interfaces common in traditional terminals, VTM provides a more flexible windowing system within its text grid. As demonstrated in videos, users can arrange applications in a manner reminiscent of a graphical desktop . The detailed user interface documentation further illustrates the extensive mouse and keyboard actions available for managing these windows . This approach to window management goes beyond the capabilities of terminal multiplexers like <code>tmux </code>or <code>screen</code>, offering a more visually oriented, albeit still text-based, method for organizing applications. Tools like <code>tmux </code>and <code>screen </code>typically operate within a single terminal window, whereas VTM creates distinct, resizable areas within its text-based desktop.\n<br>\n<br>Another unique feature is the ability to nest VTM instances . Running a text-based desktop environment within another offers a level of organizational control and potential for isolated workspaces not found in traditional terminals. This nesting capability could be particularly useful for managing complex workflows or creating sandboxed environments. Imagine having a dedicated text-based desktop for development tasks running inside another for general computing, providing a clear separation of concerns.\n<br>\n<br>VTM's capability to render its output to either a dedicated GUI window (currently on Windows) or a standard text console  provides significant adaptability. This dual rendering option makes VTM accessible in both graphical and purely text-based environments. For users who prefer a graphical interface, the Windows GUI rendering allows them to experience VTM's features, while those working in text-only environments can also utilize it. A video demonstrates VTM running seamlessly within the Windows Terminal , showcasing its ability to integrate with existing terminal emulators.\n<br>\n<br>Similar to <code>screen </code>or <code>tmux</code>, VTM allows users to detach from running applications, which continue to operate in the background, and then re-attach to them later . This feature enhances the persistence and management of long-running command-line tasks within the VTM environment. Users can close the VTM window, and their processes will continue to run, allowing them to resume their work at a later time.\n<br><br>Furthermore, VTM offers various mechanisms for remote access, enabling users to run remote applications and even the entire desktop environment over SSH . This built-in remote access functionality could make VTM a valuable tool for system administrators and developers who frequently work with remote machines. The documentation explicitly outlines commands for establishing remote connections and running applications or the full desktop via SSH.\n  </p>\n\n    <h2 id=\"why-you-might-want-to-take-vtm-for-a-spin\">\n      Why You Might Want to Take VTM for a Spin\n    </h2>\n\n  <p>\n    VTM presents several compelling reasons for users to consider trying it out, depending on their individual needs and preferences. For those who are simply curious about novel computing paradigms and enjoy exploring unconventional tools, VTM offers a unique experience unlike any standard terminal emulator or graphical desktop environment. Its text-based nature provides a distinct way of interacting with a computer that might appeal to those seeking something different.\n<br>\n<br>Users who value a minimalist, text-centric environment and are intrigued by the potential for lower resource usage compared to traditional GUIs might find VTM particularly attractive. If efficiency and a distraction-free workspace are priorities, VTM's approach could be a compelling alternative.\n<br>\n<br>Even for command-line power users who are already comfortable with tools like `tmux` or `screen`, VTM offers a different way to manage and interact with multiple terminal-based applications. The \"infinite canvas\" concept, as hinted at in video demonstrations , could provide a more intuitive or visually organized approach to managing numerous terminal sessions.\n<br>\n<br>Developers who spend a significant amount of time working with text editors, consoles, and other command-line tools might find VTM's integrated and organized workspace beneficial. Having the ability to arrange these tools in a desktop-like manner within a text-based environment could enhance productivity.\n<br>\n<br>Retro computing enthusiasts might appreciate VTM's ability to capture the aesthetic of classic text-based interfaces while providing modern features such as window management and cross-platform compatibility. It offers a nostalgic feel with contemporary functionality.\n<br>\n<br>System administrators could find VTM's remote access capabilities and its structured approach to managing multiple terminal sessions particularly useful for server management tasks. The ability to run remote desktops or individual applications over SSH could streamline remote workflows.\n<br>\n<br>However, it's important to acknowledge potential drawbacks. The entirely text-based nature of VTM might not appeal to users who heavily rely on graphical applications for their daily tasks. The user interface paradigm and the extensive reliance on keyboard shortcuts, as suggested in documentation and videos , might require a learning period for new users. The current limitation of GUI rendering to Windows might also be a consideration for users on other platforms who might need to run VTM within an existing terminal emulator. Finally, as VTM appears to be an active project, some features might be under development or subject to change.\n<br>\n<br>Ultimately, VTM caters to a specific niche of users who are either seeking a fundamentally different computing experience or have particular needs that a text-based desktop environment can address. While it's unlikely to replace mainstream graphical desktops for the majority of users, its unique approach could be highly valuable for certain individuals and specific use cases.\n  </p>\n\n    <h2 id=\"text-as-the-new-frontier\">\n      Text as the New Frontier?\n    </h2>\n\n  <p>\n    In the evolving landscape of command-line tools, Warp represents a significant step forward in enhancing the traditional terminal experience, making it more intelligent, user-friendly, and collaborative. However, VTM takes a far more radical approach by reimagining the entire desktop environment as a text-based interface. While Warp refines the familiar paradigm, VTM dares to ask \"what if we went back to text, but with modern windowing and application management?\". This bold approach could lead to exciting new ways of interacting with our computers, even if it remains a niche tool for specific use cases and adventurous users. For those intrigued by the possibilities of a text-based future, exploring the VTM GitHub repository and trying it out for themselves could offer a glimpse into a fundamentally different way of computing.\n  </p>\n\n    <h2 id=\"feature-comparison\">\n      Feature Comparison\n    </h2>\n<div><table>\n  <thead>\n    <tr>\n      <th>Feature</th>\n      <th>Warp</th>\n      <th>VTM (Text-based Desktop)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td><strong>Core Concept</strong></td>\n      <td>Modern terminal emulator with enhanced features</td>\n      <td>Text-based application creating a complete desktop environment from text cells</td>\n    </tr>\n    <tr>\n      <td><strong>UI Paradigm</strong></td>\n      <td>Primarily graphical with text-based command line</td>\n      <td>Entirely text-based user interface (TUI)</td>\n    </tr>\n    <tr>\n      <td><strong>Window Management</strong></td>\n      <td>Tabs and split panes within a single terminal window</td>\n      <td>Text-based windows for applications that can be moved, resized, layered, and nested within a text grid</td>\n    </tr>\n    <tr>\n      <td><strong>Application Launching</strong></td>\n      <td>Standard command execution within the terminal</td>\n      <td>Wraps and runs any console application within its text-based windows</td>\n    </tr>\n    <tr>\n      <td><strong>AI Integration</strong></td>\n      <td>Built-in AI for command suggestions, error explanations, etc.</td>\n      <td>Not explicitly mentioned in the provided snippets.</td>\n    </tr>\n    <tr>\n      <td><strong>Collaboration</strong></td>\n      <td>Session sharing and other collaborative features</td>\n      <td>Multiple users can connect to a desktop session in real-time .</td>\n    </tr>\n    <tr>\n      <td><strong>Customization</strong></td>\n      <td>Themes, keybindings, prompts, etc.</td>\n      <td>Potentially extreme customization due to its text-based nature .</td>\n    </tr>\n    <tr>\n      <td><strong>Resource Usage</strong></td>\n      <td>Generally efficient, with GPU rendering for speed</td>\n      <td>Potentially lower resource usage compared to GUI environments (conceptual benefit of TUIs)</td>\n    </tr>\n    <tr>\n      <td><strong>Cross-Platform</strong></td>\n      <td>macOS, Linux, Windows</td>\n      <td>Windows, Linux, macOS, FreeBSD, NetBSD, OpenBSD</td>\n    </tr>\n    <tr>\n      <td><strong>GUI Rendering</strong></td>\n      <td>Yes</td>\n      <td>Dedicated GUI window available on Windows; renders within a terminal on other platforms</td>\n    </tr>\n    <tr>\n      <td><strong>Detached Processes</strong></td>\n      <td>Not a primary feature highlighted in snippets</td>\n      <td>Supports detaching and re-attaching to running applications .</td>\n    </tr>\n  </tbody>\n</table></div>",
            "image": "https://roger.rogverse.fyi/media/posts/7/Windows_Terminal_logo.svg-2.png",
            "author": {
                "name": "Roger Filomeno"
            },
            "tags": [
                   "Terminal",
                   "Blog"
            ],
            "date_published": "2025-03-23T19:03:03+08:00",
            "date_modified": "2025-03-23T19:21:45+08:00"
        },
        {
            "id": "https://roger.rogverse.fyi/crystalwire-10-release.html",
            "url": "https://roger.rogverse.fyi/crystalwire-10-release.html",
            "title": "Crystalwire 1.0 Release",
            "summary": "When you don't care about the firewall but need the jumping graphs that track which process consumes all your bandwidth, it's like Glasswire for terminals! Crystalwire is a command-line tool that monitors network bandwidth usage for each running process in real-time. It utilizes the psutil&hellip;",
            "content_html": "\n  <p>\n    When you don't care about the firewall but need the jumping graphs that track which process consumes all your bandwidth, it's like Glasswire for terminals!\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://roger.rogverse.fyi/media/posts/4/image-2.png\" height=\"583\" width=\"817\" alt=\"\"  sizes=\"(min-width: 1500px) calc(7.87vw + 610px), (min-width: 900px) calc(44.48vw + 68px), (min-width: 780px) calc(8vw + 604px), calc(84.35vw + 23px)\" srcset=\"https://roger.rogverse.fyi/media/posts/4/responsive/image-2-xs.webp 300w ,https://roger.rogverse.fyi/media/posts/4/responsive/image-2-sm.webp 480w ,https://roger.rogverse.fyi/media/posts/4/responsive/image-2-md.webp 768w\">\n      \n    </figure>\n\n  <p>\n    Crystalwire is a command-line tool that monitors network bandwidth usage for each running process in real-time. It utilizes the psutil library for gathering system information and displays the data in a user-friendly format.<br>\n  </p>\n\n    <h2 id=\"installation\">\n      Installation\n    </h2>\n\n  <p>\n    1. Clone the project\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>gh repo clone rpfilomeno/crystalwire</code></pre>\n\n  <p>\n    2. install 'crystalwire' the dependencies\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>pip install -r requirements.txt</code></pre>\n\n    <h2 id=\"usage\">\n      Usage\n    </h2>\n\n  <p>\n    Once installed, you can run 'crystalwire' from the command line:\n  </p>\n<pre class=\"line-numbers  language-bash\"><code>python -m crystalwire.main</code></pre>\n\n  <p>\n    \n  </p>",
            "image": "https://roger.rogverse.fyi/media/posts/4/Python-logo-notext.svg.png",
            "author": {
                "name": "Roger Filomeno"
            },
            "tags": [
                   "Python",
                   "Network",
                   "Monitoring",
                   "Blog"
            ],
            "date_published": "2025-03-22T22:54:21+08:00",
            "date_modified": "2025-03-23T01:27:26+08:00"
        },
        {
            "id": "https://roger.rogverse.fyi/monitoring-kamailio-and-asterisk-with-aws-cloudwatch.html",
            "url": "https://roger.rogverse.fyi/monitoring-kamailio-and-asterisk-with-aws-cloudwatch.html",
            "title": "Monitoring Kamailio and Asterisk with AWS CloudWatch",
            "summary": "Today I'm announcing the release to my new project VOIP Statistics to AWS CloudWatch (voip-mon-aws-cloudwatch), it is a monitoring script for Kamailio and Asterisk for AWS CloudWatch written in PHP. This works similarly to AWS CloudWatch Monitoring Script (Linux). Requirements Installation 1. Git clone to&hellip;",
            "content_html": "\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://roger.rogverse.fyi/media/posts/3/voip-aws-mon-2.jpg\" height=\"647\" width=\"1373\" alt=\"\"  sizes=\"(min-width: 1500px) calc(7.87vw + 610px), (min-width: 900px) calc(44.48vw + 68px), (min-width: 780px) calc(8vw + 604px), calc(84.35vw + 23px)\" srcset=\"https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-xs.webp 300w ,https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-sm.webp 480w ,https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-md.webp 768w\">\n      \n    </figure>\n\n  <p>\n    Today I'm announcing the release to my new project <a href=\"https://github.com/rpfilomeno/voip-mon-aws-cloudwatch\">VOIP Statistics to AWS CloudWatch (voip-mon-aws-cloudwatch)</a>, it is a monitoring script for Kamailio and Asterisk for AWS CloudWatch written in PHP. <br>\n  </p>\n\n  <p>\n    This works similarly to AWS CloudWatch Monitoring Script (Linux).<br><br>Requirements<br>\n  </p>\n\n  <ul>\n    <li>PHP 5.5 and above</li><li>Composer</li><li>Asterisk</li><li>Kamailio</li>\n  </ul>\n\n  <p>\n    Installation<br><br>1. Git clone to any Linux instance with Kamailio or Asterisk installed,<br><br>for example to ~/home/ec2-user/ using&nbsp;\n  </p>\n<pre class=\"line-numbers  language-html\"><code>git clone https://github.com/rpfilomeno/voip-mon-aws-cloudwatch.git</code></pre>\n\n  <p>\n    2. Go to the project's root directory by\n  </p>\n<pre class=\"line-numbers  language-html\"><code>cd ./voip-mon-aws-cloudwatch/</code></pre>\n\n  <p>\n    \n  </p>\n\n  <p>\n    3. Make the mon-put-instance-data.php executable\n  </p>\n<pre class=\"line-numbers  language-html\"><code>sudo chmod +x mon-put-instance-data.php</code></pre>\n\n  <p>\n    4. Install Composer\n  </p>\n<pre class=\"line-numbers  language-html\"><code>curl -sS https://getcomposer.org/installer | php</code></pre>\n\n  <p>\n    5. Install the dependencies by\n  </p>\n<pre class=\"line-numbers  language-html\"><code>php composer.phar update</code></pre>\n\n  <p>\n    6. Create your AWS&nbsp;<a href=\"http://docs.aws.amazon.com/aws-sdk-php/v3/guide/guide/credentials.html#credential-profiles\" target=\"_blank\">credentials file</a>\n  </p>\n\n    <h2 id=\"monitoring-kamailio\">\n      Monitoring Kamailio\n    </h2>\n\n  <p>\n    1. Test the script for monitoring Kamailio with\n  </p>\n<div>./mon-put-instance-data.php stats --t kamailio</div>\n\n  <p>\n    2. Install to Crontab with\n  </p>\n<div>crontab -e\n*/5 * * * * php /home/ec2-user/voip-mon-aws-cloudwatch/mon-put-instance-data.php stats --s kamailio</div>\n\n    <h2 id=\"monitoring-asterisk\">\n      Monitoring Asterisk\n    </h2>\n\n  <p>\n    1. Test the script for monitoring Kamailio with\n  </p>\n<div>./mon-put-instance-data.php stats --t asterisk\n</div>\n\n  <p>\n    2. Install to Crontab with\n  </p>\n<div>crontab -e\n*/5 * * * * php /home/ec2-user/voip-mon-aws-cloudwatch/mon-put-instance-data.php stats --s asterisk</div>",
            "image": "https://roger.rogverse.fyi/media/posts/3/images-1.png",
            "author": {
                "name": "Roger Filomeno"
            },
            "tags": [
                   "VOIP",
                   "Blog",
                   "AWS"
            ],
            "date_published": "2025-03-22T22:42:13+08:00",
            "date_modified": "2025-03-22T23:18:07+08:00"
        },
        {
            "id": "https://roger.rogverse.fyi/testing-kamailio-load-balancer-with-sipp.html",
            "url": "https://roger.rogverse.fyi/testing-kamailio-load-balancer-with-sipp.html",
            "title": "Testing Kamailio load balancer with SIPp",
            "summary": "Here are the steps to test Kamailio under load. First of all lets describe our network setup: The a user from extension 300X registered to Asterisk 1 initiates a call to an extension 400X registered at Asterisk 2. Kamailio is registered as a trunk to&hellip;",
            "content_html": "<p>Here are the steps to test Kamailio under load.</p><p>First of all lets describe our network setup:</p><script src=\"https://gist.github.com/rpfilomeno/d46493eefaf70d6838c157305ab9778a.js\"></script>\n\n<p>The a user from extension <em>300X</em> registered to <em>Asterisk 1</em> initiates a call to an extension <em>400X</em> registered at <em>Asterisk 2</em>. <em>Kamailio</em> is registered as a <em>trunk</em> to both Asterisk 1 &amp; 2; which intercepts the call which load balances it to either <em>Asterisk X or Y</em> where they do some <em>fancy</em> pre-processing to current call before its received by the callee.</p><p>Now for our testing purposes, we needed to remove the effect on performance by Asterisk 1 &amp; 2 so we installed SIPp on another host which generates calls and receives them.</p><h3 id=\"installation-and-execution-steps\">Installation and Execution Steps</h3>\n<ol>\n<li>Download and Modify SIPp to auto respond always and include OPTIONS packet as well (-aa broken?), edit src/call.cpp:</li>\n</ol>\n<pre><code class=\"language-cpp\">call::T_AutoMode call::checkAutomaticResponseMode(char * P_recv)\n{\n    if (strcmp(P_recv, &quot;BYE&quot;)==0) {\n        return E_AM_UNEXP_BYE;\n    } else if (strcmp(P_recv, &quot;CANCEL&quot;) == 0) {\n        return E_AM_UNEXP_CANCEL;\n    } else if (strcmp(P_recv, &quot;PING&quot;) == 0) {\n        return E_AM_PING;\n    } else if ((strcmp(P_recv, &quot;INFO&quot;) == 0) || (strcmp(P_recv, &quot;NOTIFY&quot;) == 0) || (strcmp(P_recv, &quot;UPDATE&quot;) == 0) || (strcmp(P_recv, &quot;OPTIONS&quot;) == 0)\n               ) {\n        return E_AM_AA;\n    } else {\n        return E_AM_DEFAULT;\n    }\n}\n</code></pre>\n<p>Compile <em>sipp-3.3.990</em> with <a href=\"http://sipp.sourceforge.net/doc/reference.html#Installing+SIPp\">RTP Support</a>.</p><p>To run the test, from SIPp Box: </p><pre><code class=\"language-bash\"># sipp 10.254.1.30 -i 10.254.1.40 -sf uac.xml -aa -inf accounts.csv -l 10000 -r 1 -rp 1000 -trace_msg -trace_err -trace_stat\n</code></pre>\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th>Parameter</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10.254.1.30</td>\n      <td>target Kamailio's IP on the LAN A side (see network diagram)</td>\n    </tr>\n    <tr>\n      <td>-i 10.254.1.40</td>\n      <td>make sure to bind SIPp on this IP especially if we are using IP Authentication on Kamailio</td>\n    </tr>\n    <tr>\n      <td>-sf <a href=\"https://gist.github.com/rpfilomeno/7445a628a3cbc0ceaaf8e9afe182578b#file-uac-xml\">uac.xml</a></td>\n      <td>use this scenario file that generates calls.</td>\n    </tr>\n    <tr>\n      <td>-inf <a href=\"https://gist.github.com/rpfilomeno/8673ee9dc7355274dfd98d187bbde925#file-accounts-csv\">accounts.csv</a></td>\n      <td>use this input CSV file, this is where the <em>[field0]</em>,<em>[field1]</em>,<em>[field2]</em> and <em>[field3]</em> values are derived in uac.xml. <br>Edit this file accordingly in format: \n        <em>\n        CallID;Kamailio LAN A IP;[authentication];Extension on Asterisk 2;Asterisk 2 LAN B IP;\n        </em>\n    </td>\n    </tr>\n    <tr>\n      <td>-l 10000</td>\n      <td>run 1000 calls.</td>\n    </tr>\n    <tr>\n      <td>-r 1 -rp 1000</td>\n      <td>make one call per 1000ms (1 secs)</td>\n    </tr>\n    <tr>\n      <td>-trace_msg</td>\n      <td>log all messages to a file (filename auto generated)</td>\n    </tr>\n    <tr>\n      <td>-trace_err</td>\n      <td>log all errors to a separate file (filename auto generated)</td>\n    </tr>\n    <tr>\n      <td>-trace_stat</td>\n      <td>generate a CSV file with statistics which is good for making graphs (default 1 minute interval) </td>\n    </tr>\n  </tbody>\n</table>\n\n\n<p>Make sure to edit the accounts.csv, change 10.254.1.30 and 10.254.7.31 accordingly.</p><p>Make sure to edit the uac.xml, change Route:</p><pre><code>&lt;sip:10.254.1.30;r2=on;lr=on;nat=yes&gt;,&lt;sip:10.254.3.30;r2=on;lr=on;nat=yes&gt;```\naccordingly since sipp-3.3.990 can&#39;t reliably generate this header so we had to hard code this for now. \n\nYou may run a SIPp on Asterisk 2 box to test higher concurrent calls (eg: testing more than 200 concurrent calls).\n\nLets shutdown Asterisk 1 &amp; 2: \n```bash\n# asterisk -rx &quot;core stop now&quot;\n</code></pre>\n<p>To run a server listening to incoming calls (server mode), run:</p><pre><code class=\"language-bash\"># sipp 10.254.7.30 -i 10.254.7.31 -sf uas.xml -aa -trace_msg -trace_err -trace_stat\n</code></pre>\n<p>Makes sure to edit the <a href=\"https://gist.github.com/rpfilomeno/5827e6ecf5863f74f53d41b1e15fa707#file-uas-xml\">uas.xml</a> to include the IP routes.</p><p>Now lets see how effective is Kamailio in this setup, here are the results I had:</p><table class=\"table\">\n  <thead>\n    <tr>\n      <th>Test Name</th>\n      <th>Concurrent Calls</th>\n      <th>Success</th>\n      <th>Failed</th>\n      <th>Dead Calls</th>\n      <th>Retransmissions</th>\n      <th>Average Response Time</th>\n      <th>Average Call Rate Per Seconds</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Test1</td>\n      <td>200</td>\n      <td>1000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2.52747</td>\n      <td>03.615000</td>\n    </tr>\n    <tr>\n      <td>Test2</td>\n      <td>300</td>\n      <td>998</td>\n      <td>2</td>\n      <td>5</td>\n      <td>252</td>\n      <td>3.15839</td>\n      <td>04.550000</td>\n    </tr>\n    <tr>\n      <td>Test3</td>\n      <td>400</td>\n      <td>993</td>\n      <td>7</td>\n      <td>12</td>\n      <td>1355</td>\n      <td>3.61512</td>\n      <td>13.049000</td>\n    </tr>\n    <tr>\n      <td>Test4</td>\n      <td>600</td>\n      <td>831</td>\n      <td>169</td>\n      <td>127</td>\n      <td>3554</td>\n      <td>4.05337</td>\n      <td>13.04900</td>\n    </tr>\n  </tbody>\n</table>\n\n<p>We stop at <em>Test 4</em> seeing Failed Calls spiked up at 169 calls, this was significant from our base capacity of 50 concurrent calls already.</p><p>Many thanks to <a href=\"http://saevolgo.blogspot.com/\">Gohar Ahmed</a> for helping me figuring most of the bugs.</p>",
            "image": "https://roger.rogverse.fyi/media/posts/2/5348744.png",
            "author": {
                "name": "Roger Filomeno"
            },
            "tags": [
                   "VOIP",
                   "Testing",
                   "Blog"
            ],
            "date_published": "2025-03-22T22:11:12+08:00",
            "date_modified": "2025-03-22T23:18:22+08:00"
        }
    ]
}
