<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>The AI Sloth Slayer</title>
    <link href="https://roger.rogverse.fyi/feed.xml" rel="self" />
    <link href="https://roger.rogverse.fyi" />
    <updated>2025-05-27T12:48:00+08:00</updated>
    <author>
        <name>Roger Filomeno</name>
    </author>
    <id>https://roger.rogverse.fyi</id>

    <entry>
        <title>I Compiled Philippine Colleges with Artificial Intelligence (AI) Courses So You Don&#x27;t Have To</title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/i-compiles-philippine-colleges-with-artificial-intelligence-ai-courses-so-you-dont-have-to.html"/>
        <id>https://roger.rogverse.fyi/i-compiles-philippine-colleges-with-artificial-intelligence-ai-courses-so-you-dont-have-to.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/15/philippines-minecraft.png" medium="image" />

        <updated>2025-05-27T09:56:53+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/15/philippines-minecraft.png" alt="" />
                    The Evolving Landscape of AI Education in the Philippines Artificial intelligence (AI) is rapidly transforming global industries and redefining professional roles, extending its&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/15/philippines-minecraft.png" class="type:primaryImage" alt="" /></p>
                <h3 id="the-evolving-landscape-of-ai-education-in-the-philippines"><strong>The Evolving Landscape of AI Education in the Philippines</strong></h3>
<p>Artificial intelligence (AI) is rapidly transforming global industries and redefining professional roles, extending its influence far beyond the traditional confines of information technology and data science. Its pervasive impact is now felt across diverse sectors, including healthcare, finance, business, and marketing, creating an urgent demand for a skilled workforce capable of navigating and innovating within this AI-driven world.<sup>1</sup> In response to this global shift, the Philippines is strategically positioning itself as a key player in the AI landscape, with an ambitious goal to become the ASEAN hub for artificial intelligence.<sup>2</sup> This national aspiration underscores the critical need for robust and forward-thinking AI education programs within the country’s higher education institutions.</p><p>The academic response to this technological imperative in the Philippines is not merely a reactive measure but reflects a concerted national strategy to cultivate AI talent and capability. Universities are not solely focused on imparting technical skills; there is a pronounced emphasis on developing individuals who can contribute to ethical innovation and responsible AI development. This approach is evident in the explicit articulation of principles for responsible AI, which address considerations such as the common good, empowerment, cultural sensitivity, privacy, accountability, transparency, and fairness.<sup>3</sup> Furthermore, initiatives focused on leveraging AI for sustainable community development and nation-building highlight a comprehensive vision that extends beyond purely technical training to a more mature, values-driven educational framework. This integrated perspective is crucial for ensuring that AI development contributes positively to national progress and aligns with societal values.</p><h3 id="leading-philippine-institutions-with-ai-programs"><strong>Leading Philippine Institutions with AI Programs</strong></h3>
<p>This section provides a detailed examination of AI-related programs offered by prominent Philippine universities, highlighting their unique strengths and curriculum focus.</p><p><strong>Mapúa University: Pioneering AI Engineering and Integrated Learning</strong></p><figure class="post__image"><img src="https://cdn.rogverse.fyi/mapua.png" alt="Mapua" data-is-external-image="true"></figure><p>Mapúa University has distinguished itself as a leader in AI education by being the first institution in the Philippines to introduce a Bachelor of Science in AI Engineering.<sup>2</sup> This innovative program is designed to equip students with the necessary skills to drive AI innovation and technological advancements. The curriculum of the BS in AI Engineering program is comprehensive, covering core areas such as machine learning, robotics, natural language processing, and data analytics.<sup>2</sup> It adopts a multidisciplinary approach, drawing expertise from computer science, engineering, and cognitive science to prepare students for the intricate task of designing and deploying intelligent systems.<sup>2</sup> Mapúa’s commitment to AI education is further demonstrated by its early integration of foundational AI-centered courses, including “Introduction to AI” and “Introduction to Data Science,” into its programs since 2018, particularly within the School of Information Technology.<sup>1</sup></p><p>Mapúa’s proactive stance in AI education is also reflected in its active collaborations with prominent AI-driven companies and innovators. Notably, the university has partnered with Arizona State University and OpenAI to integrate tools like ChatGPT into its higher education framework, setting a significant precedent for AI learning within the country.<sup>1</sup> Recognizing the need for flexible learning pathways, Mapúa also offers fully online programs, including the BS in AI Engineering, through its “Ubiquitous Online Experience (ÚOx),” which provides self-learning materials and comprehensive student support.<sup>5</sup> While the exact duration for the BS in AI Engineering program is not explicitly stated in the available information <sup>2</sup>, other undergraduate engineering programs at Mapúa, such as Industrial Engineering (3.5 years) and Electronics/Electrical Engineering (3 years), offer insights into typical program lengths for full-time online study.<sup>6</sup> Prospective students are advised to directly verify the specific duration for the BS in AI Engineering with the university. Graduates of Mapúa’s AI programs are prepared for a diverse range of roles, including AI Engineer, Machine Learning Engineer, Business Intelligence Developer, Research Scientist, Big Data Engineer/Architect, Database Developer, Software Engineer, and Quantitative Analyst.<sup>2</sup></p><p>Mapúa’s strategy extends beyond merely launching a new degree; it aims for a deep, systemic integration of AI across its educational ecosystem. By pioneering a dedicated AI engineering program, embedding AI courses across curricula, and actively upskilling its faculty, Mapúa is not just reacting to the increasing demand for AI professionals but is actively shaping the future of AI talent in the Philippines. The availability of fully online programs further demonstrates an adaptive and accessible approach to education, aligning with modern learning trends and potentially broadening the reach of its specialized AI offerings.</p><p><strong>University of the Philippines Diliman (UP Diliman): Advanced AI Studies and Research Hub</strong></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/updiliman.png" alt="UP Diliman " data-is-external-image="true"></figure><p>As the flagship campus of the University of the Philippines System, UP Diliman offers advanced AI programs that underscore its commitment to academic excellence and research. These include a Master of Engineering in Artificial Intelligence (MEng AI) and a Doctor of Philosophy in Artificial Intelligence (PhD AI).<sup>9</sup></p><p>The <strong>MEng AI</strong> program is a 2-year full-time or 3-year part-time professional master’s degree offered under the College of Engineering. It requires the completion of 31 units, culminating in an applied capstone project.<sup>9</sup> This multidisciplinary program focuses on the development and deployment of intelligent engineered systems capable of performing tasks that typically require human intelligence.<sup>9</sup> The <strong>PhD AI</strong> program, available as a 3 or 4-year full-time or 6 to 10-year part-time option, emphasizes state-of-the-art dissertation research and requires publications for graduation. Its core focus is on problem identification and understanding, familiarity with cutting-edge solutions, the formulation of novel algorithms and techniques, and the deployment of advanced, reliable AI systems.<sup>10</sup> Specific PhD courses include Computational Learning Theory, Machine Learning for Sequential Data, Reinforcement Learning, Differential Digital Signal Processing, Machine Learning in Natural Language Processing, Autonomous Robots, Artificial Intelligence Accelerator, and Probabilistic Graphical Models.<sup>11</sup></p><p>At the undergraduate level, the Bachelor of Science in Computer Science (B.Sc. C.S.) curriculum at UP Diliman includes “CS 180 (Artificial Intelligence)” as a required 3-unit course in the third year, second semester.<sup>13</sup> This course, often integrated with “Computer Simulation and Modeling,” incorporates the use of statistical tools, techniques, knowledge in expert systems, and artificial intelligence for data representation.<sup>14</sup> While the BSCS degree itself does not feature explicit specializations on the diploma, students can achieve a de-facto specialization through year-long projects undertaken within the department’s research laboratories and through their elective choices.<sup>13</sup> Beyond the main campus, the University of the Philippines Open University (UPOU) contributes to AI education by offering “CMSC 210: Introduction to Artificial Intelligence,” which covers foundational knowledge, machine learning principles, neural networks, various AI approaches, and applications such as natural language processing and computer vision.<sup>15</sup> UPOU has also proactively issued official guidelines for AI use in teaching and learning, emphasizing responsible and ethical integration of the technology.<sup>16</sup></p><p>UP Diliman’s Department of Computer Science is home to several research groups with significant AI-related interests. These include the Computer Vision and Machine Intelligence Group (CVMIG), which applies computational intelligence principles to biological, physical, and social systems (e.g., machines understanding the deaf, medical diagnosis, and robot interactions); the Scientific Computing Laboratory (SCL), which includes a dedicated Data Analytics Group; and the Service Science and Software Engineering Laboratory (S3), which incorporates studies related to artificial intelligence.<sup>17</sup></p><p>The university’s approach to AI education is deeply rooted in academic rigor and research excellence. The emphasis on developing “intelligent engineered systems” and extending the “AI body of knowledge” suggests a focus on fundamental advancements and high-level application. The integration of AI into the undergraduate CS curriculum, even without a formal specialization on the diploma, ensures a strong theoretical foundation. Furthermore, the UP System’s proactive development of “Principles for Responsible Artificial Intelligence” demonstrates a national leadership role in guiding ethical AI development and deployment, reflecting a comprehensive vision that extends beyond technical training to broader societal impact and governance.</p><p><strong>De La Salle University (DLSU): AI Integration within Computer Science Tracks</strong></p><figure class="post__image"><img src="https://cdn.rogverse.fyi/lasalle.png" alt="DLSU" data-is-external-image="true"></figure><p>When examining AI programs in the Philippines, it is important to differentiate between “De La Salle University” (DLSU) in the Philippines and other institutions named “La Salle University” (e.g., those in the US or Barcelona).<sup>18</sup> This report focuses exclusively on Philippine institutions.</p><p><strong>DLSU-Dasmariñas (DLSU-D)</strong> offers a Bachelor of Science in Computer Science with a Specialization in Intelligent Systems.<sup>23</sup> This specialization is designed to train students in abstract reasoning, analytical thinking, and research, with a specific focus on solving problems in Artificial Intelligence.<sup>23</sup> The curriculum emphasizes synthesizing goal-oriented processes such as problem-solving, decision-making, environmental adaptation, learning, and communication through the application of computers and algorithms.<sup>23</sup> Key AI-related courses within this track include “Introduction to Statistical Machine Learning,” “Introduction to Parallel Computing,” “Advanced Topics in Artificial Intelligence,” “Computer Vision/Image Processing,” “Advanced Topics In Algorithms,” and “Special Topics in Artificial Intelligence”.<sup>23</sup> Graduates from this program are prepared for careers as AI Programmers, Machine Learning Engineers, Computer Vision and Image Data Analysts, Software Engineers, and Systems Administrators.<sup>23</sup></p><p><strong>De La Salle University Manila (DLSU-M)</strong> provides AI-related coursework primarily through its Bachelor of Science in Computer Science Major in Software Technology (BSCS-ST) program.<sup>24</sup> The BSCS-ST curriculum covers fundamental computing theories and principles, incorporating advanced topics in intelligent systems.<sup>24</sup> A core component of this program is “CSINTSY: Introduction to Artificial Intelligence”.<sup>24</sup> Furthermore, professional electives within the Software Technology specialization offer advanced topics such as “Natural Language Processing,” “Advanced Machine Learning,” “Data Analytics,” and “Complex Systems”.<sup>24</sup> It is important to note a discrepancy in the stated program duration for DLSU-M’s BSCS programs: some sources indicate a 3-year duration <sup>27</sup>, while the total academic units required for the BSCS-ST program (173 units) <sup>24</sup> typically align with a 4-year program under a standard semester system. Prospective students are strongly advised to directly verify the accurate program length with the university.</p><p>The approach taken by both DLSU-D and DLSU-M suggests that AI is viewed as an advanced and specialized area within the broader field of Computer Science. This strategy ensures that graduates possess not only AI-specific skills but also a comprehensive understanding of core computing principles, making them versatile professionals. The practical, application-oriented nature of the AI-related courses, covering areas like Machine Learning, Computer Vision, and Natural Language Processing, prepares students for real-world challenges. The noted contradiction in program duration for DLSU-M’s BSCS programs highlights a critical ambiguity for prospective students, emphasizing the necessity of cross-referencing information and seeking official program handbooks for precise details.</p><p><strong>Ateneo de Manila University: AI in Data Science and Research-Driven Applications</strong></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/ateneo.png" alt="Ateneo" data-is-external-image="true"></figure><p>Ateneo de Manila University integrates AI concepts primarily through its Minor/Specialization in Data Science and Analytics.<sup>29</sup> While not a standalone AI degree, this program includes “CSCI 111: Introduction To Artificial Intelligence” as an elective, indicating its relevance within the data science curriculum.<sup>29</sup> Beyond this, the Bachelor of Science in Computer Engineering program at Ateneo explicitly prepares its graduates for careers as “Artificial intelligence and machine learning developers” and “Machine learning specialists”.<sup>30</sup> This suggests that AI and machine learning competencies are considered significant outcomes of their engineering curriculum, equipping students with practical skills for these burgeoning fields.</p><p>Ateneo is particularly strong in AI research, boasting several specialized laboratories within its Department of Information Systems and Computer Science that are actively engaged in various facets of AI. The <strong>Ateneo Computational Sound and Music Lab</strong> applies machine learning, computational methods, and algorithmic methodologies to the domain of sound and music, leading to advancements in AI.<sup>31</sup> The <strong>Ateneo Computer Algorithms and Applications Lab</strong> focuses on developing algorithms for optimization problems and applying computing principles in areas such as Machine Learning, Artificial Intelligence, Computer Vision, and Big Data.<sup>31</sup> The <strong>Ateneo Laboratory for Intelligent Visual Environments (ALIVE)</strong> is dedicated to improving object detection and classification through image processing and machine learning, with practical applications in biomedical systems, traffic monitoring, and surveillance.<sup>31</sup> The <strong>Ateneo Social Computing Science Lab</strong> studies human and group behaviors through natural language analysis and movements, conducting research in social media analytics and agent-based simulations.<sup>31</sup> Furthermore, the <strong>Ateneo Virtual, Augmented, and Mixed Reality Laboratory (VAMR)</strong> develops AR/VR applications for education, entertainment, and training, enhancing AR technology through interactive game scripting and hand gesture detection.<sup>31</sup> Faculty members, such as Maria Mercedes T. Rodrigo, PhD, demonstrate specific research interests in artificial intelligence in education, learning analytics, and educational games.<sup>31</sup></p><p>Ateneo’s approach to AI, primarily through a data science minor/specialization and robust research laboratories, indicates that AI is viewed as a powerful tool applicable across various domains rather than solely a standalone discipline. The diverse applications of AI in their research—spanning sound, vision, social computing, and extended reality—highlight this interdisciplinary focus. The inclusion of AI/ML as direct career paths for Computer Engineering graduates further reinforces the practical integration of AI competencies. The university’s strategy is to cultivate AI expertise through a strong emphasis on applied research and interdisciplinary collaboration, producing graduates who can apply AI principles creatively and ethically across various sectors, demonstrating a commitment to innovation that extends beyond core computer science to broader societal impact.</p><p><strong>FEU Institute of Technology (FEU Tech): Industry-Focused AI Specialization</strong></p><figure class="post__image"><img src="https://cdn.rogverse.fyi/feu.png" alt="FEU" data-is-external-image="true"></figure><p>FEU Institute of Technology (FEU Tech) offers a Bachelor of Science in Computer Science with a specialization in Artificial Intelligence.<sup>33</sup> This specialization is specifically designed to provide students with essential competencies for innovation within the AI field. The curriculum covers a wide array of topics, including problem-solving, reasoning, understanding natural language, speech recognition, and computer vision.<sup>33</sup> The program’s design emphasizes equipping students with the skills and expertise necessary to deploy AI algorithmic solutions that adhere to prevailing industry standards and best practices.<sup>33</sup> Graduates are expected to demonstrate capabilities in managing efficiency and automation, personalization, data analysis and insights, and creating predictive and prescriptive solutions.<sup>33</sup></p><p>While the exact program duration for the BSCS with AI specialization is not explicitly stated in the provided information <sup>33</sup>, general information about FEU’s College of Engineering mentions a “trimestral (four years and one term) program”.<sup>36</sup> Additionally, some BS IT curricula are outlined as 3 years.<sup>37</sup> Prospective students should directly confirm the specific duration for the AI specialization. The program prepares graduates for a wide array of AI-related careers, reflecting the growing demand in the industry. These roles include Machine Learning Engineer, Data Scientist, AI Research Scientist, Robotics Engineer, Natural Language Processing (NLP) Engineer, Computer Vision Engineer, AI Ethics and Bias Specialist, AI Product Manager, AI Consultant, AI Software Developer, AI in Healthcare Specialist, and Cybersecurity Analyst specializing in AI.<sup>33</sup> Beyond academic offerings, FEU Diliman also engages in an “AI in Action” program, which aims to leverage AI for sustainable community development in the Philippines, addressing critical challenges in governance, economic growth, and environmental sustainability.<sup>38</sup></p><p>FEU Tech’s AI program is clearly geared towards producing industry-ready professionals. The curriculum’s focus on practical deployment and adherence to industry standards, coupled with a wide range of career paths, makes it highly attractive for students seeking immediate employment in the burgeoning AI sector. The inclusion of roles like “AI Ethics and Bias Specialist” demonstrates an awareness of the broader societal implications of AI development. The “AI in Action” program further highlights a commitment to applying AI for tangible societal benefit, suggesting a program that balances technical proficiency with a sense of social responsibility. The ambiguity in program duration, however, remains a point of concern for prospective students, necessitating direct inquiry for clarity.</p><p><strong>Adamson University: AI Integration and International Dual Degree</strong></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/adamson.png" alt="adamson" data-is-external-image="true"></figure><p>Adamson University offers a Bachelor of Science in Computer Science and Information Engineering, a dual degree program established in collaboration with Minghsin University of Science and Technology (MUST) in Taiwan.<sup>39</sup> This interdisciplinary dual degree program incorporates Artificial Intelligence, Machine Learning, and Natural Language Processing as key sub-areas within its software systems component.<sup>39</sup> The program is designed to provide students with in-depth knowledge and skills from both computer science and information engineering, thereby preparing them for global competence in the technology sector.<sup>39</sup></p><p>Within Adamson’s standalone BS Computer Science curriculum (Curriculum Year 2022), “CS425A: Artificial Intelligence” is listed as a required 3-unit course in the Third Year, 1st Semester.<sup>41</sup> Additionally, “CS461: Machine Learning LEC” and “CS461L: Machine Learning LAB” are offered as electives under “REQUIRED SPECIALIZATION COURSE 3”.<sup>41</sup> A notable development in Adamson University’s commitment to AI education is the College of Computer and Information Technology’s (CCIT) achievement of being the first academic institution in the Philippines to complete the Google AI Essentials Program for <em>all</em> its faculty and staff.<sup>43</sup> This initiative, a strategic partnership with the IT and Business Process Association of the Philippines (IBPAP) and Google, focused on foundational AI concepts, responsible use of generative tools, and effective prompting techniques.<sup>43</sup> The explicit goal of this faculty development is to integrate these lessons and resources directly into the curriculum, thereby enhancing student learning and preparing them for real-world opportunities.<sup>43</sup></p><p>Adamson University is implementing a strategic, foundational approach to AI education by first ensuring its educators are proficient in the latest AI concepts. This commitment to comprehensive faculty development suggests a robust and continuously updated AI curriculum, as the knowledge gained by faculty will directly translate into enhanced teaching and learning experiences for students. This proactive measure positions Adamson to offer highly relevant and current AI education, potentially leading to a more dynamic and adaptable learning environment for students in AI and related fields.</p><p><strong>University of Santo Tomas (UST): Dedicated AI Bachelor’s and Interdisciplinary Research</strong></p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/ustph.png" alt="UST" data-is-external-image="true"></figure><p>The University of Santo Tomas (UST) demonstrates a significant commitment to AI education through its comprehensive Bachelor of Artificial Intelligence, a 4-year program designed to cultivate distinguished and globally qualified students in the field.<sup>44</sup> This dedicated undergraduate program features an extensive curriculum that covers a wide spectrum of mandatory and elective AI courses. These include “Introduction to Artificial Intelligence (CS401),” “Introduction to Machine Learning (CAI501),” “Advanced Machine Learning (CAI706),” “Artificial Neural Networks (CAI505),” “Introduction to Deep Learning (CA601),” “Natural Language Processing (CAI602),” “Introduction to Computer Vision (CAI606),” “Introduction to Robotics (CAI801),” and “Ethics in Artificial Intelligence (CAI802)”.<sup>44</sup> Other related courses encompass Data Mining and Big Data Analysis (CAI701), AI Applications and Case Studies (CAI805), Game Design and Virtual Reality (CAI806), as well as Modeling and Simulation, Intelligent Control Systems, Image Processing Basics, Data Science Principles, and Internet of Things.<sup>44</sup></p><p>Beyond the specialized AI degree, UST’s Bachelor of Science in Computer Science program also integrates AI concepts through its “Data Science” track, which focuses on equipping students with mathematical analysis and programming skills for data-driven solutions.<sup>45</sup> The “Core Computer Science” track may also include special topics in “natural languages” and “cognitive and scientific computing”.<sup>45</sup> Notably, the BSCS curriculum includes “CS 2618: Introduction to Intelligent Systems”.<sup>46</sup></p><p>UST is actively involved in AI research, with several notable initiatives. The “iSULAT” project, an AI-driven pen developed in collaboration between the Faculty of Engineering and the College of Rehabilitation Sciences, aims for early detection of neurodevelopmental conditions like ADHD and ASD.<sup>47</sup> Another project, “AI in Pharmacology &amp; Drug Discovery,” demonstrates how AI can accelerate drug design by analyzing molecular structures and predicting compound behavior.<sup>47</sup> The university also engages in research focused on “Ensuring Responsible Artificial Intelligence (AI) Adoption in the Philippines: Towards a Comprehensive AI Regulatory Framework,” and maintains a strong emphasis on “AI responsibility, ethics” in its research endeavors.<sup>47</sup> Furthermore, UST has established international research collaborations with world-class academic institutions such as Stanford Artificial Intelligence Laboratory (SAIL) and MIT Computer Science and AI Laboratory (CSAIL). These partnerships focus on research and innovation in data-driven solutions, covering areas like Natural Language Processing, Computer Vision, Anomaly Detection, and Reinforcement Learning.<sup>49</sup></p><p>UST’s strategy is to cultivate deeply specialized AI talent from the undergraduate level, preparing graduates for roles directly within the AI field. Their extensive curriculum ensures a strong foundation across various AI domains. Concurrently, their research efforts demonstrate a commitment to applying AI for tangible societal benefit (e.g., healthcare, policy) and upholding ethical principles. This dual focus positions UST as a key institution for students seeking a comprehensive, ethically-grounded AI education with opportunities to engage in impactful, interdisciplinary research.</p><h3 id="comparative-analysis-of-ai-programs"><strong>Comparative Analysis of AI Programs</strong></h3>
<p>A structured comparison of AI programs across leading Philippine institutions reveals distinct approaches and shared priorities, offering valuable insights for prospective students. The following tables summarize the key characteristics of these programs, allowing for a rapid assessment of their offerings and focus areas.</p><p><strong>Table 1: AI Program Offerings by University</strong>
<figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/pawelzmarlak-2025-05-27T03_49_41.928Z.png" alt="AI Program Offerings by University" data-is-external-image="true"></figure></p><p><strong>Table 2: Core AI Coursework Across Institutions</strong>
<figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/pawelzmarlak-2025-05-27T03_50_06.759Z.png" alt="Core AI Coursework Across Institutions" data-is-external-image="true"></figure></p><h3 id="admission-requirements-and-application-insights"><strong>Admission Requirements and Application Insights</strong></h3>
<p>Admission into AI programs in Philippine higher education institutions typically involves a set of general and specific criteria designed to ensure that prospective students possess the foundational academic aptitude for these demanding fields.</p><p><strong>A. General Admission Requirements</strong></p><p>Across various programs and institutions, common requirements for admission generally include a minimum age of 18 years and demonstrated fluency in English.<sup>9</sup> Applicants are consistently expected to have “above average grades,” indicating the necessity of a strong academic record prior to application.<sup>9</sup></p><p><strong>B. Specific Program Requirements</strong></p><p>Specific programs impose additional requirements tailored to their unique academic demands:</p><ul>
<li><strong>UP Diliman MEng AI:</strong> Requires a comprehensive set of documents, including a Curriculum Vitae, English Language Certificate, Personal Statement, Highest Academic Transcript (in English), a Photograph, Graduation Certificate (in English), and a Passport Copy.<sup>9</sup></li>
<li><strong>DLSU-Dasmariñas BSCS Intelligent Systems:</strong> Freshmen applicants must have satisfactorily completed senior high school, passed the DLSU-D Student Admissions Test (DSAT) with the program’s required cut-off scores, and successfully passed an interview with the Department Chair.<sup>23</sup> Transferees and students seeking a second course face additional stipulations, such as a minimum GPA (at least 2.00), no failing grades in any courses, submission of recommendation letters, and for BCS applicants, passing a qualifying exam.<sup>23</sup></li>
<li><strong>Ateneo de Manila University Minor/Specialization in Data Science and Analytics:</strong> Students pursuing this minor or specialization need to have achieved an average grade of C in previously taken Math courses and must have successfully completed an introductory programming course (CSCI 21 / MSYS 21: Introduction to Programming I). Furthermore, a minimum C average is required for all courses counting towards the Minor/Specialization.<sup>29</sup></li>
</ul>
<p>The admission requirements collectively indicate that while AI is a cutting-edge field, success in these programs is heavily reliant on strong foundational skills in mathematics, statistics, and computer programming. Prospective students should prioritize excelling in these core subjects during their prior academic pursuits. The inclusion of interviews and specific entrance examinations for some programs suggests an assessment of a candidate’s analytical thinking, problem-solving aptitude, and genuine interest in the field, moving beyond mere academic grades to evaluate overall suitability for the demanding nature of AI studies. This holistic evaluation approach aims to identify candidates who are not only academically prepared but also possess the intrinsic qualities necessary to thrive in an evolving technological landscape.</p><h3 id="career-prospects-for-ai-graduates"><strong>Career Prospects for AI Graduates</strong></h3>
<p>Graduates from AI-related programs in the Philippines are entering a dynamic and rapidly expanding job market, characterized by a consistent and growing demand for professionals with specialized AI expertise.<sup>1</sup> The roles available span various industries, reflecting the pervasive integration of AI technologies across economic sectors.</p><p>Common career paths for AI graduates include:</p><ul>
<li><strong>AI Engineer:</strong> Responsible for designing and deploying AI models to enhance business decisions.<sup>2</sup></li>
<li><strong>Machine Learning Engineer:</strong> Develops systems that enable machines to learn from data, applying predictive models for various applications.<sup>2</sup></li>
<li><strong>Data Scientist:</strong> Analyzes complex datasets to derive insights that drive profitability, efficiency, and strategic decision-making.<sup>2</sup></li>
<li><strong>AI Research Scientist:</strong> Operates at the forefront of AI innovation, conducting research to solve complex problems using deep learning, statistics, and machine learning methodologies.<sup>2</sup></li>
<li><strong>Robotics Engineer:</strong> Focuses on the design, development, and application of robotic systems.<sup>33</sup></li>
<li><strong>Natural Language Processing (NLP) Engineer:</strong> Specializes in developing computer programs that process and understand human language.<sup>33</sup></li>
<li><strong>Computer Vision Engineer/Image Data Analyst:</strong> Works on improving object detection, classification, and image processing techniques.<sup>23</sup></li>
<li><strong>AI Ethics and Bias Specialist:</strong> Addresses the ethical implications, privacy concerns, and potential biases inherent in AI systems.<sup>33</sup></li>
<li><strong>AI Product Manager:</strong> Oversees the development and lifecycle of AI-powered products.</li>
<li><strong>AI Consultant:</strong> Provides expert advice to organizations on AI strategy and implementation.</li>
<li><strong>AI Software Developer:</strong> Creates intelligent applications that integrate advanced algorithms and user-friendly design.</li>
<li><strong>AI in Healthcare Specialist:</strong> Applies AI solutions specifically within the medical sector for diagnostics, personalized treatments, and service development.<sup>33</sup></li>
<li><strong>Cybersecurity Analyst specializing in AI:</strong> Focuses on leveraging AI for enhanced security measures and threat detection.<sup>33</sup></li>
</ul>
<p>These diverse roles highlight that AI skills are highly transferable and applicable across a multitude of industries, ensuring that graduates are well-equipped to adapt to the evolving demands of the global job market.<sup>1</sup> The emphasis placed by universities on developing critical thinking, problem-solving, and data analysis skills further enhances the versatility and employability of AI graduates.</p><h3 id="final-thoughts"><strong>Final Thoughts</strong></h3>
<p>The landscape of Artificial Intelligence education in the Philippines is rapidly evolving, reflecting a concerted effort by leading universities to meet the escalating global and local demand for AI professionals. Institutions like Mapúa University, the University of the Philippines Diliman, De La Salle University, Ateneo de Manila University, FEU Institute of Technology, and the University of Santo Tomas are at the forefront of this transformation, each contributing uniquely to the national AI ecosystem.</p><p>Mapúa University has pioneered a dedicated Bachelor of Science in AI Engineering, emphasizing a multidisciplinary approach and strong industry collaborations, including with global leaders like OpenAI. This forward-thinking strategy positions Mapúa as a key institution for developing specialized AI talent. UP Diliman, as the national flagship university, focuses on advanced AI studies through its Master of Engineering and Doctor of Philosophy programs, underpinned by extensive research laboratories and a commitment to shaping ethical AI development through its “Principles for Responsible Artificial Intelligence.” This highlights a deep academic and research commitment to advancing the fundamental knowledge and application of AI.</p><p>De La Salle University, through its campuses in Dasmariñas and Manila, integrates AI within its Computer Science programs, offering specializations or tracks that build AI expertise upon a strong foundational computing background. This approach aims to produce versatile graduates capable of applying AI in practical scenarios. Ateneo de Manila University emphasizes an interdisciplinary approach, integrating AI concepts primarily through its Data Science and Analytics minor/specialization and fostering extensive applied AI research across various domains, from sound and vision to social computing and extended reality. This focus prepares students to leverage AI for diverse applications and societal impact.</p><p>FEU Institute of Technology stands out for its industry-aligned BS in Computer Science with an AI specialization, focusing on equipping students with practical skills to deploy AI solutions that meet industry standards. Their commitment extends to applying AI for community development, demonstrating a balance between technical proficiency and social responsibility. Adamson University’s dual degree program with an international partner and its institution-wide faculty development in AI underscore a strategic investment in human capital, ensuring a continuously updated and relevant AI curriculum for its students. Finally, the University of Santo Tomas offers a comprehensive Bachelor of Artificial Intelligence, providing a broad and deep undergraduate foundation in AI, coupled with active interdisciplinary research that addresses ethical considerations and real-world problems.</p><p>Collectively, these institutions are not only producing a skilled AI workforce but are also contributing to the ethical and responsible integration of AI into Philippine society. While variations exist in program structure—from dedicated AI degrees to specializations within broader computer science curricula and integrated courses—a common thread is the recognition of AI’s transformative power and the imperative to educate professionals who can harness this power for national development. Prospective students are encouraged to carefully consider their academic goals, the specific AI topics they wish to pursue, and the unique strengths of each institution, while also directly verifying program details such as duration and specific course offerings. The future of AI in the Philippines is being shaped by these academic endeavors, promising a generation of innovators poised to drive technological advancement and societal progress.</p><h4 id="works-cited">Works cited</h4>
<ol>
<li>AI for Learning: Finding AI-Integrated Courses | Mapúa - Mapua University, accessed May 27, 2025, <a href="https://www.mapua.edu.ph/blog/ai-for-learning-be-future-ready-with-ai-embedded-courses">https://www.mapua.edu.ph/blog/ai-for-learning-be-future-ready-with-ai-embedded-courses</a></li>
<li>Bachelor of Science in AI Engineering | Mapúa - Mapua University, accessed May 27, 2025, <a href="https://www.mapua.edu.ph/pages/academics/undergraduate/intramuros-campus/school-of-electrical-electronics-and-computer-engineering/bachelor-of-science-in-artificial-intelligence-engineering">https://www.mapua.edu.ph/pages/academics/undergraduate/intramuros-campus/school-of-electrical-electronics-and-computer-engineering/bachelor-of-science-in-artificial-intelligence-engineering</a></li>
<li>University of the Philippines Principles for Responsible and Trustworthy Artificial Intelligence, accessed May 27, 2025, <a href="https://up.edu.ph/up-principles-for-responsible-artificial-intelligence/">https://up.edu.ph/up-principles-for-responsible-artificial-intelligence/</a></li>
<li>Critical Thinking with an AI-Powered Curriculum | Mapúa - Mapua University, accessed May 27, 2025, <a href="https://www.mapua.edu.ph/blog/enhance-your-learning-experience-and-develop-critical-thinking-skills-with-the-help-of-an-ai-infused-curriculum">https://www.mapua.edu.ph/blog/enhance-your-learning-experience-and-develop-critical-thinking-skills-with-the-help-of-an-ai-infused-curriculum</a></li>
<li>Fully Online Courses and Programs at Mapúa University, accessed May 27, 2025, <a href="https://www.mapua.edu.ph/pages/academics/fully-online-programs">https://www.mapua.edu.ph/pages/academics/fully-online-programs</a></li>
<li>Online Undergraduate Courses and Programs at Mapúa University, accessed May 27, 2025, <a href="https://www.mapua.edu.ph/pages/academics/fully-online-programs/undergraduate">https://www.mapua.edu.ph/pages/academics/fully-online-programs/undergraduate</a></li>
<li>Pursue Bachelor of Science in Electronics Engineering | Mapúa - Mapua University, accessed May 27, 2025, <a href="https://www.mapua.edu.ph/pages/academics/undergraduate/intramuros-campus/school-of-electrical-electronics-and-computer-engineering/bachelor-of-science-in-electronics-engineering">https://www.mapua.edu.ph/pages/academics/undergraduate/intramuros-campus/school-of-electrical-electronics-and-computer-engineering/bachelor-of-science-in-electronics-engineering</a></li>
<li>Pursue a Degree in Electrical Engineering Online | Mapúa - Mapua University, accessed May 27, 2025, <a href="https://www.mapua.edu.ph/pages/academics/fully-online-programs/undergraduate/programs/online-bachelor-of-science-in-electrical-engineering">https://www.mapua.edu.ph/pages/academics/fully-online-programs/undergraduate/programs/online-bachelor-of-science-in-electrical-engineering</a></li>
<li>Master’s in Artificial Intelligence at University of the Philippines Diliman | Global Admissions, accessed May 27, 2025, <a href="https://www.globaladmissions.com/program/masters-artificial-intelligence/pMUNIQLV0">https://www.globaladmissions.com/program/masters-artificial-intelligence/pMUNIQLV0</a></li>
<li>Artificial Intelligence – UPD College of Engineering, accessed May 27, 2025, <a href="https://coe.upd.edu.ph/masters-of-engineering-in-artificial-intelligence/">https://coe.upd.edu.ph/masters-of-engineering-in-artificial-intelligence/</a></li>
<li>Doctor of Philosophy in Artificial Intelligence - Pages, accessed May 27, 2025, <a href="https://pages.upd.edu.ph/artificial-intelligence-program/doctor-philosophy-artificial-intelligence">https://pages.upd.edu.ph/artificial-intelligence-program/doctor-philosophy-artificial-intelligence</a></li>
<li>PhD in Artificial Intelligence at University of the Philippines Diliman | Global Admissions, accessed May 27, 2025, <a href="https://www.globaladmissions.com/program/phd-artificial-intelligence-at-university-philippines-diliman/pPUNIMR50">https://www.globaladmissions.com/program/phd-artificial-intelligence-at-university-philippines-diliman/pPUNIMR50</a></li>
<li>Undergraduate program - UP DCS, accessed May 27, 2025, <a href="https://dcs.upd.edu.ph/academics/undergraduate-program/">https://dcs.upd.edu.ph/academics/undergraduate-program/</a></li>
<li>BSCS – Curriculum - University of the Philippines Tacloban College, accessed May 27, 2025, <a href="https://www.uptacloban.edu.ph/bscs-curriculum/">https://www.uptacloban.edu.ph/bscs-curriculum/</a></li>
<li>CMSC 210 - Faculty of Information and Communication Studies, accessed May 27, 2025, <a href="https://fics.upou.edu.ph/diploma-in-computer-science/cmsc-210/">https://fics.upou.edu.ph/diploma-in-computer-science/cmsc-210/</a></li>
<li>UPOU Releases Guidelines on AI Use for Teaching and Learning, accessed May 27, 2025, <a href="https://www.upou.edu.ph/news/upou-releases-guidelines-on-ai-use-for-teaching-and-learning/">https://www.upou.edu.ph/news/upou-releases-guidelines-on-ai-use-for-teaching-and-learning/</a></li>
<li>UP Diliman Department of Computer Science - Wikipedia, accessed May 27, 2025, <a href="https://en.wikipedia.org/wiki/UP_Diliman_Department_of_Computer_Science">https://en.wikipedia.org/wiki/UP_Diliman_Department_of_Computer_Science</a></li>
<li>Program in Management of Artificial Intelligence in the Enterprise | La Salle, accessed May 27, 2025, <a href="https://www.salleurl.edu/en/education/program-management-artificial-intelligence-enterprise">https://www.salleurl.edu/en/education/program-management-artificial-intelligence-enterprise</a></li>
<li>Artificial Intelligence (M.S.) - La Salle University, accessed May 27, 2025, <a href="https://www.lasalle.edu/programs/artificial-intelligence-m-s/">https://www.lasalle.edu/programs/artificial-intelligence-m-s/</a></li>
<li>La Salle University CIS, accessed May 27, 2025, <a href="https://apply.lasalle.edu/portal/gr_cis">https://apply.lasalle.edu/portal/gr_cis</a></li>
<li>MSc Artificial Intelligence - Master’s degree • City St George’s, University of London, accessed May 27, 2025, <a href="https://www.citystgeorges.ac.uk/prospective-students/courses/postgraduate/artificial-intelligence">https://www.citystgeorges.ac.uk/prospective-students/courses/postgraduate/artificial-intelligence</a></li>
<li>La Salle University expands Computer Science programs with new degrees in AI and cybersecurity, accessed May 27, 2025, <a href="https://www.lasalle.edu/news/la-salle-university-expands-computer-science-programs-with-new-degrees-in-ai-and-cybersecurity/">https://www.lasalle.edu/news/la-salle-university-expands-computer-science-programs-with-new-degrees-in-ai-and-cybersecurity/</a></li>
<li>Bachelor of Science in Computer Science | Program Offerings …, accessed May 27, 2025, <a href="https://www.dlsud.edu.ph/programs/cics/bcs.htm">https://www.dlsud.edu.ph/programs/cics/bcs.htm</a></li>
<li>Bachelor of Science in Computer Science Major in Software …, accessed May 27, 2025, <a href="https://www.dlsu.edu.ph/colleges/ccs/undergraduate-degree-programs/cs-st/">https://www.dlsu.edu.ph/colleges/ccs/undergraduate-degree-programs/cs-st/</a></li>
<li>Bachelor of Science in Computer Science Major in Network and Information Security, accessed May 27, 2025, <a href="https://www.dlsu.edu.ph/colleges/ccs/undergraduate-degree-programs/cs-nis/">https://www.dlsu.edu.ph/colleges/ccs/undergraduate-degree-programs/cs-nis/</a></li>
<li>BS Computer Science major in Computer Systems Engineering - De La Salle University, accessed May 27, 2025, <a href="https://www.dlsu.edu.ph/colleges/ccs/undergraduate-degree-programs/cs-cse/">https://www.dlsu.edu.ph/colleges/ccs/undergraduate-degree-programs/cs-cse/</a></li>
<li>BS in Computer Science with Specialization in Software Technology | De La Salle University, accessed May 27, 2025, <a href="https://coursefinder.ph/courses/2889/bs-in-computer-science-with-specialization-in-software-technology/details">https://coursefinder.ph/courses/2889/bs-in-computer-science-with-specialization-in-software-technology/details</a></li>
<li>De La Salle University: Computer Science courses offered - FindUniversity.ph, accessed May 27, 2025, <a href="https://www.finduniversity.ph/universities/de-la-salle-university-manila/courses/computer-science/">https://www.finduniversity.ph/universities/de-la-salle-university-manila/courses/computer-science/</a></li>
<li>Undergraduate Minors | Academics | Information Systems and …, accessed May 27, 2025, <a href="https://www.ateneo.edu/sose/discs/academics/minors">https://www.ateneo.edu/sose/discs/academics/minors</a></li>
<li>Academic Programs | ECCE - Ateneo de Manila University, accessed May 27, 2025, <a href="https://www.ateneo.edu/sose/ecce/academic-programs">https://www.ateneo.edu/sose/ecce/academic-programs</a></li>
<li>Research | Information Systems and Computer Science | Ateneo de …, accessed May 27, 2025, <a href="https://www.ateneo.edu/sose/discs/research">https://www.ateneo.edu/sose/discs/research</a></li>
<li>Faculty and Staff | Ateneo Laboratory for the Learning Sciences, accessed May 27, 2025, <a href="https://alls.ateneo.edu/staff-2">https://alls.ateneo.edu/staff-2</a></li>
<li>Bachelor of Science in Computer Science - FEU Institute of …, accessed May 27, 2025, <a href="https://www.feutech.edu.ph/academics/bscs">https://www.feutech.edu.ph/academics/bscs</a></li>
<li>Bachelor of Science in Computer Science with specialization in Artificial Intelligence - FEU Alabang, accessed May 27, 2025, <a href="https://feualabang.edu.ph/academics/bscsai">https://feualabang.edu.ph/academics/bscsai</a></li>
<li>Bachelor of Science in Computer Science with Specialization in Data Science - FEU Tech, accessed May 27, 2025, <a href="https://www.feutech.edu.ph/academics/bscsds">https://www.feutech.edu.ph/academics/bscsds</a></li>
<li>Far Eastern University Institute of Technology - Wikipedia, accessed May 27, 2025, <a href="https://en.wikipedia.org/wiki/Far_Eastern_University_Institute_of_Technology">https://en.wikipedia.org/wiki/Far_Eastern_University_Institute_of_Technology</a></li>
<li>BS IT Curriculum 2022 2023 FEU Tech | PDF | Computer Programming - Scribd, accessed May 27, 2025, <a href="https://www.scribd.com/document/684155985/BS-IT-Curriculum-2022-2023-FEU-Tech">https://www.scribd.com/document/684155985/BS-IT-Curriculum-2022-2023-FEU-Tech</a></li>
<li>AI in Action: Advancing Community Development Through Artificial Intelligence - FEU Diliman, accessed May 27, 2025, <a href="https://feudiliman.edu.ph/feudiliman/features/ai-in-action-advancing-community-development-through-artificial-intelligence">https://feudiliman.edu.ph/feudiliman/features/ai-in-action-advancing-community-development-through-artificial-intelligence</a></li>
<li>What is Computer Science and Information Engineering? - Adamson University, accessed May 27, 2025, <a href="https://www.adamson.edu.ph/v1/?page=dual-degree-cs-ie-home">https://www.adamson.edu.ph/v1/?page=dual-degree-cs-ie-home</a></li>
<li>Sub-Areas of Computer Science and Information Engineering - Adamson University, accessed May 27, 2025, <a href="https://www.adamson.edu.ph/v1/?page=dual-degree-cs-ie-subareas">https://www.adamson.edu.ph/v1/?page=dual-degree-cs-ie-subareas</a></li>
<li>Curriculum Year 2022 - Adamson University, accessed May 27, 2025, <a href="https://www.adamson.edu.ph/v1/?page=curriculum&cid=+++++n&curryear=2022">https://www.adamson.edu.ph/v1/?page=curriculum&amp;cid=%20%20%20%20%20n&amp;curryear=2022</a></li>
<li>bs computer science - Adamson University, accessed May 27, 2025, <a href="https://www.adamson.edu.ph/v1/?page=pos-course&amp;course=n">https://www.adamson.edu.ph/v1/?page=pos-course&amp;course=n</a></li>
<li>Charting a Digital Future: CCIT becomes first PH University to complete IBPAP-Google AI Essentials program, accessed May 27, 2025, <a href="https://www.adamson.edu.ph/v1/?page=view-news&amp;newsid=3410">https://www.adamson.edu.ph/v1/?page=view-news&amp;newsid=3410</a></li>
<li>بكالوريوس الذكاء الإصطناعي - جامعة العلوم والتكنولوجيا, accessed May 27, 2025, <a href="https://ust.edu/en/faculty-of-engineering-and-computing/bachelor-of-artificial-intelligence/">https://ust.edu/en/faculty-of-engineering-and-computing/bachelor-of-artificial-intelligence/</a></li>
<li>Department of Computer Science - University of Santo Tomas, accessed May 27, 2025, <a href="https://www.ust.edu.ph/information-and-computing-sciences/department-of-computer-science/">https://www.ust.edu.ph/information-and-computing-sciences/department-of-computer-science/</a></li>
<li>Bachelor of Science in Computer Science - University of Santo Tomas, accessed May 27, 2025, <a href="https://www.ust.edu.ph/academics/programs/bachelor-of-science-in-computer-science/">https://www.ust.edu.ph/academics/programs/bachelor-of-science-in-computer-science/</a></li>
<li>UST Research Fortnight: Thomasians integrate AI, tech across disciplines | The Varsitarian, accessed May 27, 2025, <a href="https://varsitarian.net/sci-tech/20250227/ust-research-fortnight-thomasians-integrate-ai-tech-across-disciplines-posters">https://varsitarian.net/sci-tech/20250227/ust-research-fortnight-thomasians-integrate-ai-tech-across-disciplines-posters</a></li>
<li>AI responsibility, ethics take center stage at 2025 UST Research Fortnight | The Varsitarian, accessed May 27, 2025, <a href="https://varsitarian.net/sci-tech/20250219/ai-responsibility-ethics-take-center-stage-at-2025-ust-research-fortnight">https://varsitarian.net/sci-tech/20250219/ai-responsibility-ethics-take-center-stage-at-2025-ust-research-fortnight</a></li>
<li>UST Academic Partnerships, accessed May 27, 2025, <a href="https://www.ust.com/content/dam/ust/documents/UST-Academic-Partnership_Rebranded_2.pdf">https://www.ust.com/content/dam/ust/documents/UST-Academic-Partnership_Rebranded_2.pdf</a></li>
<li>Graduate Degree Programs - UPD College of Engineering - UP Diliman, accessed May 27, 2025, <a href="https://coe.upd.edu.ph/academics-overview/graduate-degree-programs/">https://coe.upd.edu.ph/academics-overview/graduate-degree-programs/</a></li>
<li>Curriculum Year 2023 - Adamson University, accessed May 27, 2025, <a href="https://www.adamson.edu.ph/v1/?page=curriculum&cid=++++76&curryear=2023">https://www.adamson.edu.ph/v1/?page=curriculum&amp;cid=%20%20%20%2076&amp;curryear=2023</a></li>
<li>Bachelor of Science in Data Science | Mapúa - Mapua University, accessed May 27, 2025, <a href="https://www.mapua.edu.ph/pages/academics/undergraduate/makati-campus/school-of-information-technology/bachelor-of-science-in-data-science">https://www.mapua.edu.ph/pages/academics/undergraduate/makati-campus/school-of-information-technology/bachelor-of-science-in-data-science</a></li>
</ol>

            ]]>
        </content>
    </entry>
    <entry>
        <title>41 Million Smart Communications Subscriber Mobile Numbers Possibly Exposed by Critical Vulnerability</title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/41-million-smart-communications-subscriber-mobile-numbers-possibly-exposed-by-critical-vulnerability.html"/>
        <id>https://roger.rogverse.fyi/41-million-smart-communications-subscriber-mobile-numbers-possibly-exposed-by-critical-vulnerability.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/12/Smart-Live-More-Today-1.jpg" medium="image" />
            <category term="vulnerability"/>
            <category term="smart-telco"/>
            <category term="cybersecurity"/>
            <category term="Network"/>
            <category term="Blog"/>

        <updated>2025-04-18T13:15:36+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/12/Smart-Live-More-Today-1.jpg" alt="" />
                    Overview Today I’m disclosing a significant security vulnerability affecting Smart Communications (TEL) mobile subscribers in the Philippines. This vulnerability exposes customers’ mobile phone&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/12/Smart-Live-More-Today-1.jpg" class="type:primaryImage" alt="" /></p>
                <h2 id="overview">Overview</h2>
<p>Today I’m disclosing a significant security vulnerability affecting Smart Communications (<a href="https://www.marketwatch.com/investing/stock/tel?countrycode=ph">TEL</a>) mobile subscribers in the Philippines. This vulnerability exposes customers’ mobile phone numbers through insecure API communications, potentially contributing to the recent surge in SMS spam and SIM swapping attacks that have plagued Filipino mobile users.</p><h2 id="discovery-timeline">Discovery Timeline</h2>
<ul>
<li><strong>December 12, 2024</strong>: Initially discovered the vulnerability while analyzing network traffic with Wireshark</li>
<li><strong>April 15, 2025</strong>: Formal notification sent to Smart Communications with detailed findings</li>
<li><strong>April 18, 2025</strong>: No response received; publishing initial disclosure with limited technical details</li>
<li><strong>May 18, 2025</strong>: If no vendor response,  technical details and proof of concept   published</li>
</ul>
<h2 id="disclosure-timeline">Disclosure Timeline</h2>
<ul>
<li><strong>May 18, 2025</strong>: Disclosure submitted to <a href="https://hackerone.com/disclosure-assistance?type=team">HackerOne Disclosure Assistance</a> with Report ID #3151783 with Severity: Medium (4 - 6.9)</li>
<li><strong>May 18, 2025</strong>: Disclosure submitted to Google Play Store Review.</li>
</ul>
<h2 id="technical-details">Technical Details</h2>
<h3 id="information-diclosure-via-unencrypted-api-call">Information Diclosure via Unencrypted API call</h3>
<p>The vulnerability exists in an API endpoint used by <a href="https://play.google.com/store/apps/details?id=com.smart.consumer.app">Smart Communications Mobile App</a>. When users access the app, the server responds with a JSON payload containing a key called <code>x-nokia-msisdn</code> which contains the user’s full mobile phone number in plaintext.</p><p>This communication happens over standard HTTP rather than HTTPS, making it trivially interceptable on any network. The lack of encryption is especially concerning given the sensitive nature of the information being transmitted.</p><p><a href="https://cdn.rogverse.fyi/jbgoa8aOQe.png"><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/jbgoa8aOQe.png" alt="Wiresghark" data-is-external-image="true"></figure></a>
(click image to view full resolution)</p><p>Since <code>http://app1.smart.com.ph/</code> also returns <code>Bearer</code> which is the bearer header authentication and <code>x-application-token</code> which is the JWT token; we can now exploit this fusther to get the information from <code>https://app1.smart.com.ph/api/v2/quick-view?number=639190000000</code> without user login. We also able to reuse the token since it expires only after 5 days. Also note the query <code>number</code> query parameter is inconsequential – just a mere logging or security by obscurity.</p><p><a href="https://cdn.rogverse.fyi/thorium_o0sDAbnIbU.png"><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/thorium_o0sDAbnIbU.png" alt="MITM Proxy" data-is-external-image="true"></figure></a>
(click image to view full resolution)</p><p>The response show all the same data from the app wthout login which includes:</p><table>
<thead>
<tr>
<th>Name</th>
<th>Field</th>
</tr>
</thead>
<tbody><tr>
<td>Current load</td>
<td><code>&quot;balance&quot;: &quot;34.00&quot;</code></td>
</tr>
<tr>
<td>Load expiration</td>
<td><code>&quot;expiration&quot;: &quot;08-DEC-2025 12:48AM&quot;</code></td>
</tr>
<tr>
<td>Rewards point</td>
<td><code>&quot;balance&quot;: &quot;190.55&quot;,</code></td>
</tr>
<tr>
<td>Subscriptions</td>
<td><code>&quot;name&quot;: &quot;UNLI 5G DATA 599&quot;,</code></td>
</tr>
<tr>
<td>Sim registration</td>
<td><code>&quot;register_sim_banner&quot;: null,</code></td>
</tr>
</tbody></table>
<p><a href="https://cdn.rogverse.fyi/thorium_CKHZaPmOW1.png"><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/thorium_CKHZaPmOW1.png" alt="MITM Proxy" data-is-external-image="true"></figure></a>
(click image to view full resolution)</p><h3 id="android-permission-bypass">Android Permission Bypass</h3>
<p>Apps can now reliably steal a user’s mobile number with their consent, without needing to request the <code>android.permission.READ_PHONE_STATE permission</code>.\</p><h3 id="attack-vectors">Attack Vectors</h3>
<ol>
<li><p><strong>Network Monitoring</strong>: Anyone on the WiFi network can intercept this traffic using common tools like Wireshark, instantly revealing mobile numbers of all Smart customers using their apps on that network. </p></li>
<li><p><strong>Malicious Mobile Apps</strong>: While CORS protections prevent website-based exploitation, any application installed on the user’s device can directly query the vulnerable API to retrieve the <code>x-nokia-msisdn</code> value without requiring special permissions.</p></li>
<li><p><strong>Hotspot Exploitation</strong>: Users sharing their mobile connection via hotspot are vulnerable to malware on connected devices accessing this API through the established connection.</p></li>
</ol>
<p>Through additional reverse engineering using <a href="https://github.com/dweinstein/awesome-frida">Frida</a> and <a href="https://mitmproxy.org/">MITM</a> proxy tools, I was able to map numerous API method calls that transmit this sensitive information, suggesting the vulnerability is pervasive throughout their systems.</p><h2 id="impact-assessment">Impact Assessment</h2>
<p>Based on the evidence gathered, I strongly believe this vulnerability has been actively exploited for years and represents a primary vector for how SMS spammers and SIM swap scammers have been able to:</p><ul>
<li>Gather comprehensive databases of active Smart mobile numbers</li>
<li>Target specific subscribers with high confidence in number validity</li>
<li>Execute sophisticated phishing campaigns with user-specific information</li>
<li>Potentially facilitate SIM swap attacks by providing the first piece of information needed</li>
</ul>
<h3 id="cvss-score">CVSS Score</h3>
<p>The unofficial CVSS score for this vulnerability is:</p><pre><code>AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:N/A:N/E:P/RL:X/RC:U/CR:L/IR:L/AR:L/MAV:N/MAC:L/MPR:N/MUI:X/MS:U/MC:N/MI:N/MA:N
</code></pre>
<p>This translates to a <strong>Medium severity</strong> vulnerability with network-based attack vectors requiring low complexity to exploit, with no authentication needed.</p><h2 id="recommendations-for-users">Recommendations for Users</h2>
<p>While waiting for Smart Communications to address this vulnerability:</p><ol>
<li><strong>Limit app usage on hotspot</strong>: When possible, avoid sharing internet via hotspot to other devices such a laptops, tvboxes. etc.</li>
<li><strong>Be cautious with app permissions</strong>: Minimize the number of applications installed on your device, particularly those requesting network access.</li>
<li><strong>Monitor for suspicious activity</strong>: Be vigilant for unusual SMS messages, unexpected account access, or other signs your number may have been compromised</li>
<li><strong>Consider secondary authentication</strong>: Where possible, use app-based authentication methods rather than SMS-based verification</li>
</ol>
<h2 id="vendor-response">Vendor Response</h2>
<p>As of publication, Smart Communications has not responded to the vulnerability disclosure submitted on April 15, 2025. The vulnerability remains open and unaddressed.</p><p>Smart Communications has no publicly published contact information for vulnerability disclosure, so we also made best efforts to contact key persons that can act on our disclosure without success.</p><table>
<thead>
<tr>
<th>Name</th>
<th>Position</th>
<th>Response</th>
</tr>
</thead>
<tbody><tr>
<td><a href="https://www.linkedin.com/in/ronald-ryan-ruiz-9a330a90/">Ronald Ryan Ruiz</a></td>
<td>Cyber Security Solution Architect, Strategist</td>
<td>No Response</td>
</tr>
<tr>
<td><a href="https://www.linkedin.com/in/ma-kristina-angela-ycasas-5801a29b/">Ma. Kristina Angela Ycasas</a></td>
<td>Cyber Security Operations (IAM) - Information Security Supervisor</td>
<td>No Response</td>
</tr>
<tr>
<td><a href="https://www.linkedin.com/in/noelperlas/">Noel Perlas</a></td>
<td>VP - App Product Design &amp; Management @ Smart Communications, Inc. / UI/UX Design</td>
<td>No Response</td>
</tr>
<tr>
<td><a href="https://www.linkedin.com/in/favian-ong-61920211/">Favian Ong</a></td>
<td>IT Security Manager at Smart Communications</td>
<td>No Response</td>
</tr>
</tbody></table>
<p>No response was received within 30 days of the initial disclosure (by May 18, 2025).</p><h2 id="responsible-disclosure">Responsible Disclosure</h2>
<p>This disclosure follows standard responsible disclosure practices, giving the vendor appropriate time to address the issue before publishing technical details that could facilitate exploitation. The limited information provided here is sufficient to alert users to the risk without enabling new attack vectors.</p><h2 id="recommended-vulnerability-mitigation-plan">Recommended Vulnerability Mitigation Plan</h2>
<p>My suggestion for fast mitigation plan since this vulnerabiliy is already actively exploited long before this research is conducted.</p><h3 id="immediate-actions-0-7-days">Immediate Actions (0-7 days)</h3>
<ol>
<li><p><strong>Implement HTTPS/TLS</strong></p><ul>
<li>Immediately deploy SSL certificates for all API endpoints, especially app1.smart.com.ph</li>
<li>Configure secure TLS 1.3 protocols with modern cipher suites</li>
<li>Implement HSTS (HTTP Strict Transport Security) to prevent downgrade attacks</li>
</ul>
</li>
<li><p><strong>Emergency Authentication</strong></p><ul>
<li>Deploy basic API authentication requirements for all endpoints (no dashboard without login)</li>
<li>Implement token-based authentication for mobile apps</li>
<li>Revoke and rotate any existing shared secrets (shorter jwt token lifetime)</li>
</ul>
</li>
<li><p><strong>Response Headers</strong></p><ul>
<li>Remove sensitive data from HTTP headers (especially x-nokia-msisdn, use session based id and pass the actual value via internal API call)</li>
<li>Implement proper Content-Security-Policy headers</li>
<li>Ensure Referrer-Policy is set to restrict information leakage</li>
</ul>
</li>
<li><p><strong>Communication</strong></p><ul>
<li>Acknowledge receipt of vulnerability report to researcher</li>
<li>Prepare customer communication strategy</li>
<li>Brief executive leadership on situation severity</li>
</ul>
</li>
</ol>
<h3 id="short-term-actions-7-30-days">Short-Term Actions (7-30 days)</h3>
<ol>
<li><p><strong>API Architecture Overhaul</strong></p><ul>
<li>Implement proper OAuth 2.0 authentication flow for all APIs</li>
<li>Create secure token exchange that doesn’t expose subscriber identifiers</li>
<li>Implement rate limiting to prevent mass enumeration</li>
<li>Add request signing to prevent tampering and unauthorized access</li>
</ul>
</li>
<li><p><strong>Mobile App Updates</strong></p><ul>
<li>Push emergency updates to all mobile applications</li>
<li>Store sensitive data in secure app enclaves/keystores</li>
<li>Implement additional app-level encryption for sensitive communications</li>
</ul>
</li>
<li><p><strong>Monitoring &amp; Detection</strong></p><ul>
<li>Deploy API monitoring for unusual access patterns</li>
<li>Implement alerts for potential mass-harvesting attempts</li>
<li>Create detection mechanisms for abnormal API usage</li>
</ul>
</li>
<li><p><strong>Subscriber Protection (especially for known user of the velnerable app)</strong></p><ul>
<li>Enhance SIM swap protection procedures</li>
<li>Implement additional verification steps for high-risk transactions</li>
<li>Review SMS spam filtering algorithms</li>
</ul>
</li>
</ol>
<hr>
<p><em>I will update this post with any vendor response or patch information when available.</em></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Interacting Minds: A Research Paper on Multi-Modal/MOE AI Agent Collaboration</title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/interacting-minds-a-research-paper-on-multi-modalmoe-ai-agent-collaboration.html"/>
        <id>https://roger.rogverse.fyi/interacting-minds-a-research-paper-on-multi-modalmoe-ai-agent-collaboration.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/11/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3.jpg" medium="image" />
            <category term="research"/>
            <category term="Blog"/>
            <category term="AI"/>

        <updated>2025-04-14T09:13:26+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/11/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3.jpg" alt="" />
                    1. Introduction: The Rise of Collaborative Multi-Modal MOE AI Agents The field of artificial intelligence has witnessed a significant proliferation of AI agents,&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/11/Flux_Schnell_two_robots_talking_over_the_phone_in_1940_cartoon_3.jpg" class="type:primaryImage" alt="" /></p>
                <h2 id="1-introduction-the-rise-of-collaborative-multi-modal-moe-ai-agents"><strong>1. Introduction: The Rise of Collaborative Multi-Modal MOE AI Agents</strong></h2>
<p>The field of artificial intelligence has witnessed a significant proliferation of AI agents, evolving from rudimentary models to sophisticated entities capable of autonomous action. These agents are designed to operate independently, making decisions based on their environment, inputs, and predefined objectives to achieve specific goals.<sup>1</sup> This capacity for independent action distinguishes AI agents from traditional AI models, which typically require direct human prompting for every step.<sup>1</sup></p><p>A particularly transformative advancement in this domain is the emergence of multi-modal AI agents. Unlike unimodal systems that process only a single type of data, multi-modal agents possess the capability to understand and analyze information across various modalities, including text, images, audio, and video.<sup>1</sup> This multi-faceted understanding enables them to generate more refined and accurate outputs, significantly enhancing their versatility and applicability in complex real-world scenarios where diverse data types are prevalent and crucial for improving accuracy.<sup>1</sup></p><p>Complementing this development is the increasing adoption of the Mixture of Experts (MOE) architecture in building large-scale AI models. The MOE technique addresses the computational challenges associated with training massive models by dividing them into smaller, specialized sub-networks known as “experts”.<sup>5</sup> A crucial component of the MOE architecture is the gating network, which intelligently selects the most appropriate expert or combination of experts to process each specific input.<sup>5</sup> This approach allows for a significant increase in model capacity and performance without a proportional increase in computational cost, making it a key enabler for developing advanced AI systems.<sup>8</sup></p><p>The convergence of multi-modal AI and MOE architectures is paving the way for the next generation of intelligent systems: sophisticated multi-agent systems where autonomous, multi-modal MOE agents can interact and collaborate to tackle complex problems that would be insurmountable for individual agents.<sup>1</sup> This paradigm shift in AI promises to unlock unprecedented levels of efficiency, innovation, and problem-solving capabilities across a wide range of applications.</p><p>This research paper aims to provide a comprehensive exploration of how these advanced multi-modal MOE AI agents will interact with each other. The scope of this investigation will encompass their communication methods, collaboration strategies, the inherent advantages and potential disadvantages of autonomous interaction, the mechanisms through which they might negotiate and reach agreements, the critical role of human oversight, advanced communication techniques such as dynamic function calls and code exchange, important considerations for collaboration between agents from different entities, and the potential real-world applications of such autonomous inter-agent systems. By delving into these key aspects, this paper seeks to provide a foundational understanding of the future landscape of collaborative AI.</p><h2 id="2-foundations-understanding-multi-modal-ai-and-mixture-of-experts"><strong>2. Foundations: Understanding Multi-Modal AI and Mixture of Experts</strong></h2>
<h3 id="21-multi-modal-ai-agents"><strong>2.1 Multi-Modal AI Agents</strong></h3>
<p>At its core, an AI agent is a computational entity engineered to operate independently.<sup>1</sup> Its primary function is to perform specific tasks autonomously, making decisions based on the information it gathers from its environment, the inputs it receives, and the overarching goals it is programmed to achieve.<sup>1</sup> The defining characteristic that distinguishes an AI agent from a standard AI model is its inherent ability to act upon its environment.<sup>1</sup></p><p>Multi-modal agents represent a significant evolution beyond traditional unimodal AI systems. These advanced agents are characterized by their capacity to process and interpret data from a diverse array of modalities, including but not limited to text, images, audio, and video.<sup>1</sup> This ability to understand and analyze information across multiple sensory channels allows multi-modal agents to generate outputs that can also span these different formats.<sup>1</sup> The integration of various data types leads to outputs that are often more refined and accurate compared to those produced by systems limited to a single modality.<sup>1</sup> For instance, a multi-modal agent might be tasked with creating an image based on both a textual description and an accompanying audio file, demonstrating its ability to synthesize information from different sources.<sup>1</sup></p><p>The potential applications of multi-modal agents extend the reach of AI into a broader understanding and interaction with the physical world, moving beyond the limitations of text or image-only processing.<sup>1</sup> Consider augmented reality (AR) applications where multi-modal agents can assist users in performing everyday tasks, leveraging egocentric audio and video observational capabilities to understand the user’s actions and provide proactive interventions.<sup>9</sup> These agents can see and listen to the actions taken by users, enabling them to detect and correct mistakes, offer encouragement, or simply engage in helpful conversation, akin to a human teacher or assistant.<sup>9</sup> The ability to process diverse biological information layers, such as genomics, proteomics, and metabolomics, to enable more precise and individualized medical diagnoses and treatments further illustrates the power of multi-modal AI.<sup>1</sup></p><p>The generalized architecture of a multi-modal AI agent typically begins with an input layer that captures data from various sources, encompassing text, audio, images, and video.<sup>1</sup> This diverse input allows the agent to gather a comprehensive understanding of the user’s request or the surrounding environment.<sup>1</sup> Following the input layer are modality encoders, which are responsible for pre-processing the data specific to each modality, extracting relevant features that can be further analyzed.<sup>10</sup> A crucial component is the modality interface, which serves to align the features extracted from different modalities into a common representational space, allowing the agent to understand the relationships and dependencies between them.<sup>10</sup> At the core of the agent’s reasoning and understanding lies a Large Language Model (LLM), which processes the aligned multi-modal information to interpret the user’s intent, generate plans, and formulate responses.<sup>1</sup> Finally, the output layer is responsible for generating the agent’s response, which can also span across multiple modalities, providing information or taking actions in the most appropriate format.<sup>1</sup></p><h3 id="22-mixture-of-experts-moe-models"><strong>2.2 Mixture of Experts (MOE) Models</strong></h3>
<p>The Mixture of Experts (MOE) model represents an innovative strategy in machine learning designed to effectively address complex problems by leveraging the collective intelligence of multiple specialized sub-models, often referred to as “experts”.<sup>5</sup> This technique is particularly valuable in the context of training large language models, which often demand significant computational resources.<sup>6</sup> The MOE approach tackles this challenge by breaking down these large models into smaller, more focused networks.<sup>6</sup></p><p>Imagine an AI model structured as a team of specialists, each possessing unique expertise in a particular area.<sup>6</sup> An MOE model operates on this principle by dividing a complex task among these smaller, specialized networks.<sup>6</sup> Each expert is trained to excel in a specific aspect of the problem, enabling the model to address the overall task with greater efficiency and accuracy.<sup>6</sup> This is analogous to having a diverse team of professionals, such as doctors, mechanics, and chefs, each handling the tasks within their domain of expertise.<sup>6</sup></p><p>The architecture of an MOE model comprises several key components. The input is the problem or data that needs to be processed by the AI.<sup>6</sup> The experts are the smaller AI models, each trained to be highly proficient in a specific part of the overall problem.<sup>6</sup> The gating network acts as a manager, deciding which expert is best suited to handle each part of the input.<sup>6</sup> It examines the input and determines the appropriate expert or combination of experts to process it.<sup>6</sup> Finally, the output is the final answer or solution produced by the MOE model after the selected experts have completed their work.<sup>6</sup></p><p>The training process for an MOE model differs from that of a traditional dense model, as it is conducted on the individual components rather than the entire model at once.<sup>6</sup> During expert training, each expert is trained on a specific subset of data or tasks, allowing it to focus and develop deep expertise in its assigned area.<sup>6</sup> For example, in a language processing task, one expert might specialize in syntax while another focuses on semantics.<sup>6</sup> The gating network is trained alongside the expert networks and is tasked with learning to select the most suitable expert for a given input.<sup>6</sup> It receives the same input as the experts and learns to predict a probability distribution over the experts, indicating which one is best equipped to handle the current input.<sup>6</sup> In the joint training phase, the entire MOE system, including both the expert models and the gating network, is trained together.<sup>6</sup> This ensures that both the gating network and the experts are optimized to work in harmony, with the loss function combining the losses from the individual components to encourage a collaborative optimization approach.<sup>6</sup></p><p>The MOE architecture offers several significant advantages. By utilizing specialized models, it improves the accuracy and efficiency of decision-making for complex problems.<sup>7</sup> The modular design allows for easy expansion and adaptation to evolving challenges and data complexity, as new experts can be added without requiring a complete redesign.<sup>7</sup> Dynamic gating enables real-time adaptability, continuously enhancing decision-making and task execution.<sup>7</sup> Furthermore, MOE models optimize resource utilization by activating only the relevant experts for a given input, reducing processing needs while maintaining high performance.<sup>7</sup> Unlike conventional dense models where the entire network is executed for every input, MOE models use conditional computation to enforce sparsity, allowing for increased model capacity without a corresponding increase in the computational burden.<sup>8</sup> This balance between efficiency and performance makes MOE a promising strategy for scaling AI systems.<sup>12</sup></p><p><strong>Table 1: Comparison of Dense and MoE Models</strong></p><table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Feature</strong></td>
<td><strong>Dense Models</strong></td>
<td><strong>MoE Models</strong></td>
</tr>
<tr>
<td>Parameters (Total)</td>
<td>All parameters are active for every input</td>
<td>Large number of total parameters, but only a subset used during inference</td>
</tr>
<tr>
<td>Parameters (Active Inference)</td>
<td>Equal to total parameters</td>
<td>Significantly smaller than total parameters</td>
</tr>
<tr>
<td>Computation Cost (Training)</td>
<td>High, scales with the entire model size</td>
<td>Potentially lower due to expert parallelism and conditional computation</td>
</tr>
<tr>
<td>Computation Cost (Inference)</td>
<td>High, requires processing the entire network</td>
<td>Significantly lower as only selected experts are activated</td>
</tr>
<tr>
<td>Sparsity</td>
<td>No inherent sparsity</td>
<td>Introduces sparsity through the gating mechanism and expert selection</td>
</tr>
<tr>
<td>Specialization</td>
<td>Generalized learning across all data</td>
<td>Experts are specialized in different domains or aspects of the problem</td>
</tr>
<tr>
<td>Scalability</td>
<td>Computationally expensive to scale</td>
<td>Enables scaling to extremely large models with manageable resources</td>
</tr>
</tbody></table>
<h2 id="3-inter-agent-communication-protocols-and-methods"><strong>3. Inter-Agent Communication: Protocols and Methods</strong></h2>
<p>Effective interaction between multi-modal MOE AI agents hinges on their ability to communicate seamlessly and efficiently. Several protocols and methods are being explored to facilitate this crucial aspect of collaborative intelligence.</p><p>Natural language communication offers a highly intuitive approach, leveraging the advanced natural language understanding and generation capabilities inherent in Large Language Models.<sup>1</sup> This allows agents to exchange goals, instructions, and feedback in a manner closely resembling human conversation.<sup>1</sup> Supporting various modalities like text and voice further enhances the flexibility of these interactions, enabling agents to choose the most appropriate mode based on the specific application and context.<sup>1</sup></p><p>For tasks requiring precision and efficiency, structured data exchange provides a robust alternative. Utilizing standardized data formats such as JSON or XML enables agents to exchange task-specific information, parameters, and results in a clear and unambiguous manner.<sup>13</sup> This method also facilitates seamless integration with existing systems and platforms that rely on these well-defined data structures.<sup>13</sup></p><p>Agent Communication Languages (ACLs) offer a more formal framework for inter-agent interaction. Protocols like KQML and FIPA-ACL provide a structured approach to communication, including predefined message types known as performatives. These performatives allow agents to express various communicative acts, such as informing, requesting, and promising, leading to more semantically rich and less ambiguous exchanges through standardized message structures and interaction protocols.<sup>15</sup></p><p>Interestingly, in certain multi-agent systems, particularly those employing reinforcement learning, agents can spontaneously develop their own communication protocols and signaling mechanisms.<sup>18</sup> This phenomenon, known as emergent communication, can lead to highly efficient communication tailored to specific tasks, although the resulting “languages” may be difficult for humans to interpret.<sup>18</sup></p><p>To ensure broad interoperability across diverse AI ecosystems, several standardization efforts are underway. The Agent2Agent (A2A) protocol, developed with support from numerous technology partners, aims to standardize how AI agents communicate, securely exchange information, and coordinate actions across various platforms and frameworks, regardless of the underlying vendor or technology.<sup>13</sup> A2A is designed to enable agents to collaborate in their natural modalities, even without shared memory or context, building upon existing standards like HTTP and JSON.<sup>13</sup></p><p>Another key standardization effort is the Model Context Protocol (MCP), which focuses on enabling secure, two-way connections between AI agents and external data sources.<sup>20</sup> MCP acts as a universal standard for connecting AI systems with data sources, simplifying the process of giving AI agents access to the information they need to perform tasks effectively.<sup>21</sup> Major players like Stripe, Neo4j, and Cloudflare are already offering MCP servers, indicating its potential as a foundational protocol for AI agent interoperability.<sup>23</sup></p><p>Other notable standardization initiatives include the Agent Protocol by LangChain, an open-source project aiming to codify framework-agnostic APIs for serving LLM agents in production.<sup>22</sup> This protocol focuses on defining essential endpoints for agent interaction, such as creating tasks and triggering steps, with the goal of simplifying integration and fostering a more cohesive AI agent ecosystem.<sup>24</sup></p><p>The future of inter-agent communication will likely be characterized by a multifaceted approach. It will likely integrate the natural fluidity of natural language for high-level interactions, the structured precision of data exchange for task-specific needs, the semantic richness of ACLs for complex negotiations, and the task-optimized efficiency of emergent protocols, all while being increasingly underpinned by standardized protocols like A2A and MCP to ensure widespread interoperability across the burgeoning landscape of AI agents.</p><h2 id="4-strategies-for-collaborative-task-achievement"><strong>4. Strategies for Collaborative Task Achievement</strong></h2>
<p>The ability of multi-modal MOE AI agents to collaborate effectively is paramount for tackling complex objectives. Several key strategies are emerging to facilitate this collaboration.</p><p>A fundamental step in achieving complex goals is task decomposition. AI agents can be designed to break down high-level user-defined objectives into a prioritized list of smaller, more manageable sub-tasks.<sup>1</sup> This process often involves sophisticated planning and reasoning capabilities, allowing agents to efficiently segment tasks and determine the optimal sequence for execution.<sup>3</sup></p><p>Another crucial strategy is role specialization. Within a multi-agent system, different agents can be assigned specialized roles, each leveraging their unique expertise – potentially enhanced by an MOE architecture – to contribute to the overarching goal.<sup>27</sup> This mirrors the dynamics of human teams, where individuals with specific skills and knowledge collaborate to achieve a common objective.<sup>27</sup> For instance, in a supply chain optimization scenario, one agent might specialize in demand forecasting while another focuses on ensuring timely order fulfillment.<sup>27</sup></p><p>Effective collaboration also relies heavily on knowledge sharing. Agents must be able to exchange critical information, observations, and insights derived from their respective modalities or expert domains.<sup>29</sup> This sharing of knowledge contributes to a collective understanding of the problem at hand and informs the development of potential solutions. The use of shared knowledge bases or ontologies can further enhance this process by ensuring consistent interpretation of terms and concepts across different agents.<sup>33</sup></p><p>Coordination mechanisms play a vital role in managing the interactions between multiple agents. These mechanisms can range from centralized coordination, where a supervisor agent analyzes input, breaks down problems, and delegates tasks to sub-agents, to decentralized coordination, where agents interact directly with each other using defined communication protocols.<sup>28</sup> Agentic orchestration platforms are also being developed to provide a structured environment for managing complex workflows and ensuring seamless collaboration between agents.<sup>35</sup></p><p>In many scenarios, agents will engage in iterative refinement. This involves agents working both in parallel and sequentially, building upon each other’s outputs and iteratively improving the quality of the final result.<sup>36</sup> Cooperative agents, in particular, play a crucial role in this process by scrutinizing each other’s contributions and collaboratively enhancing the overall outcome.<sup>36</sup> The Mixture of Agents (MoA) paradigm exemplifies this approach, where layers of specialized LLM agents work together, with proposers generating diverse responses and aggregators synthesizing them into a high-quality final output.<sup>36</sup></p><p>Effective collaboration among multi-modal MOE agents will likely necessitate a dynamic and adaptive approach. This approach will leverage the unique strengths of each agent through role specialization, facilitate seamless knowledge exchange using standardized protocols and ontologies, employ appropriate coordination mechanisms to manage the inherent complexity of multi-agent systems, and encourage the iterative refinement of solutions to achieve optimal outcomes for intricate tasks. For example, Amazon Bedrock employs a supervisor-subagent model where a central agent coordinates specialized sub-agents to tackle complex, multi-step tasks, demonstrating a hierarchical approach to collaboration.<sup>28</sup> In contrast, multi-agent workflows in areas like supply chain optimization might involve more decentralized interactions, with agents directly communicating to manage inventory and fulfillment.<sup>27</sup> The emerging MoA framework further highlights the potential of cooperative agents to iteratively improve the quality of responses by building upon each other’s outputs, showcasing a more fluid and dynamic collaboration strategy.<sup>36</sup></p><h2 id="5-benefits-of-autonomous-multi-agent-interaction"><strong>5. Benefits of Autonomous Multi-Agent Interaction</strong></h2>
<p>The autonomous interaction of multi-modal MOE agents presents a compelling array of potential benefits that promise to revolutionize various aspects of technology and industry.</p><p>One of the most significant advantages is the potential for increased efficiency. Autonomous agents can automate complex, multi-step processes and workflows without the need for constant human intervention.<sup>28</sup> This leads to substantial reductions in task completion times and a more optimal utilization of resources.<sup>38</sup> Furthermore, these agents can handle multiple tasks concurrently and adapt to changing conditions in real-time, significantly enhancing operational efficiency across diverse domains.<sup>39</sup> Communication among networked AI agents, for instance, enables them to work together towards a common goal much more efficiently than a single agent operating in isolation.<sup>17</sup></p><p>Autonomous multi-agent interaction also offers improved scalability. These systems can readily handle increasing workloads and data volumes by dynamically adding or removing agents as needed, providing a flexible and cost-effective solution for managing fluctuating demands.<sup>17</sup> This scalability facilitates the deployment of AI solutions across large and distributed systems without requiring fundamental architectural overhauls.<sup>29</sup></p><p>The multi-modal nature of these agents contributes to enhanced accuracy. By performing cross-verification of data obtained from diverse sources, they can significantly reduce the likelihood of errors and improve the reliability of decision-making processes.<sup>35</sup> This capability helps minimize the human errors often associated with manual tasks and data processing, leading to more dependable outcomes.<sup>1</sup></p><p>Another key benefit is the 24/7 availability of autonomous agents. Unlike human workers, these agents can operate continuously around the clock without requiring breaks or rest, ensuring uninterrupted service and support across different time zones.<sup>40</sup> This continuous operation enables real-time responses and proactive problem-solving at any time, enhancing the responsiveness and resilience of various systems.<sup>29</sup></p><p>The automation of tasks and processes through autonomous multi-agent interaction can also lead to substantial cost reduction. By taking over tasks traditionally performed by human labor, organizations can achieve significant savings in operational expenses, freeing up human employees to concentrate on more strategic and creative endeavors.<sup>39</sup> Moreover, the intelligent automation facilitated by these agents can optimize resource allocation and minimize waste, further contributing to cost efficiencies.<sup>42</sup></p><p>In essence, the autonomous interaction of multi-modal MOE agents presents a powerful pathway to significant operational advantages. These include enhanced efficiency in task execution, improved scalability to meet varying demands, greater accuracy in data processing and decision-making, continuous availability for round-the-clock operation, and substantial reductions in operational costs. These benefits collectively drive innovation and transform business processes across a multitude of industries. For example, intelligent AI agents can blend seamlessly into existing business systems, autonomously managing complex, multi-step processes with minimal oversight, leading to “hands-off” automation solutions.<sup>38</sup> The ability of networked agents to share data and refine strategies based on real-time information further underscores the potential for significant efficiency gains.<sup>17</sup></p><h2 id="6-challenges-and-considerations-efficiency-privacy-and-security"><strong>6. Challenges and Considerations: Efficiency, Privacy, and Security</strong></h2>
<p>While the potential of autonomous multi-agent interaction is vast, realizing its benefits necessitates careful consideration and proactive management of several inherent challenges related to efficiency, privacy, and security.</p><p>Efficiency in communication and coordination can become a significant hurdle as the number of interacting agents increases.<sup>7</sup> The overhead associated with agents exchanging messages and synchronizing their actions can potentially lead to performance bottlenecks if not managed effectively through efficient protocols and message management strategies.<sup>7</sup> Coordinating and synchronizing the activities of a large number of autonomous agents, particularly in dynamic and unpredictable environments, presents a considerable challenge.<sup>28</sup> Furthermore, ensuring optimal resource allocation and load balancing across the specialized MOE experts within and across interacting agents requires sophisticated mechanisms.<sup>11</sup></p><p>Privacy is another critical concern. Autonomous agents often require access to, process, and exchange sensitive personal or organizational data across multiple modalities.<sup>2</sup> This raises significant risks of unintended data exposure or misuse if appropriate safeguards are not in place.<sup>2</sup> Obtaining informed consent and ensuring robust data governance become particularly challenging when agents operate autonomously on behalf of users or organizations.<sup>46</sup> Moreover, enabling secure collaboration between agents from different entities without compromising the privacy and security of their users’ sensitive information requires the adoption of privacy-preserving techniques.<sup>48</sup></p><p>Security risks are also paramount. The autonomous nature and extensive access privileges of AI agents make them potential targets for cyberattacks, data breaches, and adversarial manipulation.<sup>2</sup> Malicious actors could potentially compromise agents, leading to unauthorized actions, the exfiltration of sensitive data, or the disruption of critical systems.<sup>52</sup> Establishing robust authentication, authorization, and continuous monitoring mechanisms is essential to secure inter-agent communication and prevent unauthorized access or manipulation.<sup>52</sup></p><p>Beyond these technical challenges, ethical considerations are crucial. Autonomous agents trained on potentially biased data may exhibit those biases in their actions and decisions, leading to unfair or discriminatory outcomes.<sup>2</sup> The decision-making processes of complex AI agents can often lack transparency and explainability, making it difficult to understand and audit their actions.<sup>47</sup> Furthermore, establishing clear lines of accountability and responsibility for the actions and outcomes of autonomous AI agents presents a significant challenge.<sup>2</sup></p><p>In summary, while the autonomous interaction of multi-modal MOE agents offers tremendous potential, its successful and responsible implementation hinges on proactively addressing the challenges related to managing efficiency at scale, safeguarding the privacy of sensitive data, ensuring robust security against a range of threats, and navigating the complex ethical landscape to build trust and ensure positive societal impact. For example, limitations in data transmission and network latency can impact the efficiency of communication between a growing number of agents.<sup>43</sup> Privacy risks arise from the extensive data access required for autonomous operation, necessitating strict compliance with data protection regulations.<sup>44</sup> Security vulnerabilities can be exploited by malicious actors, highlighting the need for continuous monitoring and robust guardrails.<sup>44</sup> Finally, biases in training data can lead to unfair outcomes, underscoring the importance of transparency and accountability in AI agent behavior.<sup>59</sup></p><h2 id="7-autonomous-negotiation-and-agreement-in-ai-agent-systems"><strong>7. Autonomous Negotiation and Agreement in AI Agent Systems</strong></h2>
<p>A key aspect of effective collaboration among autonomous multi-modal MOE agents is their ability to negotiate and reach agreements without direct human intervention. This involves several intricate mechanisms.</p><p>Intent recognition plays a crucial role, enabling AI agents to infer the goals, intentions, and preferences of other agents by observing their actions, communication patterns, and interactions with the environment.<sup>63</sup> This goes beyond simply recognizing a sequence of actions to understanding the underlying intent or overall goal of another agent.<sup>63</sup> Machine learning techniques and contextual understanding can further enhance the accuracy of intent recognition in complex multi-agent scenarios.<sup>66</sup> For instance, an agent might observe another agent repeatedly attempting to access a specific resource and infer its intent to utilize that resource for a particular task.<sup>65</sup></p><p>Negotiation protocols provide the structured sets of rules and standards that govern the negotiation process between AI agents.<sup>15</sup> These protocols define how agents make proposals, issue counter-offers, and ultimately reach mutually acceptable agreements in both cooperative and competitive settings.<sup>15</sup> Various types of negotiation protocols exist, including auction-based mechanisms where agents bid competitively for resources or tasks, contract net protocols where agents announce tasks and bid to complete them, and argumentation-based approaches where agents exchange reasoned arguments to justify their positions.<sup>69</sup></p><p>Conflict resolution strategies are essential for situations where autonomous AI agents encounter disagreements, competing objectives, or conflicting actions.<sup>71</sup> These strategies can involve further negotiation, the use of mediation by a designated agent, or the application of predefined ethical principles or rules to resolve the conflict.<sup>71</sup> For example, if two agents simultaneously attempt to access a limited resource, a conflict resolution strategy might involve a negotiation process to determine which agent has a higher priority or can utilize the resource more efficiently.<sup>71</sup></p><p>Game theory offers a powerful mathematical framework for modeling strategic interactions between negotiating AI agents.<sup>70</sup> By applying game-theoretic principles, agents can analyze potential outcomes, predict the behavior of other agents, and choose optimal strategies to maximize their own utility or the utility of the user they represent.<sup>70</sup> Concepts like Nash Equilibrium, where no agent can improve its outcome by unilaterally changing its strategy, and Pareto Efficiency, where it’s impossible to make one agent better off without making another worse off, are particularly relevant in AI agent negotiation.<sup>76</sup></p><p>Multi-Agent Reinforcement Learning (MARL) provides another promising avenue for training AI agents to negotiate effectively.<sup>81</sup> Through repeated interactions, experience, and feedback (in the form of rewards or punishments) in simulated or real-world environments, agents can learn to refine their negotiation tactics and adapt their behavior based on the actions of other agents and the dynamics of the environment.<sup>87</sup> This allows agents to develop sophisticated negotiation policies without explicit programming.<sup>86</sup></p><p>Autonomous negotiation and agreement in AI agent systems will likely involve a combination of these mechanisms. Agents will need to accurately recognize the intentions of others, adhere to established negotiation protocols, employ appropriate conflict resolution strategies, and leverage game-theoretic reasoning or reinforcement learning to optimize negotiation outcomes in a variety of scenarios, from simple resource allocation to complex contract agreements. For instance, AI agents are being developed to autonomously negotiate contracts in procurement, aiming to secure the best possible terms by analyzing historical data and market trends.<sup>69</sup></p><h2 id="8-the-necessity-of-human-oversight-and-confirmation"><strong>8. The Necessity of Human Oversight and Confirmation</strong></h2>
<p>Despite the increasing sophistication of autonomous AI agents, human oversight and confirmation remain crucial for ensuring their responsible and beneficial operation.</p><p>Ethical considerations necessitate human involvement to ensure that the actions and decisions of autonomous AI agents align with human values, societal norms, and ethical principles.<sup>60</sup> This helps mitigate the risk of unintended harmful or biased outcomes that might arise from purely autonomous decision-making.<sup>60</sup> Establishing clear ethical guidelines and frameworks to govern the behavior of AI agents is essential for their responsible deployment.<sup>60</sup></p><p>Safety and risk mitigation are also key reasons for human oversight. Human intervention serves as a vital safety net, preventing autonomous agents from making critical errors or engaging in unintended behaviors that could lead to negative consequences, particularly in high-stakes domains such as healthcare or finance.<sup>44</sup> Approaches like “human-in-the-loop” and “human-on-the-loop” allow for necessary guidance and control over autonomous systems.<sup>60</sup></p><p>Legal and regulatory compliance demands human oversight to ensure that the actions of AI agents adhere to relevant laws, regulations, and industry standards, especially in highly regulated sectors.<sup>44</sup> As the legal landscape surrounding AI continues to evolve, human accountability for the actions of autonomous systems remains paramount.<sup>55</sup></p><p>For complex or high-stakes decisions, human confirmation or approval is often essential.<sup>3</sup> This is particularly true for decisions or agreements that carry significant financial, legal, or ethical implications.<sup>3</sup> Multi-signature schemes, for example, can require both human and AI agent approval for sensitive transactions, providing an added layer of security and control.<sup>111</sup></p><p>Maintaining user trust is another critical aspect. Human oversight and the ability for users to monitor and control the actions of AI agents are crucial for building and sustaining trust in these autonomous systems.<sup>105</sup> Transparency and explainability in AI decision-making processes further contribute to user confidence.<sup>60</sup></p><p>While the long-term vision might involve increasingly autonomous AI agents, the current stage of development necessitates robust human oversight and confirmation mechanisms. These mechanisms are vital for addressing ethical considerations, ensuring safety and compliance with regulations, handling complex and high-stakes decisions responsibly, and ultimately building the trust required for the widespread adoption of these powerful technologies. For instance, in financial transactions, a setup where an autonomous agent proposes transactions but requires approval from human signers provides enhanced security and control.<sup>111</sup> Similarly, in high-risk applications, human oversight ensures that AI decisions align with ethical guidelines and legal frameworks.<sup>105</sup></p><h2 id="9-enhancing-communication-dynamic-function-calls-and-code-exchange"><strong>9. Enhancing Communication: Dynamic Function Calls and Code Exchange</strong></h2>
<p>To further enhance the efficiency and capabilities of multi-modal MOE AI agents, advanced communication methods beyond natural language are being explored, including dynamic function calls and code exchange.</p><p>Dynamic function calls allow AI agents to interact with external tools, access specific data, or trigger particular actions in a more structured and efficient manner compared to relying solely on natural language instructions.<sup>114</sup> By defining the structure of functions and their parameters, agents can precisely specify the actions they need to perform, leading to reduced ambiguity and more direct execution of tasks through well-defined interfaces.<sup>115</sup> For example, an agent might use a function call to retrieve the current weather information for a specific location or to add an event to a user’s calendar.<sup>114</sup></p><p>The exchange of code between AI agents represents another powerful advanced communication method.<sup>118</sup> This allows agents to share specialized capabilities or algorithms that might not be readily available through standard APIs or natural language commands.<sup>19</sup> By exchanging and executing code snippets, agents can potentially achieve more efficient collaboration and problem-solving, leveraging the unique functionalities developed by others.<sup>19</sup> For instance, one agent specializing in a particular type of data analysis could share a code function with another agent that needs to perform that specific analysis.<sup>118</sup></p><p>Dynamic function calls and code exchange offer several advantages over natural language communication. They can lead to increased speed of interaction, reduced potential for misinterpretation or ambiguity, and enhanced precision in specifying actions and data formats.<sup>117</sup> These methods enable agents to interact with greater efficiency and directly invoke specific functionalities or share complex logic.</p><p>However, the exchange and execution of code between autonomous AI agents introduces significant security risks.<sup>19</sup> The potential for malicious code injection, unauthorized access to systems, or overall compromise necessitates the implementation of robust security measures.<sup>19</sup> Sandboxing environments, rigorous code verification processes, and the establishment of trust mechanisms between agents are crucial for mitigating these risks and ensuring safe and secure code exchange.<sup>56</sup></p><p>In conclusion, dynamic function calls and the exchange of code represent powerful advanced communication methods that can significantly enhance the efficiency and flexibility of interaction between multi-modal MOE AI agents. They enable agents to perform complex tasks and share specialized capabilities more effectively than natural language alone. Nevertheless, the potential security implications associated with executing code from other agents underscore the critical need for implementing stringent security protocols and establishing trust frameworks to ensure safe and reliable communication. For example, the AI-Exchange Protocol (AIXP) has been proposed as a standard to facilitate the exchange of information, potentially including code, between AI agents.<sup>118</sup> While function calling provides a structured way for agents to use external tools <sup>114</sup>, the direct exchange of executable code requires careful security considerations to prevent potential vulnerabilities.<sup>19</sup></p><h2 id="10-navigating-cross-entity-collaboration-and-prioritizing-user-interests"><strong>10. Navigating Cross-Entity Collaboration and Prioritizing User Interests</strong></h2>
<p>As multi-modal MOE AI agents become more prevalent, scenarios involving collaboration between agents from different entities will become increasingly common. This raises important questions about how these agents, such as personal AI and company AI, can collaborate effectively while prioritizing the interests of their respective users.</p><p>Collaboration between personal AI agents, acting on behalf of individuals, and company AI agents, representing organizations, presents a unique set of complexities.<sup>1</sup> These agents might have differing goals and priorities, reflecting the distinct objectives of the individuals and the organizations they serve.<sup>1</sup> Aligning these potentially disparate interests when their AI agents interact is a significant challenge.</p><p>To facilitate effective collaboration that respects user interests, mechanisms for preference signaling are essential. AI agents need to be able to communicate and understand the preferences, constraints, and priorities of their respective users during inter-agent interactions.<sup>95</sup> This could involve agents being guided by user-defined rules, accessing preference profiles, or even interpreting natural language instructions from their users to inform their collaborative behavior.<sup>120</sup></p><p>During negotiation processes with agents from other entities, AI agents must be equipped to prioritize and advocate for the best possible outcomes for their own users.<sup>96</sup> This might involve strategic decision-making and the ability to make trade-offs while ensuring that the final agreement aligns with their user’s key objectives or “bottom line”.<sup>120</sup> For instance, an AI agent negotiating a contract on behalf of a user would need to prioritize terms that are most beneficial to that user, potentially making concessions on less critical aspects.<sup>96</sup></p><p>In situations where cross-entity collaboration involves the exchange of sensitive data, privacy-preserving techniques become crucial. Technologies such as federated learning, secure multi-party computation, and zero-knowledge proofs can enable AI agents from different entities to collaborate on tasks or share valuable insights without compromising the privacy and security of their users’ confidential information.<sup>48</sup> This is particularly important in domains like healthcare or finance where data privacy is paramount.</p><p>In conclusion, effective cross-entity collaboration between multi-modal MOE AI agents will necessitate sophisticated mechanisms for preference signaling and negotiation. These mechanisms must enable agents to understand and prioritize the interests of their respective users while interacting with agents from other entities. Furthermore, the integration of privacy-preserving techniques will be essential to ensure secure and trustworthy interactions when exchanging information across organizational or personal boundaries. For example, personal AI agents might need to signal their user’s availability for a meeting to a company AI agent attempting to schedule a team call.<sup>41</sup> In such a scenario, both agents need to prioritize their respective users’ schedules and preferences to find a mutually agreeable time.<sup>41</sup></p><h2 id="11-real-world-applications-and-future-directions"><strong>11. Real-World Applications and Future Directions</strong></h2>
<p>The potential applications of autonomous AI agent interaction are vast and span across numerous real-world scenarios.</p><p>In scheduling and meeting coordination, autonomous multi-modal MOE AI agents can significantly streamline the often cumbersome process of arranging meetings.<sup>41</sup> These agents can intelligently scan participants’ calendars, considering individual preferences, time zones, and availability to propose optimal meeting times, thereby eliminating the need for extensive back-and-forth communication.<sup>41</sup></p><p>Customer service is another area ripe for transformation. AI agents with multi-modal capabilities, such as understanding both text and voice inputs, can collaborate to handle complex customer inquiries, provide personalized support, and resolve issues with greater efficiency.<sup>124</sup> These agents can access customer history, leverage knowledge bases, and even escalate complex issues to human agents when necessary, ensuring a seamless and satisfactory customer experience.<sup>125</sup></p><p>Supply chain management stands to benefit immensely from autonomous AI agent interaction. Interacting agents can optimize various aspects of the supply chain, including demand forecasting, inventory management, supplier negotiation, and logistics coordination.<sup>127</sup> This can lead to increased efficiency, reduced costs, and a more resilient and responsive supply chain.<sup>129</sup></p><p>Industrial automation is also being revolutionized by AI agents. In manufacturing and industrial settings, autonomous agents can perform tasks such as predictive maintenance by monitoring equipment health and predicting failures, quality control by analyzing production data in real-time, process optimization by identifying inefficiencies, and coordination of robotic systems on the factory floor.<sup>130</sup> These applications lead to increased productivity, reduced downtime, and improved product quality.<sup>133</sup></p><p>Contract negotiation is another promising application. AI agents are being developed to autonomously negotiate contracts in various industries, aiming to secure optimal terms and reduce the need for manual human intervention.<sup>93</sup> These agents can analyze vast amounts of data, understand complex legal language, and negotiate based on predefined goals and constraints.<sup>96</sup></p><p>Looking towards the future, several trends are expected to shape the evolution of AI agent communication and collaboration. We will likely see the development of more sophisticated multi-agent systems capable of tackling increasingly complex problems through coordinated effort.<sup>13</sup> The emergence of standardized communication protocols, such as A2A and MCP, will be crucial for enabling seamless interoperability between agents from different platforms and domains.<sup>13</sup> There will also be a growing focus on incorporating emotional intelligence into AI agents to facilitate more natural and empathetic interactions.<sup>144</sup> Furthermore, ethical AI development and responsible deployment will become increasingly important as these agents become more integrated into our lives.<sup>140</sup></p><p>The autonomous interaction of multi-modal MOE AI agents holds immense potential to transform a wide array of real-world applications across diverse sectors. Future advancements will likely concentrate on enhancing their collaborative capabilities, ensuring their ethical and secure operation, and expanding their integration into increasingly intricate and dynamic environments. For example, in manufacturing, AI agents are already being used for predictive maintenance and quality control.<sup>131</sup> In finance, they are assisting with fraud detection and risk assessment.<sup>146</sup> The continued development and refinement of these applications, along with the emergence of new ones, will undoubtedly shape the future of how we interact with technology and solve complex problems.</p><h2 id="12-conclusion-the-future-landscape-of-interacting-multi-modal-moe-ai-agents"><strong>12. Conclusion: The Future Landscape of Interacting Multi-Modal MOE AI Agents</strong></h2>
<p>This research paper has explored the intricate landscape of interaction among multi-modal MOE AI agents, highlighting their transformative potential across various domains. The synergy between multi-modal perception, MOE-enhanced processing, and autonomous operation signifies a major leap forward in artificial intelligence, promising systems capable of perceiving, processing, and acting in complex environments with unprecedented efficiency and versatility.</p><p>The ability of these agents to communicate through diverse methods, including natural language, structured data exchange, and emerging standardized protocols, lays the foundation for sophisticated collaboration. Strategies such as task decomposition, role specialization, knowledge sharing, and iterative refinement enable multi-agent systems to tackle complex objectives that would be beyond the reach of individual agents. The benefits of autonomous interaction are substantial, offering increased efficiency, improved scalability, enhanced accuracy, continuous availability, and significant cost reductions.</p><p>However, realizing the full potential of these technologies requires careful consideration of the inherent challenges. Managing efficiency at scale, safeguarding the privacy of sensitive data, ensuring robust security against various threats, and addressing complex ethical implications are all critical aspects that must be proactively managed to build trust and ensure responsible deployment.</p><p>Standardization efforts, such as the development of protocols like A2A and MCP, are crucial for facilitating seamless interoperability and collaboration among agents from different platforms and domains. These efforts will pave the way for a more connected and collaborative AI ecosystem.</p><p>Future research should focus on developing more robust and efficient communication protocols, exploring advanced strategies for collaborative task achievement, establishing effective mechanisms for human oversight and control, and innovating approaches to ensure privacy and security in cross-entity interactions. As AI agents continue to evolve, understanding and addressing these key areas will be paramount.</p><p>In conclusion, the future landscape of artificial intelligence will be significantly shaped by the autonomous interaction of multi-modal MOE AI agents. Their potential to drive innovation, solve complex problems, and transform industries is immense. By continuing to advance our understanding of their communication, collaboration, and decision-making processes, while remaining mindful of the associated challenges and ethical considerations, we can harness the full power of these interacting minds to create a more efficient, intelligent, and beneficial future.</p><h4 id="works-cited"><strong>Works cited</strong></h4>
<ol>
<li><p>AI Interactivity (Part I): AI Agents and Multimodal Agents - Tensility Venture Partners, <a href="https://www.tensilityvc.com/insights/ai-interactivity-part-i-ai-agents-and-multimodal-agents">https://www.tensilityvc.com/insights/ai-interactivity-part-i-ai-agents-and-multimodal-agents</a></p></li>
<li><p>Top 10 Research Papers on AI Agents (2025) - Analytics Vidhya, <a href="https://www.analyticsvidhya.com/blog/2024/12/ai-agents-research-papers/">https://www.analyticsvidhya.com/blog/2024/12/ai-agents-research-papers/</a></p></li>
<li><p>Multimodality, Tool Use, and Autonomous Agents: Large Language Models Explained, Part 3 | Center for Security and Emerging Technology, <a href="https://cset.georgetown.edu/article/multimodality-tool-use-and-autonomous-agents/">https://cset.georgetown.edu/article/multimodality-tool-use-and-autonomous-agents/</a></p></li>
<li><p>[2306.13549] A Survey on Multimodal Large Language Models - arXiv, <a href="https://arxiv.org/abs/2306.13549">https://arxiv.org/abs/2306.13549</a></p></li>
<li><p>www.datacamp.com, <a href="https://www.datacamp.com/blog/mixture-of-experts-moe#:~:text=Mixture%20of%20Experts%20(MoE)%20is,best%20expert%20for%20each%20input.">https://www.datacamp.com/blog/mixture-of-experts-moe#:~:text=Mixture%20of%20Experts%20(MoE)%20is,best%20expert%20for%20each%20input.</a></p></li>
<li><p>What Is Mixture of Experts (MoE)? How It Works, Use Cases &amp; More | DataCamp, <a href="https://www.datacamp.com/blog/mixture-of-experts-moe">https://www.datacamp.com/blog/mixture-of-experts-moe</a></p></li>
<li><p>Mixture of Experts: Advancing AI Agent Collaboration and Decisions - Akira AI, <a href="https://www.akira.ai/blog/mixture-of-experts-for-ai-agents">https://www.akira.ai/blog/mixture-of-experts-for-ai-agents</a></p></li>
<li><p>What is mixture of experts? | IBM, <a href="https://www.ibm.com/think/topics/mixture-of-experts">https://www.ibm.com/think/topics/mixture-of-experts</a></p></li>
<li><p>YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents in Augmented Reality Tasks - Google Research, <a href="https://research.google/pubs/yeti-yet-to-intervene-proactive-interventions-by-multimodal-ai-agents-in-augmented-reality-tasks/">https://research.google/pubs/yeti-yet-to-intervene-proactive-interventions-by-multimodal-ai-agents-in-augmented-reality-tasks/</a></p></li>
<li><p>survey on multimodal large language models | National Science Review - Oxford Academic, <a href="https://academic.oup.com/nsr/article/11/12/nwae403/7896414">https://academic.oup.com/nsr/article/11/12/nwae403/7896414</a></p></li>
<li><p>Mixture of Experts LLMs: Key Concepts Explained - neptune.ai, <a href="https://neptune.ai/blog/mixture-of-experts-llms">https://neptune.ai/blog/mixture-of-experts-llms</a></p></li>
<li><p>[R] New Paper on Mixture of Experts (MoE) : r/MachineLearning - Reddit, <a href="https://www.reddit.com/r/MachineLearning/comments/1erv2sn/r_new_paper_on_mixture_of_experts_moe/">https://www.reddit.com/r/MachineLearning/comments/1erv2sn/r_new_paper_on_mixture_of_experts_moe/</a></p></li>
<li><p>Announcing the Agent2Agent Protocol (A2A) - Google for Developers Blog, <a href="https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/">https://developers.googleblog.com/en/a2a-a-new-era-of-agent-interoperability/</a></p></li>
<li><p>How do AI agents communicate with other agents? - Milvus, <a href="https://milvus.io/ai-quick-reference/how-do-ai-agents-communicate-with-other-agents">https://milvus.io/ai-quick-reference/how-do-ai-agents-communicate-with-other-agents</a></p></li>
<li><p>Agent Communication Protocols: An Overview - SmythOS, <a href="https://smythos.com/ai-agents/ai-agent-development/agent-communication-protocols/">https://smythos.com/ai-agents/ai-agent-development/agent-communication-protocols/</a></p></li>
<li><p>Comparing Agent Communication Languages and Protocols: Choosing the Right Framework for Multi-Agent Systems - SmythOS, <a href="https://smythos.com/ai-agents/ai-agent-development/agent-communication-languages-and-protocols-comparison/">https://smythos.com/ai-agents/ai-agent-development/agent-communication-languages-and-protocols-comparison/</a></p></li>
<li><p>What is AI Agent Communication? - IBM, <a href="https://www.ibm.com/think/topics/ai-agent-communication">https://www.ibm.com/think/topics/ai-agent-communication</a></p></li>
<li><p>Interpretation of Emergent Communication in Heterogeneous Collaborative Embodied Agents - CVF Open Access, <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Patel_Interpretation_of_Emergent_Communication_in_Heterogeneous_Collaborative_Embodied_Agents_ICCV_2021_paper.pdf">https://openaccess.thecvf.com/content/ICCV2021/papers/Patel_Interpretation_of_Emergent_Communication_in_Heterogeneous_Collaborative_Embodied_Agents_ICCV_2021_paper.pdf</a></p></li>
<li><p>AI Agent Communication: Breakthrough or Security Nightmare? - Deepak Gupta, <a href="https://guptadeepak.com/when-ai-agents-start-whispering-the-double-edged-sword-of-autonomous-agent-communication/">https://guptadeepak.com/when-ai-agents-start-whispering-the-double-edged-sword-of-autonomous-agent-communication/</a></p></li>
<li><p>A2A and MCP: Start of the AI Agent Protocol Wars? - Koyeb, <a href="https://www.koyeb.com/blog/a2a-and-mcp-start-of-the-ai-agent-protocol-wars">https://www.koyeb.com/blog/a2a-and-mcp-start-of-the-ai-agent-protocol-wars</a></p></li>
<li><p>Introducing the Model Context Protocol - Anthropic, <a href="https://www.anthropic.com/news/model-context-protocol">https://www.anthropic.com/news/model-context-protocol</a></p></li>
<li><p>The Rise of AI Agents and the Need for Standardized Protocols - Pynomial, <a href="https://pynomial.com/2025/02/the-rise-of-ai-agents-and-the-need-for-standardized-protocols/">https://pynomial.com/2025/02/the-rise-of-ai-agents-and-the-need-for-standardized-protocols/</a></p></li>
<li><p>The AI Agent Infrastructure Stack — Three Defining Layers: Tools, Data, and Orchestration, <a href="https://www.madrona.com/ai-agent-infrastructure-three-layers-tools-data-orchestration/">https://www.madrona.com/ai-agent-infrastructure-three-layers-tools-data-orchestration/</a></p></li>
<li><p>Agent Protocol, <a href="https://agentprotocol.ai/">https://agentprotocol.ai/</a></p></li>
<li><p>Common interface for interacting with AI agents. The protocol is tech stack agnostic - you can use it with any framework for building agents. - GitHub, <a href="https://github.com/AI-Engineer-Foundation/agent-protocol">https://github.com/AI-Engineer-Foundation/agent-protocol</a></p></li>
<li><p>Top 7 Frameworks for Building AI Agents in 2025 - Analytics Vidhya, <a href="https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/">https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/</a></p></li>
<li><p>What Are AI Agentic Workflows &amp; How to Implement Them - Multimodal.dev, <a href="https://www.multimodal.dev/post/ai-agentic-workflows">https://www.multimodal.dev/post/ai-agentic-workflows</a></p></li>
<li><p>Introducing multi-agent collaboration capability for Amazon Bedrock (preview) - AWS, <a href="https://aws.amazon.com/blogs/aws/introducing-multi-agent-collaboration-capability-for-amazon-bedrock/">https://aws.amazon.com/blogs/aws/introducing-multi-agent-collaboration-capability-for-amazon-bedrock/</a></p></li>
<li><p>Multi-Agent Collaboration Mechanisms: A Survey of LLMs - arXiv, <a href="https://arxiv.org/html/2501.06322v1">https://arxiv.org/html/2501.06322v1</a></p></li>
<li><p>Knowledge Sharing AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/knowledge-sharing">https://clickup.com/p/ai-agents/knowledge-sharing</a></p></li>
<li><p>Unleashing the Future of Knowledge Management with Agentic AI - Akira AI, <a href="https://www.akira.ai/blog/ai-agent-for-knowledge-base">https://www.akira.ai/blog/ai-agent-for-knowledge-base</a></p></li>
<li><p>Leveraging Multi-AI Agents for Cross-Domain Knowledge Discovery - arXiv, <a href="https://arxiv.org/html/2404.08511v1">https://arxiv.org/html/2404.08511v1</a></p></li>
<li><p>How do multi-agent systems handle heterogeneous agents? - Milvus, <a href="https://milvus.io/ai-quick-reference/how-do-multiagent-systems-handle-heterogeneous-agents">https://milvus.io/ai-quick-reference/how-do-multiagent-systems-handle-heterogeneous-agents</a></p></li>
<li><p>Agent Communication and Ontologies - SmythOS, <a href="https://smythos.com/ai-agents/agent-architectures/agent-communication-and-ontologies/">https://smythos.com/ai-agents/agent-architectures/agent-communication-and-ontologies/</a></p></li>
<li><p>Multimodal AI Agents: Reimaging Human-Computer Interaction - Akira AI, <a href="https://www.akira.ai/blog/ai-agents-with-multimodal-models">https://www.akira.ai/blog/ai-agents-with-multimodal-models</a></p></li>
<li><p>Exploring MoE and MoA for Smarter AI Solutions - PuppyAgent, <a href="https://www.puppyagent.com/blog/Exploring-MoE-and-MoA-for-Smarter-AI-Solutions">https://www.puppyagent.com/blog/Exploring-MoE-and-MoA-for-Smarter-AI-Solutions</a></p></li>
<li><p>Mixture of Agents: An Emerging Approach in AI Methodologies - Dria, <a href="https://dria.co/blog/mixture-of-agents:-an-emerging-approach-in-ai-methodologies">https://dria.co/blog/mixture-of-agents:-an-emerging-approach-in-ai-methodologies</a></p></li>
<li><p>What Are Intelligent AI Agents (And Can They Really Work Alone)? | Moveworks, <a href="https://www.moveworks.com/us/en/resources/blog/what-is-intelligent-ai-agent-how-they-work-autonomously">https://www.moveworks.com/us/en/resources/blog/what-is-intelligent-ai-agent-how-they-work-autonomously</a></p></li>
<li><p>Autonomous AI Agents: Exploring Their Role - Neontri, <a href="https://neontri.com/blog/autonomous-ai-agents/">https://neontri.com/blog/autonomous-ai-agents/</a></p></li>
<li><p>Autonomous Agent Frameworks - SmythOS, <a href="https://smythos.com/ai-agents/agent-architectures/autonomous-agent-frameworks/">https://smythos.com/ai-agents/agent-architectures/autonomous-agent-frameworks/</a></p></li>
<li><p>Meeting Scheduler AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/meeting-scheduler">https://clickup.com/p/ai-agents/meeting-scheduler</a></p></li>
<li><p>Multimodal AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/multimodal">https://clickup.com/p/ai-agents/multimodal</a></p></li>
<li><p>Multi-agent Systems and Communication: Enabling Effective Interaction Between Agents, <a href="https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-and-communication/">https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-and-communication/</a></p></li>
<li><p>Preparing for the AI Agent Revolution: Navigating the Legal and Compliance Challenges of Autonomous Decision-Makers - StoneTurn, <a href="https://stoneturn.com/insight/preparing-for-the-ai-agent-revolution/">https://stoneturn.com/insight/preparing-for-the-ai-agent-revolution/</a></p></li>
<li><p>Privacy Concerns AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/privacy-concerns">https://clickup.com/p/ai-agents/privacy-concerns</a></p></li>
<li><p>Minding Mindful Machines: AI Agents and Data Protection Considerations, <a href="https://fpf.org/blog/minding-mindful-machines-ai-agents-and-data-protection-considerations/">https://fpf.org/blog/minding-mindful-machines-ai-agents-and-data-protection-considerations/</a></p></li>
<li><p>Five privacy concerns around agentic AI | SC Media, <a href="https://www.scworld.com/perspective/five-privacy-concerns-around-agentic-ai">https://www.scworld.com/perspective/five-privacy-concerns-around-agentic-ai</a></p></li>
<li><p>Unlocking the Potential of Agentic AI with Privacy-Enhancing Technologies - Duality Tech, <a href="https://dualitytech.com/blog/unlocking-the-potential-of-agentic-ai-with-privacy-enhancing-technologies/">https://dualitytech.com/blog/unlocking-the-potential-of-agentic-ai-with-privacy-enhancing-technologies/</a></p></li>
<li><p>Empowering Agentic AI Within Financial Systems Requires Zero-Knowledge Proofs and Privacy-Preserving Technologies | Chainlink Blog, <a href="https://blog.chain.link/agentic-ai-in-finance/">https://blog.chain.link/agentic-ai-in-finance/</a></p></li>
<li><p>Secret Network and Project Zero Partner, <a href="https://scrt.network/blog/secret-network-and-project-zero-partner">https://scrt.network/blog/secret-network-and-project-zero-partner</a></p></li>
<li><p>AI Agents Need A Privacy Layer - Oasis Network, <a href="https://oasisprotocol.org/blog/ai-agents-privacy-blockchain">https://oasisprotocol.org/blog/ai-agents-privacy-blockchain</a></p></li>
<li><p>The Rise of AI Agents and the Security Challenges Ahead | Auth0, <a href="https://auth0.com/blog/the-rise-of-ai-agents-and-the-security-challenges-ahead/">https://auth0.com/blog/the-rise-of-ai-agents-and-the-security-challenges-ahead/</a></p></li>
<li><p>The Identities Behind AI Agents: A Deep Dive Into AI &amp; NHI - The Hacker News, <a href="https://thehackernews.com/2025/04/the-identities-behind-ai-agents-deep.html">https://thehackernews.com/2025/04/the-identities-behind-ai-agents-deep.html</a></p></li>
<li><p>Mitigating the Top 10 Vulnerabilities in AI Agents - XenonStack, <a href="https://www.xenonstack.com/blog/vulnerabilities-in-ai-agents">https://www.xenonstack.com/blog/vulnerabilities-in-ai-agents</a></p></li>
<li><p>Challenges in Governing AI Agents - Lawfare, <a href="https://www.lawfaremedia.org/article/challenges-in-governing-ai-agents">https://www.lawfaremedia.org/article/challenges-in-governing-ai-agents</a></p></li>
<li><p>Awesome-LLM-based-AI-Agents-Knowledge/8-4-communication.md at main - GitHub, <a href="https://github.com/mind-network/Awesome-LLM-based-AI-Agents-Knowledge/blob/main/8-4-communication.md">https://github.com/mind-network/Awesome-LLM-based-AI-Agents-Knowledge/blob/main/8-4-communication.md</a></p></li>
<li><p>5 Security Considerations for Managing AI Agents and Their Identities - Aembit, <a href="https://aembit.io/blog/5-security-considerations-for-managing-ai-agents-and-their-identities/">https://aembit.io/blog/5-security-considerations-for-managing-ai-agents-and-their-identities/</a></p></li>
<li><p>Understanding AI Agent Security - Promptfoo, <a href="https://www.promptfoo.dev/blog/agent-security/">https://www.promptfoo.dev/blog/agent-security/</a></p></li>
<li><p>The Future of Autonomous Agents: Trends, Challenges, and Opportunities Ahead, <a href="https://smythos.com/ai-agents/agent-architectures/future-of-autonomous-agents/">https://smythos.com/ai-agents/agent-architectures/future-of-autonomous-agents/</a></p></li>
<li><p>AI Agent Best Practices and Ethical Considerations | Writesonic, <a href="https://writesonic.com/blog/ai-agents-best-practices">https://writesonic.com/blog/ai-agents-best-practices</a></p></li>
<li><p>The Ethical Challenges of AI Agents | Tepperspectives, <a href="https://tepperspectives.cmu.edu/all-articles/the-ethical-challenges-of-ai-agents/">https://tepperspectives.cmu.edu/all-articles/the-ethical-challenges-of-ai-agents/</a></p></li>
<li><p>Ethical considerations in deploying autonomous AI agents - Tech Edition, <a href="https://www.techedt.com/ethical-considerations-in-deploying-autonomous-ai-agents">https://www.techedt.com/ethical-considerations-in-deploying-autonomous-ai-agents</a></p></li>
<li><p>Intent recognition in multi-agent systems: Cow herding - ResearchGate, <a href="https://www.researchgate.net/publication/274205903_Intent_recognition_in_multi-agent_systems_Cow_herding">https://www.researchgate.net/publication/274205903_Intent_recognition_in_multi-agent_systems_Cow_herding</a></p></li>
<li><p>Intent Recognition in Multi-Agent Systems: Collective Box Pushing and Cow Herding - CORE, <a href="https://core.ac.uk/download/pdf/213404087.pdf">https://core.ac.uk/download/pdf/213404087.pdf</a></p></li>
<li><p>Plan and Intent Recognition in a Multi-agent System for Collective Box Pushing, <a href="https://www.researchgate.net/publication/274469749_Plan_and_Intent_Recognition_in_a_Multi-agent_System_for_Collective_Box_Pushing">https://www.researchgate.net/publication/274469749_Plan_and_Intent_Recognition_in_a_Multi-agent_System_for_Collective_Box_Pushing</a></p></li>
<li><p>Prediction of Intent in Robotics and Multi-agent Systems | SciSpace, <a href="https://scispace.com/pdf/prediction-of-intent-in-robotics-and-multi-agent-systems-2uazbh7zl0.pdf">https://scispace.com/pdf/prediction-of-intent-in-robotics-and-multi-agent-systems-2uazbh7zl0.pdf</a></p></li>
<li><p>Negotiation Protocols for AI Agents - Matoffo, <a href="https://matoffo.com/negotiation-protocols-for-ai-agents/">https://matoffo.com/negotiation-protocols-for-ai-agents/</a></p></li>
<li><p>accessed January 1, 1970, <a href="https://www.researchgate.net/publication/343780350_Autonomous_Negotiation_in_Multi-Agent_Systems_Principles_and_Challenges">https://www.researchgate.net/publication/343780350_Autonomous_Negotiation_in_Multi-Agent_Systems_Principles_and_Challenges</a></p></li>
<li><p>Agent Communication and Negotiation: Enhancing Decision-Making and Collaboration in Multi-Agent Systems - SmythOS, <a href="https://smythos.com/ai-agents/agent-architectures/agent-communication-and-negotiation/">https://smythos.com/ai-agents/agent-architectures/agent-communication-and-negotiation/</a></p></li>
<li><p>Multi-Agent Systems and Negotiation: Strategies for Effective Agent Collaboration, <a href="https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-and-negotiation/">https://smythos.com/ai-agents/multi-agent-systems/multi-agent-systems-and-negotiation/</a></p></li>
<li><p>Conflict Resolution AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/conflict-resolution">https://clickup.com/p/ai-agents/conflict-resolution</a></p></li>
<li><p>Normative conflict resolution through human–autonomous agent interaction - University of York, <a href="https://pure.york.ac.uk/portal/files/116793996/1-s2.0-S2666659625000101-main.pdf">https://pure.york.ac.uk/portal/files/116793996/1-s2.0-S2666659625000101-main.pdf</a></p></li>
<li><p>Dealing With Ethical Conflicts In Autonomous Agents And Multi-Agent Systems, <a href="https://www.researchgate.net/publication/279258407_Dealing_With_Ethical_Conflicts_In_Autonomous_Agents_And_Multi-Agent_Systems">https://www.researchgate.net/publication/279258407_Dealing_With_Ethical_Conflicts_In_Autonomous_Agents_And_Multi-Agent_Systems</a></p></li>
<li><p>Resolving Conflict in Decision-Making for Autonomous Driving - Robotics, <a href="https://www.roboticsproceedings.org/rss17/p049.pdf">https://www.roboticsproceedings.org/rss17/p049.pdf</a></p></li>
<li><p>How can multi-agent systems communicate? Is game theory the answer? - Capgemini USA, <a href="https://www.capgemini.com/us-en/insights/expert-perspectives/how-can-multi-agent-systems-communicate-is-game-theory-the-answer/">https://www.capgemini.com/us-en/insights/expert-perspectives/how-can-multi-agent-systems-communicate-is-game-theory-the-answer/</a></p></li>
<li><p>Agent-Based Modeling and Game Theory: Simulating Strategic Interactions in Complex Systems - SmythOS, <a href="https://smythos.com/ai-industry-solutions/law/agent-based-modeling-and-game-theory/">https://smythos.com/ai-industry-solutions/law/agent-based-modeling-and-game-theory/</a></p></li>
<li><p>Game-theoretic LLM: Agent Workflow for Negotiation Games - arXiv, <a href="https://arxiv.org/html/2411.05990v1">https://arxiv.org/html/2411.05990v1</a></p></li>
<li><p>Scientific approaches and techniques for negotiation : a game theoretic and artificial intelligence perspective - CWI, <a href="https://ir.cwi.nl/pub/4448">https://ir.cwi.nl/pub/4448</a></p></li>
<li><p>Game Theory (Stanford Encyclopedia of Philosophy), <a href="https://plato.stanford.edu/entries/game-theory/#AI">https://plato.stanford.edu/entries/game-theory/#AI</a></p></li>
<li><p>Game Theory in AI: The Nash Equilibrium EXPLAINED - YouTube, <a href="https://www.youtube.com/watch?v=fbHl9AbcSic">https://www.youtube.com/watch?v=fbHl9AbcSic</a></p></li>
<li><p>MARLIN: Multi-Agent Reinforcement Learning Guided by Language-Based Inter-Robot Negotiation - arXiv, <a href="https://arxiv.org/html/2410.14383v3">https://arxiv.org/html/2410.14383v3</a></p></li>
<li><p>[2410.14383] MARLIN: Multi-Agent Reinforcement Learning Guided by Language-Based Inter-Robot Negotiation - arXiv, <a href="https://arxiv.org/abs/2410.14383">https://arxiv.org/abs/2410.14383</a></p></li>
<li><p>Applying Multi-Agent Reinforcement Learning to Candidate/Employer Job Matching and Salary Negotiations | Computer Science and Economics, <a href="https://csec.yale.edu/senior-essays/fall-2022/applying-multi-agent-reinforcement-learning-candidateemployer-job-matching">https://csec.yale.edu/senior-essays/fall-2022/applying-multi-agent-reinforcement-learning-candidateemployer-job-matching</a></p></li>
<li><p>Deep Reinforcement Learning Agent for Negotiation in Multi-Agent Cooperative Distributed Predictive Control - MDPI, <a href="https://www.mdpi.com/2076-3417/13/4/2432">https://www.mdpi.com/2076-3417/13/4/2432</a></p></li>
<li><p>MULTI-AGENT REINFORCEMENT LEARNING FOR COALITIONAL BARGAINING GAMES, <a href="https://openreview.net/forum?id=OaZktJBVpUy">https://openreview.net/forum?id=OaZktJBVpUy</a></p></li>
<li><p>A Deep Reinforcement Learning Approach to Concurrent Bilateral Negotiation - IJCAI, <a href="https://www.ijcai.org/proceedings/2020/0042.pdf">https://www.ijcai.org/proceedings/2020/0042.pdf</a></p></li>
<li><p>Towards Learning Multi-Agent Negotiations via Self-Play - CVF Open Access, <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/ADW/Tang_Towards_Learning_Multi-Agent_Negotiations_via_Self-Play_ICCVW_2019_paper.pdf">https://openaccess.thecvf.com/content_ICCVW_2019/papers/ADW/Tang_Towards_Learning_Multi-Agent_Negotiations_via_Self-Play_ICCVW_2019_paper.pdf</a></p></li>
<li><p>Towards Learning Multi-Agent Negotiations via Self-Play, <a href="https://machinelearning.apple.com/research/towards-learning-multi-agent-negotiations-via-self-play">https://machinelearning.apple.com/research/towards-learning-multi-agent-negotiations-via-self-play</a></p></li>
<li><p>Single-Agent vs. Multi-Agent Techniques for Concurrent Reinforcement Learning of Negotiation Dialogue Policies - ACL Anthology, <a href="https://aclanthology.org/P14-1047/">https://aclanthology.org/P14-1047/</a></p></li>
<li><p>accessed January 1, 1970, <a href="https://arxiv.org/abs/2006.03753">https://arxiv.org/abs/2006.03753</a></p></li>
<li><p>Unlock Savings with Autonomous Negotiation Agents (ANA) - Zycus, <a href="https://www.zycus.com/solution/autonomous-negotiation-agents">https://www.zycus.com/solution/autonomous-negotiation-agents</a></p></li>
<li><p>Negotiation Strategy AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/negotiation-strategy">https://clickup.com/p/ai-agents/negotiation-strategy</a></p></li>
<li><p>AI Negotiation Agent | statworx®, <a href="https://www.statworx.com/en/generative-ai-solutions/ai-negotiation-agent/">https://www.statworx.com/en/generative-ai-solutions/ai-negotiation-agent/</a></p></li>
<li><p>AI-Powered Deals: How Autonomous Negotiation is Redefining Supply Chain Strategy, <a href="https://supplychain360.io/autonomous-negotiation-revolutionizing-supply-chain-efficiency-2025-trends/">https://supplychain360.io/autonomous-negotiation-revolutionizing-supply-chain-efficiency-2025-trends/</a></p></li>
<li><p>Multi-AI Agents and How Business Can Prepare, <a href="https://www.mri.co.jp/en/knowledge/article/202412_2.html">https://www.mri.co.jp/en/knowledge/article/202412_2.html</a></p></li>
<li><p>The Role of Procurement: AI Agents for Contract Negotiation in Finance - Akira AI, <a href="https://www.akira.ai/blog/ai-agents-for-contract-negotiation">https://www.akira.ai/blog/ai-agents-for-contract-negotiation</a></p></li>
<li><p>AI Lease Negotiation 2025 Ultimate Guide | Real Estate Deals - Rapid Innovation, <a href="https://www.rapidinnovation.io/post/ai-agent-lease-negotiation-assistant">https://www.rapidinnovation.io/post/ai-agent-lease-negotiation-assistant</a></p></li>
<li><p>AI Agents Are Transforming Healthcare Payer Interactions With Smart Negotiation, <a href="https://www.thoughtful.ai/blog/ai-agents-are-transforming-healthcare-payer-interactions-with-smart-negotiation">https://www.thoughtful.ai/blog/ai-agents-are-transforming-healthcare-payer-interactions-with-smart-negotiation</a></p></li>
<li><p>Understanding Agentic AI in Procurement: How Autonomous AI Has Been Transforming Supplier Deals - Pactum, <a href="https://pactum.com/understanding-agentic-ai-in-procurement-how-autonomous-ai-has-been-transforming-supplier-deals/">https://pactum.com/understanding-agentic-ai-in-procurement-how-autonomous-ai-has-been-transforming-supplier-deals/</a></p></li>
<li><p>When Will Your AI Negotiate With My AI? - Nibble, <a href="https://blog.nibbletechnology.com/will-ai-negotiate-with-ai">https://blog.nibbletechnology.com/will-ai-negotiate-with-ai</a></p></li>
<li><p>Contract Negotiation AI Agents for the Finance Industry - Glide, <a href="https://www.glideapps.com/agents/finance/contract-negotiation-ai-agents">https://www.glideapps.com/agents/finance/contract-negotiation-ai-agents</a></p></li>
<li><p>How To Use AI Negotiation To Get More Of What You Want | Lindy, <a href="https://www.lindy.ai/blog/ai-negotiation">https://www.lindy.ai/blog/ai-negotiation</a></p></li>
<li><p>AI in Contract Negotiations (procurement) : r/legaltech - Reddit, <a href="https://www.reddit.com/r/legaltech/comments/1i3eqtg/ai_in_contract_negotiations_procurement/">https://www.reddit.com/r/legaltech/comments/1i3eqtg/ai_in_contract_negotiations_procurement/</a></p></li>
<li><p>The leader in agentic AI for procurement for over half a decade, <a href="https://pactum.com/">https://pactum.com/</a></p></li>
<li><p>The crucial role of humans in AI oversight - Cornerstone OnDemand, <a href="https://www.cornerstoneondemand.com/resources/article/the-crucial-role-of-humans-in-ai-oversight/">https://www.cornerstoneondemand.com/resources/article/the-crucial-role-of-humans-in-ai-oversight/</a></p></li>
<li><p>How humans &amp; AI agents can work together ethically &amp; effectively - Macro 4, <a href="https://www.macro4.com/blog/the-rise-of-ai-agents-how-humans-and-machines-can-work-together-ethically-and-effectively/">https://www.macro4.com/blog/the-rise-of-ai-agents-how-humans-and-machines-can-work-together-ethically-and-effectively/</a></p></li>
<li><p>New Ethics Risks Courtesy of AI Agents? Researchers Are on the Case - IBM, <a href="https://www.ibm.com/think/insights/ai-agent-ethics">https://www.ibm.com/think/insights/ai-agent-ethics</a></p></li>
<li><p>What Ethical Issues Does Agentforce AI Bring to the Table for CIOs? - Inclusion Cloud, <a href="https://inclusioncloud.com/insights/blog/ethical-issues-agentforce-cios/">https://inclusioncloud.com/insights/blog/ethical-issues-agentforce-cios/</a></p></li>
<li><p>AI agents evolve rapidly, challenging human oversight - IBM, <a href="https://www.ibm.com/think/insights/ai-agents-evolve-rapidly">https://www.ibm.com/think/insights/ai-agents-evolve-rapidly</a></p></li>
<li><p>Unlocking value with AI agents: A responsible approach - PwC, <a href="https://www.pwc.com/us/en/tech-effect/ai-analytics/responsible-ai-agents.html">https://www.pwc.com/us/en/tech-effect/ai-analytics/responsible-ai-agents.html</a></p></li>
<li><p>Human approval for AI agent actions - Safe Docs, <a href="https://docs.safe.global/home/ai-agent-quickstarts/human-approval">https://docs.safe.global/home/ai-agent-quickstarts/human-approval</a></p></li>
<li><p>From Fine Print to Machine Code: How AI Agents are Rewriting the Rules of Engagement: Part 3 of 3, <a href="https://law.stanford.edu/2025/03/26/from-fine-print-to-machine-code-how-ai-agents-are-rewriting-the-rules-of-engagement-part-3-of-3/">https://law.stanford.edu/2025/03/26/from-fine-print-to-machine-code-how-ai-agents-are-rewriting-the-rules-of-engagement-part-3-of-3/</a></p></li>
<li><p>5 Ways To Build a Trustworthy AI Agent - Salesforce, <a href="https://www.salesforce.com/blog/trustworthy-ai-agent/">https://www.salesforce.com/blog/trustworthy-ai-agent/</a></p></li>
<li><p>How to use Azure AI Agent Service with function calling - Learn Microsoft, <a href="https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/function-calling">https://learn.microsoft.com/en-us/azure/ai-services/agents/how-to/tools/function-calling</a></p></li>
<li><p>Function-Calling vs Agents - Community.aws, <a href="https://community.aws/content/2sryksE4Ga2hAsUksJZfnT8pJnr/function-calling-vs-agents">https://community.aws/content/2sryksE4Ga2hAsUksJZfnT8pJnr/function-calling-vs-agents</a></p></li>
<li><p>ReAct agents vs function calling agents - LeewayHertz, <a href="https://www.leewayhertz.com/react-agents-vs-function-calling-agents/">https://www.leewayhertz.com/react-agents-vs-function-calling-agents/</a></p></li>
<li><p>Agent Communication and Message Passing: Streamlining Interaction and Data Exchange in Multi-Agent Systems - SmythOS, <a href="https://smythos.com/ai-agents/agent-architectures/agent-communication-and-message-passing/">https://smythos.com/ai-agents/agent-architectures/agent-communication-and-message-passing/</a></p></li>
<li><p>AI-Exchange Protocol (AIXP): A Communication Standard for Artificial Intelligence Agents - GitHub, <a href="https://github.com/davila7/AIXP">https://github.com/davila7/AIXP</a></p></li>
<li><p>Communicating with other agents – Fetch.ai Documentation, <a href="https://fetch.ai/docs/guides/agents/intermediate/communicating-with-other-agents">https://fetch.ai/docs/guides/agents/intermediate/communicating-with-other-agents</a></p></li>
<li><p>Designing AI Agents That Work for You, Part 1: Communication Patterns - Innovation at Consumer Reports, <a href="https://innovation.consumerreports.org/designing-ai-agents-that-work-for-you-part-1/">https://innovation.consumerreports.org/designing-ai-agents-that-work-for-you-part-1/</a></p></li>
<li><p>How to Automate Meeting Scheduling with AI - Datagrid, <a href="https://www.datagrid.com/blog/automate-email-scheduling-ai">https://www.datagrid.com/blog/automate-email-scheduling-ai</a></p></li>
<li><p>Calendly AI Agents - Relevance AI, <a href="https://relevanceai.com/agent-templates-software/calendly">https://relevanceai.com/agent-templates-software/calendly</a></p></li>
<li><p>Emergency Meeting Coordination AI Agent | ClickUp™, <a href="https://clickup.com/p/ai-agents/emergency-meeting-coordination">https://clickup.com/p/ai-agents/emergency-meeting-coordination</a></p></li>
<li><p>www.salesforce.com, <a href="https://www.salesforce.com/service/ai/customer-service-agents/#:~:text=AI%20customer%20service%20agents%20are,a%20personalized%20and%20conversational%20way.">https://www.salesforce.com/service/ai/customer-service-agents/#:~:text=AI%20customer%20service%20agents%20are,a%20personalized%20and%20conversational%20way.</a></p></li>
<li><p>AI Customer Service Agents - Salesforce, <a href="https://www.salesforce.com/service/ai/customer-service-agents/">https://www.salesforce.com/service/ai/customer-service-agents/</a></p></li>
<li><p>AI Agent-Led Customer Service: Revolutionizing Support with Freddy AI - Freshworks, <a href="https://www.freshworks.com/freshdesk/ai-agents/customer-service/">https://www.freshworks.com/freshdesk/ai-agents/customer-service/</a></p></li>
<li><p>sema4.ai, <a href="https://sema4.ai/blog/ai-agents-supply-chain/#:~:text=AI%20agents%20monitor%20supplier%20performance,costs%20while%20ensuring%20adequate%20supply.">https://sema4.ai/blog/ai-agents-supply-chain/#:~:text=AI%20agents%20monitor%20supplier%20performance,costs%20while%20ensuring%20adequate%20supply.</a></p></li>
<li><p>AI Agents for Manufacturing Success | Salesforce US, <a href="https://www.salesforce.com/manufacturing/artificial-intelligence/ai-agents-for-manufacturing/">https://www.salesforce.com/manufacturing/artificial-intelligence/ai-agents-for-manufacturing/</a></p></li>
<li><p>Revolutionizing Supply Chain Management: How AI Agents are Reshaping Industry Logistics - Sema4.ai, <a href="https://sema4.ai/blog/ai-agents-supply-chain/">https://sema4.ai/blog/ai-agents-supply-chain/</a></p></li>
<li><p>Industrial AI in action: How AI agents and digital threads will transform the manufacturing industries - Microsoft, <a href="https://www.microsoft.com/en-us/industry/blog/manufacturing-and-mobility/manufacturing/2025/03/25/industrial-ai-in-action-how-ai-agents-and-digital-threads-will-transform-the-manufacturing-industries/">https://www.microsoft.com/en-us/industry/blog/manufacturing-and-mobility/manufacturing/2025/03/25/industrial-ai-in-action-how-ai-agents-and-digital-threads-will-transform-the-manufacturing-industries/</a></p></li>
<li><p>From Data to Decisions: AI Agents for Industrial Process Optimization - Akira AI, <a href="https://www.akira.ai/blog/ai-agents-for-industrial-process-optimization">https://www.akira.ai/blog/ai-agents-for-industrial-process-optimization</a></p></li>
<li><p>Why should manufacturers embrace AI agents now? - The World Economic Forum, <a href="https://www.weforum.org/stories/2025/01/why-manufacturers-should-embrace-next-frontier-ai-agents/">https://www.weforum.org/stories/2025/01/why-manufacturers-should-embrace-next-frontier-ai-agents/</a></p></li>
<li><p>AI Agents in Manufacturing 2025 Ultimate Guide - Rapid Innovation, <a href="https://www.rapidinnovation.io/post/ai-agent-manufacturing-applications-use-cases-benefits">https://www.rapidinnovation.io/post/ai-agent-manufacturing-applications-use-cases-benefits</a></p></li>
<li><p>AI Agents for Manufacturing Will Give You Superpowers | Plataine, <a href="https://www.plataine.com/blog/ai-agents-for-manufacturing-will-give-you-superpowers/">https://www.plataine.com/blog/ai-agents-for-manufacturing-will-give-you-superpowers/</a></p></li>
<li><p>What are AI Agents in Manufacturing? - Augmentir, <a href="https://www.augmentir.com/glossary/ai-agents-in-manufacturing">https://www.augmentir.com/glossary/ai-agents-in-manufacturing</a></p></li>
<li><p>AI agent for manufacturing: Applications and use cases, components, capabilities, implementation and benefits - LeewayHertz, <a href="https://www.leewayhertz.com/ai-agent-for-manufacturing/">https://www.leewayhertz.com/ai-agent-for-manufacturing/</a></p></li>
<li><p>Reinventing Manufacturing with Agentic AI - Akira AI, <a href="https://www.akira.ai/blog/ai-agents-for-manufacturing">https://www.akira.ai/blog/ai-agents-for-manufacturing</a></p></li>
<li><p>AI Agents In Production – A High Level Overview - Hiflylabs, <a href="https://hiflylabs.com/blog/2024/8/1/ai-agents-multi-agent-overview">https://hiflylabs.com/blog/2024/8/1/ai-agents-multi-agent-overview</a></p></li>
<li><p>How AI Agents Are Driving ROI: 3 Real-World Case Studies (2025) - Creole Studios, <a href="https://www.creolestudios.com/real-world-ai-agent-case-studies/">https://www.creolestudios.com/real-world-ai-agent-case-studies/</a></p></li>
<li><p>The Future of AI: The Power of Agent-to-Agent - Workday Blog, <a href="https://blog.workday.com/en-us/agent-to-agent-overview.html">https://blog.workday.com/en-us/agent-to-agent-overview.html</a></p></li>
<li><p>Future of AI Agents: Trends &amp; Predictions for Businesses (2025) - REVE Chat, <a href="https://www.revechat.com/blog/future-of-ai-agents/">https://www.revechat.com/blog/future-of-ai-agents/</a></p></li>
<li><p>AI Agents: The Defining Workforce Trend of 2025 - Data Society, <a href="https://datasociety.com/ai-agents-the-defining-workforce-trend-of-2025/">https://datasociety.com/ai-agents-the-defining-workforce-trend-of-2025/</a></p></li>
<li><p>Generative AI meets the virtual world: A model for human-AI collaboration - Deloitte, <a href="https://www2.deloitte.com/us/en/insights/industry/technology/ai-and-vr-model-for-human-ai-collaboration.html">https://www2.deloitte.com/us/en/insights/industry/technology/ai-and-vr-model-for-human-ai-collaboration.html</a></p></li>
<li><p>Top 10 AI Agent Trends and Predictions for 2025 - Analytics Vidhya, <a href="https://www.analyticsvidhya.com/blog/2024/12/ai-agent-trends/">https://www.analyticsvidhya.com/blog/2024/12/ai-agent-trends/</a></p></li>
<li><p>Why agents are the next frontier of generative AI - McKinsey, <a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/why-agents-are-the-next-frontier-of-generative-ai">https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/why-agents-are-the-next-frontier-of-generative-ai</a></p></li>
<li><p>16 Real-World AI Agents Examples in 2025 - Aisera, <a href="https://aisera.com/blog/ai-agents-examples/">https://aisera.com/blog/ai-agents-examples/</a></p></li>
</ol>

            ]]>
        </content>
    </entry>
    <entry>
        <title>Joplin with plugins: The Last Note-Taking App You Will Need </title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/joplin-with-plugins-the-last-note-taking-app-you-will-need.html"/>
        <id>https://roger.rogverse.fyi/joplin-with-plugins-the-last-note-taking-app-you-will-need.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/10/joplin-screenshot1.png" medium="image" />
            <category term="note-taking"/>
            <category term="Blog"/>

        <updated>2025-04-08T23:02:27+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/10/joplin-screenshot1.png" alt="" />
                    The digital landscape is saturated with note-taking applications, each promising to be the ultimate solution for organizing thoughts, managing projects, and boosting productivity.
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/10/joplin-screenshot1.png" class="type:primaryImage" alt="" /></p>
                
  <p>
    The digital landscape is saturated with note-taking applications, each promising to be the ultimate solution for organizing thoughts, managing projects, and boosting productivity. From the all-encompassing workspace of Notion to the established ecosystem of Evernote, the interconnected graph of Obsidian, and the simplicity of Google Keep, users have a plethora of options. However, amidst these giants, a lesser-known open-source application, <a href="https://joplinapp.org/">Joplin</a>, is quietly amassing power through a unique advantage: its extensive and versatile plugin ecosystem. While often positioned as an underdog, Joplin's ability to be customized and extended through these community-driven additions allows it to not only compete with but, in many ways, surpass the functionality offered by its more mainstream counterparts.&nbsp;&nbsp;
  </p>
<div><div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube.com/embed/ARNt7LFpzpw?si=7NVmCzTwdTiB4zwO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></div></div>

  <p>
    The core strength of Joplin lies in its adaptability. Unlike some note-taking applications that offer a fixed set of features, Joplin's architecture allows users to selectively enhance its capabilities through plugins. This modular approach provides a significant advantage, enabling individuals to tailor the application precisely to their specific needs and workflows. Instead of being forced to adopt features they don't require, Joplin users can choose from a vast library of extensions that add functionalities ranging from advanced project management tools to specialized academic features. This power of extensibility is Joplin's hidden weapon in its quest to challenge the dominance of the established note-taking giants.
  </p>

    <h2 id="joplins-arsenal-exploring-the-plugin-ecosystem">
      Joplin's Arsenal: Exploring the Plugin Ecosystem
    </h2>

  <p>
    The true potential of Joplin is unlocked by its thriving <a href="https://joplinapp.org/plugins" target="_blank">plugin ecosystem</a>, which currently boasts over 150 extensions. This impressive number is a clear indicator of the active and dedicated community that supports and enhances the application. Installing these plugins is a remarkably user-friendly process. Many plugins can be found and installed directly from within the Joplin application itself through the settings menu. For users who prefer a more hands-on approach or want to explore the latest community contributions, plugins can also be downloaded from platforms like GitHub and installed manually. This dual approach to installation caters to users of all technical skill levels.
  </p>

  <p>
    The breadth of Joplin's plugin ecosystem is truly remarkable, covering a wide spectrum of functionalities designed to enhance productivity, organization, customization, task management, and integration with other tools. For productivity enhancements, plugins like Note Tabs address a common desire to work with multiple notes simultaneously by introducing a familiar tabbed interface. Rich Markdown elevates the writing experience by offering a more visually appealing and customizable Markdown editor. Navigating long documents becomes easier with the Outline plugin, which provides a sidebar table of contents. Consistent formatting is ensured by the Templates plugin, allowing users to create and reuse predefined note structures. Quick access to frequently used items is provided by the Favorites plugin , while the Quick Links plugin streamlines internal linking between notes, fostering a more interconnected knowledge base.
  </p>
<div><p><img loading="lazy" src="https://cdn.rogverse.fyi/thorium_FwXeqlTMIX.png"  data-is-external-image="true"></p></div>

  <p>
    For users seeking advanced organization capabilities, Joplin offers powerful plugin options. Kanban plugins, such as KanMug and YesYouKan, transform Joplin into a visual task management system, allowing notes to be arranged on customizable boards, similar to Notion's board views or dedicated Kanban applications. To visualize the connections between notes, Graph View plugins like Sepremento's Awesome Graph, Link Graph UI, and Joplin Graph Plugin offer interactive network diagrams, akin to Obsidian's renowned graph view. Enhancing the interconnectedness of notes further, Backlinks plugins like Automatic Backlinks automatically create links from notes that reference the current one, a core feature of Roam Research's approach to knowledge management.
  </p>

  <p>
    The visual appeal and user experience of Joplin can also be tailored through plugins. The macOS Theme provides a native look and feel for macOS users , while the Extra Markdown editor settings plugin offers fine-grained control over the editing environment. Beyond specific themes, Joplin's core functionality supports the use of custom themes, allowing for deep visual customization.
  </p>

  <p>
    Task management within Joplin can be significantly enhanced with dedicated plugins. Inline TODO allows embedding to-dos directly within notes and provides a consolidated summary. Metis offers a straightforward task manager based on the portable Todo.txt format. For tracking time spent on tasks, the Time Slip plugin provides a solution integrated directly within notes. Calendar integration is offered by the Joplin Calendar plugin , while the Journal plugin facilitates daily journaling practices. The Agenda plugin provides a dedicated panel displaying upcoming and overdue tasks.
  </p>

  <p>
    Finally, Joplin's plugin ecosystem extends its reach through integrations with other valuable tools. The Web Clipper browser extension allows users to save web pages and articles as notes directly into Joplin. The Email to Note plugin enables sending emails to a specific address, which are then automatically converted into Joplin notes. For users of the spaced repetition learning tool Anki, the Anki Sync plugin provides bidirectional synchronization. Developers can even integrate Joplin with their coding workflow using the VSCode Integration.
  </p>

  <p>
    Beyond these core categories, Joplin's plugin repository contains unique and specialized tools that highlight its remarkable flexibility. The Rubi and Furigana Plugin was created to assist users learning Japanese by adding support for ruby characters. The Function Plot Plugin provides the ability to generate mathematical visualizations directly within notes. The Hotfolder plugin automates the process of importing files from a local directory as new notes. The Joplin AI assistant integrates artificial intelligence capabilities for features like related note suggestions. For users who need spreadsheet-like functionality, the JSheets plugin offers a unique solution. Visual thinkers can benefit from the Mindmap Plugin. Lastly, the Automatic Backlinks plugin provides a crucial feature for building interconnected knowledge graphs, a hallmark of applications like Roam Research and Obsidian. These examples demonstrate the platform's capacity to cater to highly specific and diverse user needs.
  </p>

    <h2 id="the-giants-and-their-domains-strengths-and-weaknesses-of-alternatives">
      The Giants and Their Domains: Strengths and Weaknesses of Alternatives
    </h2>

  <p>
    To truly understand how Joplin, empowered by its plugins, can compete, it's essential to examine the strengths and weaknesses of its primary alternatives. Each application offers a distinct set of features and caters to different user preferences.
  </p>
<div><p>
<table>
        <thead>
            <tr>
                <th>Application</th>
                <th>Key Strengths</th>
                <th>Key Weaknesses</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Notion</td>
                <td>Flexibility, databases, project management features, integrations, feature-rich free plan</td>
                <td>Steep learning curve, potential for distraction, expensive for teams</td>
            </tr>
            <tr>
                <td>Evernote</td>
                <td>Web clipping, organization, search, integrations, robust note-taking features</td>
                <td>Restricted free plan, high pricing, performance issues reported</td>
            </tr>
            <tr>
                <td>Obsidian</td>
                <td>Local-first, Markdown-based, extensive plugin ecosystem, graph view, strong internal linking</td>
                <td>Steeper learning curve for non-technical users, less intuitive for basic note-taking, paid sync service</td>
            </tr>
            <tr>
                <td>Microsoft OneNote</td>
                <td>Free, cross-platform, integration with Microsoft ecosystem, inking capabilities, flexible page layout</td>
                <td>Can feel bloated, syncing issues reported, less privacy-focused</td>
            </tr>
            <tr>
                <td>Apple Notes</td>
                <td>Free for Apple users, integrated into the ecosystem, simple and fast, secure notes</td>
                <td>Limited features compared to others, only available on Apple devices, syncing issues reported</td>
            </tr>
            <tr>
                <td>Google Keep</td>
                <td>Free, simple, cross-platform, quick note-taking, reminders, excellent Google Workspace integration</td>
                <td>Limited formatting and organization, no notebooks, basic task management, no dedicated desktop app</td>
            </tr>
            <tr>
                <td>Roam Research</td>
                <td>Bi-directional linking, networked thought, graph view, focus on emergent connections</td>
                <td>Expensive, steep learning curve, cloud-based (privacy concerns for some), development concerns</td>
            </tr>
            <tr>
                <td>Logseq</td>
                <td>Free and open-source, local-first, outliner-based, bi-directional linking, flashcards, PDF annotation</td>
                <td>Steeper learning curve, less polished than some, mobile apps in beta</td>
            </tr>
            <tr>
                <td>Craft</td>
                <td>Beautiful interface, block-based editor, collaboration features, well-structured documents</td>
                <td>Primarily cloud-based, less focus on plain Markdown, can be expensive for individual users after the free tier</td>
            </tr>
        </tbody>
    </table>
</p></div>

  <p>
    Notion excels as a versatile workspace, offering a highly flexible block-based system that allows users to create custom pages, databases, and project management tools. Its strong collaboration features and integrations make it a popular choice for teams. However, its extensive functionality can be overwhelming for new users, leading to a steep learning curve. The sheer number of options can also be a source of distraction, and the pricing structure can become prohibitive for larger teams.&nbsp;
  </p>

  <p>
    Evernote, a long-standing player in the note-taking space, offers robust note-taking features with rich formatting options and an excellent web clipper. Its powerful search functionality, including OCR, and good organizational structure with notebooks and tags are key strengths. However, the free plan has become increasingly restrictive, and the paid plans can be quite expensive. Some users have also reported performance issues and a feeling of the application becoming bloated over time.
  </p>

  <p>
    Obsidian, favored by those building personal knowledge graphs, offers a local-first approach, ensuring data ownership and privacy. Built on Markdown, it provides flexibility and longevity for notes. Its highly customizable nature, thanks to a vast plugin ecosystem and themes, is a major draw. The powerful internal linking with backlinks and a graph view for visualizing connections are core features. However, users unfamiliar with Markdown and the concept of a personal knowledge graph might face a steeper learning curve. While the interface is minimalistic, it might not appeal to all users, and official syncing across devices requires a paid subscription.
  </p>

  <p>
    Microsoft OneNote, often pre-installed on Windows devices, is free to use and integrates seamlessly with the Microsoft 365 ecosystem. Its flexible page layout allows for freeform note placement, and its strong inking capabilities are excellent for handwritten notes and annotations. However, some users find it can feel bloated with features, and syncing issues across devices are occasionally reported. Compared to some other options, it places less emphasis on privacy.
  </p>

  <p>
    Apple Notes, free for Apple users, offers deep integration within the Apple ecosystem, providing seamless syncing across devices. Its user interface is simple and intuitive, making it excellent for quick note-taking, and it offers secure notes with Face ID/Touch ID locking. However, compared to more advanced applications, its feature set is limited, and it is only available within the Apple ecosystem. Syncing reliability has also been questioned by some users.
  </p>

  <p>
    Google Keep stands out for its simplicity and speed in capturing quick notes, lists, and reminders, and it's completely free. Its excellent integration with other Google Workspace apps is a significant advantage for many users. However, it offers very limited formatting options and lacks a hierarchical organization system with notebooks. Its task management capabilities are basic, and it does not have a dedicated desktop application.
  </p>

  <p>
    Roam Research has pioneered the concept of bi-directional linking, allowing users to create highly interconnected knowledge networks. Its graph view provides a unique way to visualize the relationships between notes, and it focuses on networked thought and discovering emergent connections. However, it is one of the most expensive note-taking applications available and can have a steep learning curve due to its unconventional approach. Its reliance on cloud storage might also be a concern for privacy-conscious users.
  </p>

  <p>
    Logseq, a free and open-source alternative, offers a local-first approach, prioritizing data privacy. Its outliner-based structure encourages breaking down thoughts into interconnected blocks, and it features strong bi-directional linking and graph view capabilities. It also includes useful features like flashcards and PDF annotation. However, users unfamiliar with outliner workflows might experience a steeper learning curve, and its user interface might feel less polished than some commercial options. The mobile apps are currently in beta.
  </p>

  <p>
    Craft provides a visually appealing and user-friendly interface with a block-based editor focused on creating well-structured documents. Its strong collaboration features allow for real-time sharing and co-editing of documents. However, it is primarily cloud-based, which might concern users who prefer local storage. It also places less emphasis on plain Markdown editing compared to some other applications and can become expensive for individual users after the free tier.
  </p>

    <h2 id="andnbspplugin-power-joplin-bridges-the-gaps-and-leaps-ahead">
      &nbsp;Plugin Power: Joplin Bridges the Gaps (and Leaps Ahead)
    </h2>

  <p>
    Joplin's plugin ecosystem provides a powerful mechanism to address many of the weaknesses found in these alternative applications and even introduce features that surpass their built-in capabilities.
  </p>

  <p>
    For project management, Joplin plugins like <a href="https://joplinapp.org/plugins/plugin/joplin-plugin-kanmug/" target="_blank">KanMug </a>and YesYouKan bring robust Kanban board functionality, allowing users to visually manage tasks and projects within their notes. This effectively bridges the gap with applications like Notion that offer similar board views. The flexibility of these Joplin plugins, with customizable columns and the ability to associate notes based on tags or notebook paths , can even offer a more tailored project management experience.
  </p>

  <p>
    In the realm of task management, Joplin's plugin arsenal goes beyond the basic to-do lists offered by Evernote or OneNote. Inline TODO allows embedding tasks with context , Metis offers a portable Todo.txt-based system , and Time Slip provides integrated time tracking. The addition of calendar and agenda views through plugins like Joplin Calendar and Agenda  further enhances Joplin's ability to manage tasks effectively, potentially exceeding the built-in features of many competitors.
  </p>
<div><p><img loading="lazy" src="https://cdn.rogverse.fyi/joplin-graph.png"  data-is-external-image="true"></p></div>

  <p>
    For knowledge organization, Joplin's graph view plugins (<a href="https://joplinapp.org/plugins/plugin/org.sepremento.joplin.graph/" target="_blank">Sepremento's Awesome Graph</a>, Link Graph UI, Joplin Graph Plugin) provide a visual exploration of interconnected notes, directly mirroring a key strength of Obsidian. The Automatic Backlinks plugin implements Roam Research's innovative bi-directional linking system, fostering a highly connected personal knowledge base. These plugins empower Joplin users to build sophisticated knowledge networks with visual exploration capabilities similar to dedicated tools.&nbsp;
  </p>

  <p>
    While Joplin Cloud offers collaboration features, the plugin ecosystem is still evolving in this area. However, the ability to share notes via links and export in various formats provides workarounds for collaborative editing using other platforms.
  </p>

    <h2 id="andnbspvoices-from-the-community-user-reviews-and-comparisons">
      &nbsp;Voices from the Community: User Reviews and Comparisons
    </h2>

  <p>
    User reviews and community discussions provide valuable real-world perspectives on Joplin's capabilities. Many users appreciate Joplin's open-source nature, giving them control over their data. The local storage option is a significant advantage for privacy-conscious individuals. The support for Markdown is also a key draw for many. The power of Joplin's plugins is frequently cited as a major strength, allowing users to tailor the application to their specific needs. Users report successfully implementing features like note tabs and graph views through plugins, effectively addressing feature gaps with other applications.
  </p>

  <p>
    Some users note that Joplin's user interface can feel less polished compared to some alternatives. However, the availability of themes, such as the macOS theme, allows for visual customization. While the mobile app is sometimes mentioned as having limitations, it still provides essential functionality for on-the-go access. The initial learning curve of Markdown is also a point of feedback for some new users. Overall, the community sentiment suggests that while Joplin might have some areas for improvement, its plugin ecosystem is a powerful tool that allows users to overcome many of these limitations and create a highly customized and effective note-taking solution. The open-source nature and active community foster a sense of continuous improvement and shared ownership of the application.
  </p>

    <h2 id="the-freedom-of-choice-joplins-customization-edge">
      The Freedom of Choice: Joplin's Customization Edge
    </h2>

  <p>
    A key differentiator for Joplin is its commitment to user choice and customization. Unlike more integrated applications like Apple Notes or Google Keep, which offer a fixed set of features, Joplin's plugin-based architecture provides unparalleled flexibility. Users are empowered to build a note-taking system that precisely matches their workflow, selecting only the functionalities they require. This modularity avoids the feature bloat often found in all-in-one solutions and allows for a highly personalized user experience.
  </p>

  <p>
    Beyond plugins, Joplin offers further avenues for customization. Users can alter the application's visual appearance through custom themes. For those who desire even finer control over styling, the userchrome.css file can be modified to adjust the user interface at a granular level. Additionally, Joplin allows for the customization of keyboard shortcuts, enabling users to optimize their workflow for maximum efficiency. This deep level of customization, extending beyond just features to encompass appearance and behavior, provides Joplin users with a unique level of control over their note-taking environment
  </p>

    <h2 id="conclusion-joplin-the-plugin-powered-contender">
      Conclusion: Joplin - The Plugin-Powered Contender
    </h2>

  <p>
    In a crowded marketplace of note-taking applications, Joplin stands out as a powerful and adaptable contender, primarily due to its robust and versatile plugin ecosystem. While it might be considered an underdog compared to giants like Notion, Evernote, and Obsidian, Joplin's ability to be tailored to individual needs through these community-driven extensions allows it to effectively compete and, in many instances, surpass the functionality offered by its more established rivals. Its open-source nature, coupled with its deep customization options, provides users with a level of control and flexibility that is often absent in proprietary alternatives. For individuals who value the freedom to shape their tools to their exact specifications, Joplin, with its plugin-powered arsenal, emerges as a compelling and highly capable note-taking solution ready to conquer the digital workspace.
  </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>NeuroSync: Glimpse Interactive Digital Experiences</title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/neurosync-glimpse-interactive-digital-experiences.html"/>
        <id>https://roger.rogverse.fyi/neurosync-glimpse-interactive-digital-experiences.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/9/neurosync-2.jpg" medium="image" />
            <category term="Blog"/>
            <category term="AI"/>

        <updated>2025-04-07T11:20:23+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/9/neurosync-2.jpg" alt="" />
                    NeuroSync: The Future of Interactive Digital Experiences is Here Get ready for a revolution in digital interaction! This blog post dives into the&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/9/neurosync-2.jpg" class="type:primaryImage" alt="" /></p>
                <h1 id="neurosync-the-future-of-interactive-digital-experiences-is-here">NeuroSync: The Future of Interactive Digital Experiences is Here</h1>
<p>Get ready for a revolution in digital interaction! This blog post dives into the exciting world of <a href="https://neurosync.info/">NeuroSync</a>, an open-source project poised to redefine how we experience interactive games, digital avatars, and even streaming content. Prepare to have your perception of reality in the digital realm challenged!</p><h2 id="the-quest-for-believable-digital-avatars">The Quest for Believable Digital Avatars</h2>
<p>We’re constantly seeking more immersive and dynamic digital experiences. Whether it’s diving into a new game, exploring the metaverse, or connecting on social media, the believability of digital avatars is key. Realistic facial animation, with all its subtle nuances, is crucial for conveying emotions and creating genuine engagement. Historically, this has been a complex and labor-intensive process. But now, <a href="https://huggingface.co/AnimaVR/NEUROSYNC_Audio_To_Face_Blendshape">NeuroSync</a> is stepping onto the scene to change the game.</p><p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/inzoi.jpg" alt="Digital Avatar" data-is-external-image="true"></figure>
<em>INZOI a glimpse into the world of digital avatars.</em></p><h2 id="neurosync-unlocking-real-time-facial-animation-in-unreal-engine-5">NeuroSync: Unlocking Real-Time Facial Animation in Unreal Engine 5</h2>
<p>NeuroSync is an open-source marvel that allows for the real-time streaming of facial blendshapes into the powerful <a href="https://www.unrealengine.com/en-US/">Unreal Engine 5</a> using audio input. Let’s break down how this works:</p><h3 id="detailed-technical-overview">Detailed Technical Overview</h3>
<p>At its core, NeuroSync utilizes a sophisticated transformer seq2seq model. This model cleverly translates audio features into facial blendshape coefficients in real-time, making digital characters’ faces move in sync with their speech and even express emotions.</p><h3 id="the-power-of-the-local-api">The Power of the Local API</h3>
<p>For developers who crave control and minimal lag, NeuroSync offers a <a href="https://github.com/AnimaVR/NeuroSync_Local_API">Local API</a>. This allows you to host the pre-trained audio-to-face model on your own hardware, giving you complete command over the animation process and potentially reducing latency.</p><h3 id="seamless-integration-with-unreal-engine-5">Seamless Integration with Unreal Engine 5</h3>
<p>Integrating NeuroSync into Unreal Engine 5 is a breeze thanks to the <a href="https://docs.unrealengine.com/5.3/en-US/livelink-in-unreal-engine/">LiveLink API</a>. The <a href="https://github.com/AnimaVR/NeuroSync_Player">NeuroSync Player</a> acts as the bridge, streaming the animation data directly into the engine. It leverages Apple’s ARKit blendshapes for a wide range of realistic facial movements.</p><h3 id="continuous-improvement">Continuous Improvement</h3>
<p><a href="https://youtu.be/iqzbrE7KV_M?si=pw4LWBluneJRI57i">NeuroSync</a> is constantly evolving. Recent updates, like the one on February 4, 2025, have brought significant improvements in timing accuracy and the naturalness of expressions, especially in areas like brows, cheeks, and mouth shapes. Another update on March 29, 2025, further enhanced accuracy and smoothness through refined training data and model architecture.</p><p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/thorium_m0BM7Eu1AP.png" alt="NeuroSync in Unreal Engine 5" data-is-external-image="true"></figure>
<em>NeuroSync seamlessly integrates with Unreal Engine 5</em></p><h2 id="the-power-couple-neurosync-and-multimodal-llms-in-interactive-games">The Power Couple: NeuroSync and Multimodal LLMs in Interactive Games</h2>
<p>Imagine combining NeuroSync’s realistic facial animation with the intelligence of multimodal Large Language Models (LLMs). This synergy could lead to truly revolutionary interactive gaming experiences.</p><h3 id="beyond-text-multimodal-llms-understand-the-game">Beyond Text: Multimodal LLMs Understand the Game</h3>
<p>Multimodal LLMs can process various forms of data, including text, images, and audio. This allows them to understand the game’s context and the player’s input in a much richer way than traditional text-based LLMs. They can interpret visual cues, spoken dialogue, and even the overall game environment to create more intelligent and responsive NPCs.</p><h3 id="bringing-characters-to-life-with-expressive-animation">Bringing Characters to Life with Expressive Animation</h3>
<p>NeuroSync provides the visual expressiveness that complements the intelligence of MLLMs. While an MLLM can generate smart dialogue, NeuroSync animates the character’s face in real-time, synchronized with the speech. This creates incredibly believable and relatable virtual characters.</p><h3 id="the-future-is-now-existing-integrations">The Future is Now: Existing Integrations</h3>
<p>The integration of LLMs with game engines is already being explored. Projects like <a href="https://arxiv.org/html/2309.12276v2">LLMR (Large Language Model for Mixed Reality)</a> and <a href="https://www.immersivecomputinglab.org/wp-content/uploads/2024/08/2024-ISMAR-AgentBehaviorGeneration.pdf">VIVRA (Voice Interactive Virtual Reality Annotation)</a> showcase the potential of LLMs in creating dynamic and interactive virtual worlds. The <a href="https://github.com/AkshitIreddy/Interactive-LLM-Powered-NPCs">Interactive LLM Powered NPCs</a> project even aims to revolutionize NPC interactions in existing games using AI for dialogue and facial animation.</p><p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/graphic-features-supported-convai-1.png" alt="LLM Powered NPC" data-is-external-image="true"></figure>
<em>Intelligent NPCs powered by LLMs.</em></p><h2 id="neurosync-and-metas-vision-digital-twins-and-ai-influencers">NeuroSync and Meta’s Vision: Digital Twins and AI Influencers</h2>
<p>Tech giant Meta is heavily invested in the metaverse and the creation of realistic digital twins and engaging AI influencers. NeuroSync could play a vital role in bringing these digital entities to life.</p><h3 id="metas-ambitious-plans">Meta’s Ambitious Plans</h3>
<p>Meta envisions a future where digital twins accurately represent real-world individuals in the metaverse. Engaging AI influencers would also require highly realistic and expressive avatars.</p><h3 id="enhancing-visual-fidelity-and-emotional-expression">Enhancing Visual Fidelity and Emotional Expression</h3>
<p>NeuroSync’s real-time audio-to-facial animation can significantly contribute to the visual fidelity and emotional expressiveness of these Meta-driven avatars. The ability to generate nuanced facial expressions directly from audio will make digital twins and AI influencers feel more alive and believable.</p><h3 id="potential-for-collaboration">Potential for Collaboration</h3>
<p>The synergy between NeuroSync and Meta’s goals opens up exciting possibilities for collaboration. Meta could integrate NeuroSync’s technology to enhance its avatar creation process, and the open-source nature of NeuroSync could benefit from the scale and resources of Meta’s platforms.</p><p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/Zucc_pgzaxw.jpg" alt="Metaverse Avatars" data-is-external-image="true"></figure>
<em>Realistic avatars in the metaverse.</em></p><h2 id="blurring-reality-neurosync-unreal-engine-5-and-streaming-content">Blurring Reality: NeuroSync, Unreal Engine 5, and Streaming Content</h2>
<p>The combination of NeuroSync and Unreal Engine 5’s incredible rendering capabilities could lead to a future where it’s hard to distinguish between computer-generated graphics and reality in streaming content.</p><h3 id="unreal-engine-5-a-master-of-photorealism">Unreal Engine 5: A Master of Photorealism</h3>
<p>Unreal Engine 5 is renowned for its ability to create stunningly photorealistic visuals in real-time. Games like Unrecord and Bodycam (while not explicitly detailed in the provided snippets, their visual fidelity is well-known) showcase the engine’s power to produce graphics that can often be mistaken for real life.</p><h3 id="elevating-ai-avatars-in-live-streaming">Elevating AI Avatars in Live Streaming</h3>
<p>When you pair UE5’s visual prowess with NeuroSync’s lifelike facial animation, AI avatars in live streaming scenarios can reach unprecedented levels of realism. Imagine AI streamers that not only look incredibly real but also speak and emote with natural facial expressions. This could truly blur the lines between virtual and human content creators.</p><p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/Unreal+Engine_spotlights_meet-vincent-a-real-time-digital-human-created-in-house-by-a-team-of-just-five_Spotlight_Giantstep_blog_body_img2-1640x1000-fcfc6112efbd1cceabc7687e7fb4d456276791f8.jpg" alt="Unreal Engine 5 Realism" data-is-external-image="true"></figure>
<em>Meet Vincent: a real-time digital human. The photorealistic power of Unreal Engine 5.</em></p><h2 id="the-rise-of-ai-digital-personalities-surpassing-humans">The Rise of AI Digital Personalities: Surpassing Humans?</h2>
<p>The emergence of AI digital personalities, such as the popular AI Vtubers Neurosama and Codemiko, raises the question: could AI eventually surpass human creators in online interactions?</p><h3 id="neurosama-and-codemiko-the-ai-vtubing-phenomenon">Neurosama and Codemiko: The AI Vtubing Phenomenon</h3>
<p><a href="https://en.wikipedia.org/wiki/Neuro-sama">Neurosama</a> is an AI VTuber and chatbot on Twitch, created by developer Vedal. She uses a large language model to generate human-like responses and has gained a massive following, even breaking <a href="https://streamscharts.com/news/vedals-ai-vtuber-neuro-twitch-hype-train-record">Twitch’s Hype Train record</a>. <a href="https://en.wikipedia.org/wiki/CodeMiko">Codemiko</a>, on the other hand, is a VTuber known for her unique glitchy aesthetic and highly interactive streams. Behind the avatar is a real person, Youna Kang (The Technician), who uses motion capture and Unreal Engine to bring Codemiko to life.</p><h3 id="why-are-they-so-popular">Why Are They So Popular?</h3>
<p>Neurosama’s success is partly due to the novelty of interacting with an AI, while Codemiko’s appeal lies in her unique character and high level of interactivity. Both demonstrate that engaging digital personalities, whether fully AI-driven or human-controlled with advanced avatars, can captivate online audiences.</p><h3 id="ai-vs-humans-the-great-debate">AI vs. Humans: The Great Debate</h3>
<p>Could AI digital personalities truly surpass human creators? While AI offers advantages like 24/7 availability and scalability, it currently lacks the genuine emotions and lived experiences that drive deep human connection. It’s more likely that AI will become a powerful tool that complements human creativity rather than replacing it entirely.</p><p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/Neuro-sama-20231106-1.webp" alt="AI VTuber" data-is-external-image="true"></figure>
<em>AI VTubers like Neurosama are gaining popularity.</em></p><p><figure class="post__image"><img loading="lazy" src="https://cdn.rogverse.fyi/thorium_9XrxXIYuJO-ezgif.com-cut.gif" alt="Codemiko" data-is-external-image="true"></figure>
<em>Codemiko, known for her interactive streams.</em></p><h2 id="conclusion-embracing-the-future-of-interactive-media">Conclusion: Embracing the Future of Interactive Media</h2>
<p>NeuroSync, in conjunction with the power of multimodal LLMs and the stunning visuals of Unreal Engine 5, is paving the way for a truly transformative era in interactive media. From more engaging games and realistic digital avatars to the potential blurring of lines in streaming content, the possibilities are immense. While AI digital personalities are making waves, the unique essence of human creativity will likely ensure a future where both AI and human creators thrive, offering diverse and enriching digital experiences.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Beyond the Terminal: Is VTM the Revolutionary Text-Based Desktop In The Making? </title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/beyond-the-terminal-is-vtm-the-revolutionary-text-based-desktop-in-the-making.html"/>
        <id>https://roger.rogverse.fyi/beyond-the-terminal-is-vtm-the-revolutionary-text-based-desktop-in-the-making.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/7/Windows_Terminal_logo.svg-2.png" medium="image" />
            <category term="Terminal"/>
            <category term="Blog"/>

        <updated>2025-03-23T19:03:03+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/7/Windows_Terminal_logo.svg-2.png" alt="" />
                    The world of command-line interfaces is experiencing a renaissance. For years, the terminal remained a relatively static tool, a direct descendant of the&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/7/Windows_Terminal_logo.svg-2.png" class="type:primaryImage" alt="" /></p>
                
  <p>
    The world of command-line interfaces is experiencing a renaissance. For years, the terminal remained a relatively static tool, a direct descendant of the teletype machines of the past. But recently, we've seen exciting innovations aimed at enhancing the user experience, with tools like the Warp terminal leading the charge . These modern terminals offer a plethora of features designed to boost productivity and make the command line more accessible. However, a new contender has emerged, one that proposes a far more radical shift: VTM, the text-based desktop environment . Could this be more than just another terminal emulator? Could it be a truly revolutionary way to interact with our computers?
  </p>

    <h2 id="warp-modernizing-the-terminal-experience">
      Warp: Modernizing the Terminal Experience
    </h2>

  <p>
    Warp has garnered significant attention for its approach to modernizing the terminal. It takes the familiar concept of a terminal emulator and infuses it with features inspired by contemporary development environments . One of its standout capabilities is the integration of AI, offering intelligent command suggestions and explanations for errors, effectively lowering the barrier to entry for those less familiar with the command line . Warp also introduces the concept of "blocks," grouping command inputs and outputs together for easier navigation, sharing, and filtering, addressing a common frustration of sifting through lengthy terminal sessions . For those accustomed to IDEs, Warp provides IDE-like editing on the command line, allowing users to place their mouse cursor and edit commands intuitively without the need for excessive backspacing . Furthermore, it boasts smart completions for a vast array of CLI tools, streamlining the process of entering commands . Collaboration is another key aspect, with features like session sharing enabling teams to work together on the command line in real-time . Users can also personalize their experience with extensive customization options for themes, keybindings, and prompts . Under the hood, Warp leverages technologies like Rust and GPU rendering to deliver performance enhancements, resulting in a faster and more responsive terminal . In essence, Warp refines the traditional terminal paradigm, making it more user-friendly, intelligent, and collaborative, focusing on improving the experience of interacting with the command line within a graphical environment .
  </p>

    <h2 id="vtm-a-different-breed-the-text-based-desktop-environment">
      VTM: A Different Breed - The Text-Based Desktop Environment
    </h2>

    <figure class="post__image post__image--center">
      <a href="https://github.com/directvt/vtm" target="_blank">
        <img loading="lazy" src="https://roger.rogverse.fyi/media/posts/7/vtm_jSrkwppU3f.png" height="814" width="1298" alt="VTM on Windows 11 running Yazi"  sizes="(max-width: 48em) 100vw, 768px" srcset="https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-xs.webp 300w ,https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-sm.webp 480w ,https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-md.webp 768w ,https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-lg.webp 1024w ,https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-xl.webp 1360w ,https://roger.rogverse.fyi/media/posts/7/responsive/vtm_jSrkwppU3f-2xl.webp 1600w">
      </a>
      <figcaption>https://github.com/directvt/vtm</figcaption>
    </figure>

  <p>
    Stepping into a different realm entirely is VTM. Unlike Warp, which enhances the terminal, VTM aims to create a complete desktop environment constructed entirely from text cells arranged in a TUI (Text-based User Interface) matrix . This fundamental difference in approach leads to a unique set of features . The entire user interface in VTM is rendered using text characters, forming a mosaic of cells that constitute the display. This includes everything from application windows to any potential menus or interface elements. A key aspect of VTM is its ability to manage windows. It can wrap any console application within these text-based "windows," which users can then arrange, resize, move, and even layer, offering a desktop-like organizational structure . The documentation for VTM's user interface details a comprehensive set of mouse and keyboard shortcuts for these window management operations, including actions for moving, resizing, maximizing, minimizing, and closing windows . Remarkably, VTM can be nested indefinitely, allowing for the creation of intricate and potentially isolated text-based desktop layouts . Users can launch existing command-line applications within this environment , with documentation mentioning command-line launching and the possibility of a default application setting . Video demonstrations show users launching terminal emulators and other text-based tools within the VTM environment . VTM offers flexibility in rendering its TUI matrix, capable of displaying it within its own GUI window (currently only on Windows) or within a compatible text console . Furthermore, VTM boasts cross-platform support, running on Windows and various \*nix systems . This vision of a complete desktop built from text fundamentally diverges from the approach of traditional terminals and Warp, which primarily focus on enhancing the experience within the confines of a single terminal window. VTM, on the other hand, seeks to be a text-based alternative to the traditional graphical desktop.
  </p>

    <h2 id="revolutionary-potential-why-vtm-might-just-be-the-next-big-thing-or-a-niche-gem">
      Revolutionary Potential: Why VTM Might Just Be the Next Big Thing (or a Niche Gem)
    </h2>

  <p>
    The implications of VTM being a text-based desktop environment are significant. One potential advantage lies in resource usage. Theoretically, an environment built entirely from text could consume considerably fewer system resources like CPU, RAM, and GPU compared to a conventional graphical desktop . While specific data on VTM's resource footprint isn't readily available, the inherent nature of a TUI suggests a lighter overhead compared to rendering complex graphical elements. This potential for lower resource consumption could make VTM particularly appealing in resource-constrained scenarios, on older hardware, or for users who prioritize efficiency.
<br>
<br>Furthermore, the text-based foundation of VTM could unlock unparalleled levels of customization. Since every aspect of the interface is rendered with text, users could theoretically have fine-grained control over its appearance and potentially even its functionality through text-based configuration files . The user interface documentation hints at extensive configuration options . This level of control could resonate with users who desire deep personalization of their computing environment.
<br>
<br>VTM's unique approach also opens up possibilities for use cases that extend beyond typical terminal workflows. It could serve as a minimalist computing environment for those seeking a distraction-free, text-centric experience. Its potential for lightweight operation could make it an efficient solution for remote access, especially in situations with limited bandwidth . VTM might also find applications in embedded systems where graphical capabilities are constrained. Additionally, it could offer unique accessibility advantages for users with certain visual impairments. The aesthetic of classic text-based interfaces combined with modern features like window management and application support could appeal to users who appreciate retro computing styles but require contemporary functionality . Moreover, VTM could provide a structured, windowed environment for running multiple terminal-based applications, offering a different organizational paradigm compared to tools like<code> tmux&nbsp;</code>or <code>screen</code> .
<br>
<br>In contrast, the enhancements offered by Warp primarily focus on improving the efficiency and usability of the traditional terminal experience within a graphical environment. While Warp undoubtedly addresses many pain points of command-line users, VTM challenges the fundamental paradigm of how we interact with our computers at a lower level. This difference in scope suggests that while Warp aims to make the existing terminal experience better, VTM explores a more radical alternative, potentially leading to more significant shifts in user interaction.
  </p>

    <h2 id="vtms-unique-features-standing-out-from-the-crowd">
      VTM's Unique Features: Standing Out from the Crowd
    </h2>

  <p>
    Several specific features of VTM distinguish it from both traditional terminal emulators and modern ones like Warp. One key difference is VTM's text-based window management . Unlike the tabbed or split-pane interfaces common in traditional terminals, VTM provides a more flexible windowing system within its text grid. As demonstrated in videos, users can arrange applications in a manner reminiscent of a graphical desktop . The detailed user interface documentation further illustrates the extensive mouse and keyboard actions available for managing these windows . This approach to window management goes beyond the capabilities of terminal multiplexers like <code>tmux </code>or <code>screen</code>, offering a more visually oriented, albeit still text-based, method for organizing applications. Tools like <code>tmux </code>and <code>screen </code>typically operate within a single terminal window, whereas VTM creates distinct, resizable areas within its text-based desktop.
<br>
<br>Another unique feature is the ability to nest VTM instances . Running a text-based desktop environment within another offers a level of organizational control and potential for isolated workspaces not found in traditional terminals. This nesting capability could be particularly useful for managing complex workflows or creating sandboxed environments. Imagine having a dedicated text-based desktop for development tasks running inside another for general computing, providing a clear separation of concerns.
<br>
<br>VTM's capability to render its output to either a dedicated GUI window (currently on Windows) or a standard text console  provides significant adaptability. This dual rendering option makes VTM accessible in both graphical and purely text-based environments. For users who prefer a graphical interface, the Windows GUI rendering allows them to experience VTM's features, while those working in text-only environments can also utilize it. A video demonstrates VTM running seamlessly within the Windows Terminal , showcasing its ability to integrate with existing terminal emulators.
<br>
<br>Similar to <code>screen </code>or <code>tmux</code>, VTM allows users to detach from running applications, which continue to operate in the background, and then re-attach to them later . This feature enhances the persistence and management of long-running command-line tasks within the VTM environment. Users can close the VTM window, and their processes will continue to run, allowing them to resume their work at a later time.
<br><br>Furthermore, VTM offers various mechanisms for remote access, enabling users to run remote applications and even the entire desktop environment over SSH . This built-in remote access functionality could make VTM a valuable tool for system administrators and developers who frequently work with remote machines. The documentation explicitly outlines commands for establishing remote connections and running applications or the full desktop via SSH.
  </p>

    <h2 id="why-you-might-want-to-take-vtm-for-a-spin">
      Why You Might Want to Take VTM for a Spin
    </h2>

  <p>
    VTM presents several compelling reasons for users to consider trying it out, depending on their individual needs and preferences. For those who are simply curious about novel computing paradigms and enjoy exploring unconventional tools, VTM offers a unique experience unlike any standard terminal emulator or graphical desktop environment. Its text-based nature provides a distinct way of interacting with a computer that might appeal to those seeking something different.
<br>
<br>Users who value a minimalist, text-centric environment and are intrigued by the potential for lower resource usage compared to traditional GUIs might find VTM particularly attractive. If efficiency and a distraction-free workspace are priorities, VTM's approach could be a compelling alternative.
<br>
<br>Even for command-line power users who are already comfortable with tools like `tmux` or `screen`, VTM offers a different way to manage and interact with multiple terminal-based applications. The "infinite canvas" concept, as hinted at in video demonstrations , could provide a more intuitive or visually organized approach to managing numerous terminal sessions.
<br>
<br>Developers who spend a significant amount of time working with text editors, consoles, and other command-line tools might find VTM's integrated and organized workspace beneficial. Having the ability to arrange these tools in a desktop-like manner within a text-based environment could enhance productivity.
<br>
<br>Retro computing enthusiasts might appreciate VTM's ability to capture the aesthetic of classic text-based interfaces while providing modern features such as window management and cross-platform compatibility. It offers a nostalgic feel with contemporary functionality.
<br>
<br>System administrators could find VTM's remote access capabilities and its structured approach to managing multiple terminal sessions particularly useful for server management tasks. The ability to run remote desktops or individual applications over SSH could streamline remote workflows.
<br>
<br>However, it's important to acknowledge potential drawbacks. The entirely text-based nature of VTM might not appeal to users who heavily rely on graphical applications for their daily tasks. The user interface paradigm and the extensive reliance on keyboard shortcuts, as suggested in documentation and videos , might require a learning period for new users. The current limitation of GUI rendering to Windows might also be a consideration for users on other platforms who might need to run VTM within an existing terminal emulator. Finally, as VTM appears to be an active project, some features might be under development or subject to change.
<br>
<br>Ultimately, VTM caters to a specific niche of users who are either seeking a fundamentally different computing experience or have particular needs that a text-based desktop environment can address. While it's unlikely to replace mainstream graphical desktops for the majority of users, its unique approach could be highly valuable for certain individuals and specific use cases.
  </p>

    <h2 id="text-as-the-new-frontier">
      Text as the New Frontier?
    </h2>

  <p>
    In the evolving landscape of command-line tools, Warp represents a significant step forward in enhancing the traditional terminal experience, making it more intelligent, user-friendly, and collaborative. However, VTM takes a far more radical approach by reimagining the entire desktop environment as a text-based interface. While Warp refines the familiar paradigm, VTM dares to ask "what if we went back to text, but with modern windowing and application management?". This bold approach could lead to exciting new ways of interacting with our computers, even if it remains a niche tool for specific use cases and adventurous users. For those intrigued by the possibilities of a text-based future, exploring the VTM GitHub repository and trying it out for themselves could offer a glimpse into a fundamentally different way of computing.
  </p>

    <h2 id="feature-comparison">
      Feature Comparison
    </h2>
<div><table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>Warp</th>
      <th>VTM (Text-based Desktop)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Core Concept</strong></td>
      <td>Modern terminal emulator with enhanced features</td>
      <td>Text-based application creating a complete desktop environment from text cells</td>
    </tr>
    <tr>
      <td><strong>UI Paradigm</strong></td>
      <td>Primarily graphical with text-based command line</td>
      <td>Entirely text-based user interface (TUI)</td>
    </tr>
    <tr>
      <td><strong>Window Management</strong></td>
      <td>Tabs and split panes within a single terminal window</td>
      <td>Text-based windows for applications that can be moved, resized, layered, and nested within a text grid</td>
    </tr>
    <tr>
      <td><strong>Application Launching</strong></td>
      <td>Standard command execution within the terminal</td>
      <td>Wraps and runs any console application within its text-based windows</td>
    </tr>
    <tr>
      <td><strong>AI Integration</strong></td>
      <td>Built-in AI for command suggestions, error explanations, etc.</td>
      <td>Not explicitly mentioned in the provided snippets.</td>
    </tr>
    <tr>
      <td><strong>Collaboration</strong></td>
      <td>Session sharing and other collaborative features</td>
      <td>Multiple users can connect to a desktop session in real-time .</td>
    </tr>
    <tr>
      <td><strong>Customization</strong></td>
      <td>Themes, keybindings, prompts, etc.</td>
      <td>Potentially extreme customization due to its text-based nature .</td>
    </tr>
    <tr>
      <td><strong>Resource Usage</strong></td>
      <td>Generally efficient, with GPU rendering for speed</td>
      <td>Potentially lower resource usage compared to GUI environments (conceptual benefit of TUIs)</td>
    </tr>
    <tr>
      <td><strong>Cross-Platform</strong></td>
      <td>macOS, Linux, Windows</td>
      <td>Windows, Linux, macOS, FreeBSD, NetBSD, OpenBSD</td>
    </tr>
    <tr>
      <td><strong>GUI Rendering</strong></td>
      <td>Yes</td>
      <td>Dedicated GUI window available on Windows; renders within a terminal on other platforms</td>
    </tr>
    <tr>
      <td><strong>Detached Processes</strong></td>
      <td>Not a primary feature highlighted in snippets</td>
      <td>Supports detaching and re-attaching to running applications .</td>
    </tr>
  </tbody>
</table></div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Crystalwire 1.0 Release</title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/crystalwire-10-release.html"/>
        <id>https://roger.rogverse.fyi/crystalwire-10-release.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/4/Python-logo-notext.svg.png" medium="image" />
            <category term="Python"/>
            <category term="Network"/>
            <category term="Monitoring"/>
            <category term="Blog"/>

        <updated>2025-03-22T22:54:21+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/4/Python-logo-notext.svg.png" alt="" />
                    When you don't care about the firewall but need the jumping graphs that track which process consumes all your bandwidth, it's like Glasswire&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/4/Python-logo-notext.svg.png" class="type:primaryImage" alt="" /></p>
                
  <p>
    When you don't care about the firewall but need the jumping graphs that track which process consumes all your bandwidth, it's like Glasswire for terminals!
  </p>

    <figure class="post__image post__image--center">
      <img loading="lazy" src="https://roger.rogverse.fyi/media/posts/4/image-2.png" height="583" width="817" alt=""  sizes="(max-width: 48em) 100vw, 768px" srcset="https://roger.rogverse.fyi/media/posts/4/responsive/image-2-xs.webp 300w ,https://roger.rogverse.fyi/media/posts/4/responsive/image-2-sm.webp 480w ,https://roger.rogverse.fyi/media/posts/4/responsive/image-2-md.webp 768w ,https://roger.rogverse.fyi/media/posts/4/responsive/image-2-lg.webp 1024w ,https://roger.rogverse.fyi/media/posts/4/responsive/image-2-xl.webp 1360w ,https://roger.rogverse.fyi/media/posts/4/responsive/image-2-2xl.webp 1600w">
      
    </figure>

  <p>
    Crystalwire is a command-line tool that monitors network bandwidth usage for each running process in real-time. It utilizes the psutil library for gathering system information and displays the data in a user-friendly format.<br>
  </p>

    <h2 id="installation">
      Installation
    </h2>

  <p>
    1. Clone the project
  </p>
<pre class="line-numbers  language-bash"><code>gh repo clone rpfilomeno/crystalwire</code></pre>

  <p>
    2. install 'crystalwire' the dependencies
  </p>
<pre class="line-numbers  language-bash"><code>pip install -r requirements.txt</code></pre>

    <h2 id="usage">
      Usage
    </h2>

  <p>
    Once installed, you can run 'crystalwire' from the command line:
  </p>
<pre class="line-numbers  language-bash"><code>python -m crystalwire.main</code></pre>

  <p>
    
  </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Monitoring Kamailio and Asterisk with AWS CloudWatch</title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/monitoring-kamailio-and-asterisk-with-aws-cloudwatch.html"/>
        <id>https://roger.rogverse.fyi/monitoring-kamailio-and-asterisk-with-aws-cloudwatch.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/3/images-1.png" medium="image" />
            <category term="VOIP"/>
            <category term="Blog"/>
            <category term="AWS"/>

        <updated>2025-03-22T22:42:13+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/3/images-1.png" alt="" />
                    Today I'm announcing the release to my new project VOIP Statistics to AWS CloudWatch (voip-mon-aws-cloudwatch), it is a monitoring script for Kamailio and&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/3/images-1.png" class="type:primaryImage" alt="" /></p>
                
    <figure class="post__image post__image--center">
      <img loading="lazy" src="https://roger.rogverse.fyi/media/posts/3/voip-aws-mon-2.jpg" height="647" width="1373" alt=""  sizes="(max-width: 48em) 100vw, 768px" srcset="https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-xs.webp 300w ,https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-sm.webp 480w ,https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-md.webp 768w ,https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-lg.webp 1024w ,https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-xl.webp 1360w ,https://roger.rogverse.fyi/media/posts/3/responsive/voip-aws-mon-2-2xl.webp 1600w">
      
    </figure>

  <p>
    Today I'm announcing the release to my new project <a href="https://github.com/rpfilomeno/voip-mon-aws-cloudwatch">VOIP Statistics to AWS CloudWatch (voip-mon-aws-cloudwatch)</a>, it is a monitoring script for Kamailio and Asterisk for AWS CloudWatch written in PHP. <br>
  </p>

  <p>
    This works similarly to AWS CloudWatch Monitoring Script (Linux).<br><br>Requirements<br>
  </p>

  <ul>
    <li>PHP 5.5 and above</li><li>Composer</li><li>Asterisk</li><li>Kamailio</li>
  </ul>

  <p>
    Installation<br><br>1. Git clone to any Linux instance with Kamailio or Asterisk installed,<br><br>for example to ~/home/ec2-user/ using&nbsp;
  </p>
<pre class="line-numbers  language-html"><code>git clone https://github.com/rpfilomeno/voip-mon-aws-cloudwatch.git</code></pre>

  <p>
    2. Go to the project's root directory by
  </p>
<pre class="line-numbers  language-html"><code>cd ./voip-mon-aws-cloudwatch/</code></pre>

  <p>
    
  </p>

  <p>
    3. Make the mon-put-instance-data.php executable
  </p>
<pre class="line-numbers  language-html"><code>sudo chmod +x mon-put-instance-data.php</code></pre>

  <p>
    4. Install Composer
  </p>
<pre class="line-numbers  language-html"><code>curl -sS https://getcomposer.org/installer | php</code></pre>

  <p>
    5. Install the dependencies by
  </p>
<pre class="line-numbers  language-html"><code>php composer.phar update</code></pre>

  <p>
    6. Create your AWS&nbsp;<a href="http://docs.aws.amazon.com/aws-sdk-php/v3/guide/guide/credentials.html#credential-profiles" target="_blank">credentials file</a>
  </p>

    <h2 id="monitoring-kamailio">
      Monitoring Kamailio
    </h2>

  <p>
    1. Test the script for monitoring Kamailio with
  </p>
<div>./mon-put-instance-data.php stats --t kamailio</div>

  <p>
    2. Install to Crontab with
  </p>
<div>crontab -e
*/5 * * * * php /home/ec2-user/voip-mon-aws-cloudwatch/mon-put-instance-data.php stats --s kamailio</div>

    <h2 id="monitoring-asterisk">
      Monitoring Asterisk
    </h2>

  <p>
    1. Test the script for monitoring Kamailio with
  </p>
<div>./mon-put-instance-data.php stats --t asterisk
</div>

  <p>
    2. Install to Crontab with
  </p>
<div>crontab -e
*/5 * * * * php /home/ec2-user/voip-mon-aws-cloudwatch/mon-put-instance-data.php stats --s asterisk</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Testing Kamailio load balancer with SIPp</title>
        <author>
            <name>Roger Filomeno</name>
        </author>
        <link href="https://roger.rogverse.fyi/testing-kamailio-load-balancer-with-sipp.html"/>
        <id>https://roger.rogverse.fyi/testing-kamailio-load-balancer-with-sipp.html</id>
        <media:content url="https://roger.rogverse.fyi/media/posts/2/5348744.png" medium="image" />
            <category term="VOIP"/>
            <category term="Testing"/>
            <category term="Blog"/>

        <updated>2025-03-22T22:11:12+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://roger.rogverse.fyi/media/posts/2/5348744.png" alt="" />
                    Here are the steps to test Kamailio under load. First of all lets describe our network setup: The a user from extension 300X&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://roger.rogverse.fyi/media/posts/2/5348744.png" class="type:primaryImage" alt="" /></p>
                <p>Here are the steps to test Kamailio under load.</p><p>First of all lets describe our network setup:</p><script src="https://gist.github.com/rpfilomeno/d46493eefaf70d6838c157305ab9778a.js"></script>

<p>The a user from extension <em>300X</em> registered to <em>Asterisk 1</em> initiates a call to an extension <em>400X</em> registered at <em>Asterisk 2</em>. <em>Kamailio</em> is registered as a <em>trunk</em> to both Asterisk 1 &amp; 2; which intercepts the call which load balances it to either <em>Asterisk X or Y</em> where they do some <em>fancy</em> pre-processing to current call before its received by the callee.</p><p>Now for our testing purposes, we needed to remove the effect on performance by Asterisk 1 &amp; 2 so we installed SIPp on another host which generates calls and receives them.</p><h3 id="installation-and-execution-steps">Installation and Execution Steps</h3>
<ol>
<li>Download and Modify SIPp to auto respond always and include OPTIONS packet as well (-aa broken?), edit src/call.cpp:</li>
</ol>
<pre><code class="language-cpp">call::T_AutoMode call::checkAutomaticResponseMode(char * P_recv)
{
    if (strcmp(P_recv, &quot;BYE&quot;)==0) {
        return E_AM_UNEXP_BYE;
    } else if (strcmp(P_recv, &quot;CANCEL&quot;) == 0) {
        return E_AM_UNEXP_CANCEL;
    } else if (strcmp(P_recv, &quot;PING&quot;) == 0) {
        return E_AM_PING;
    } else if ((strcmp(P_recv, &quot;INFO&quot;) == 0) || (strcmp(P_recv, &quot;NOTIFY&quot;) == 0) || (strcmp(P_recv, &quot;UPDATE&quot;) == 0) || (strcmp(P_recv, &quot;OPTIONS&quot;) == 0)
               ) {
        return E_AM_AA;
    } else {
        return E_AM_DEFAULT;
    }
}
</code></pre>
<p>Compile <em>sipp-3.3.990</em> with <a href="http://sipp.sourceforge.net/doc/reference.html#Installing+SIPp">RTP Support</a>.</p><p>To run the test, from SIPp Box: </p><pre><code class="language-bash"># sipp 10.254.1.30 -i 10.254.1.40 -sf uac.xml -aa -inf accounts.csv -l 10000 -r 1 -rp 1000 -trace_msg -trace_err -trace_stat
</code></pre>
<table class="table">
  <thead>
    <tr>
      <th>Parameter</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10.254.1.30</td>
      <td>target Kamailio's IP on the LAN A side (see network diagram)</td>
    </tr>
    <tr>
      <td>-i 10.254.1.40</td>
      <td>make sure to bind SIPp on this IP especially if we are using IP Authentication on Kamailio</td>
    </tr>
    <tr>
      <td>-sf <a href="https://gist.github.com/rpfilomeno/7445a628a3cbc0ceaaf8e9afe182578b#file-uac-xml">uac.xml</a></td>
      <td>use this scenario file that generates calls.</td>
    </tr>
    <tr>
      <td>-inf <a href="https://gist.github.com/rpfilomeno/8673ee9dc7355274dfd98d187bbde925#file-accounts-csv">accounts.csv</a></td>
      <td>use this input CSV file, this is where the <em>[field0]</em>,<em>[field1]</em>,<em>[field2]</em> and <em>[field3]</em> values are derived in uac.xml. <br>Edit this file accordingly in format: 
        <em>
        CallID;Kamailio LAN A IP;[authentication];Extension on Asterisk 2;Asterisk 2 LAN B IP;
        </em>
    </td>
    </tr>
    <tr>
      <td>-l 10000</td>
      <td>run 1000 calls.</td>
    </tr>
    <tr>
      <td>-r 1 -rp 1000</td>
      <td>make one call per 1000ms (1 secs)</td>
    </tr>
    <tr>
      <td>-trace_msg</td>
      <td>log all messages to a file (filename auto generated)</td>
    </tr>
    <tr>
      <td>-trace_err</td>
      <td>log all errors to a separate file (filename auto generated)</td>
    </tr>
    <tr>
      <td>-trace_stat</td>
      <td>generate a CSV file with statistics which is good for making graphs (default 1 minute interval) </td>
    </tr>
  </tbody>
</table>


<p>Make sure to edit the accounts.csv, change 10.254.1.30 and 10.254.7.31 accordingly.</p><p>Make sure to edit the uac.xml, change Route:</p><pre><code>&lt;sip:10.254.1.30;r2=on;lr=on;nat=yes&gt;,&lt;sip:10.254.3.30;r2=on;lr=on;nat=yes&gt;```
accordingly since sipp-3.3.990 can&#39;t reliably generate this header so we had to hard code this for now. 

You may run a SIPp on Asterisk 2 box to test higher concurrent calls (eg: testing more than 200 concurrent calls).

Lets shutdown Asterisk 1 &amp; 2: 
```bash
# asterisk -rx &quot;core stop now&quot;
</code></pre>
<p>To run a server listening to incoming calls (server mode), run:</p><pre><code class="language-bash"># sipp 10.254.7.30 -i 10.254.7.31 -sf uas.xml -aa -trace_msg -trace_err -trace_stat
</code></pre>
<p>Makes sure to edit the <a href="https://gist.github.com/rpfilomeno/5827e6ecf5863f74f53d41b1e15fa707#file-uas-xml">uas.xml</a> to include the IP routes.</p><p>Now lets see how effective is Kamailio in this setup, here are the results I had:</p><table class="table">
  <thead>
    <tr>
      <th>Test Name</th>
      <th>Concurrent Calls</th>
      <th>Success</th>
      <th>Failed</th>
      <th>Dead Calls</th>
      <th>Retransmissions</th>
      <th>Average Response Time</th>
      <th>Average Call Rate Per Seconds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Test1</td>
      <td>200</td>
      <td>1000</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>2.52747</td>
      <td>03.615000</td>
    </tr>
    <tr>
      <td>Test2</td>
      <td>300</td>
      <td>998</td>
      <td>2</td>
      <td>5</td>
      <td>252</td>
      <td>3.15839</td>
      <td>04.550000</td>
    </tr>
    <tr>
      <td>Test3</td>
      <td>400</td>
      <td>993</td>
      <td>7</td>
      <td>12</td>
      <td>1355</td>
      <td>3.61512</td>
      <td>13.049000</td>
    </tr>
    <tr>
      <td>Test4</td>
      <td>600</td>
      <td>831</td>
      <td>169</td>
      <td>127</td>
      <td>3554</td>
      <td>4.05337</td>
      <td>13.04900</td>
    </tr>
  </tbody>
</table>

<p>We stop at <em>Test 4</em> seeing Failed Calls spiked up at 169 calls, this was significant from our base capacity of 50 concurrent calls already.</p><p>Many thanks to <a href="http://saevolgo.blogspot.com/">Gohar Ahmed</a> for helping me figuring most of the bugs.</p>
            ]]>
        </content>
    </entry>
</feed>
